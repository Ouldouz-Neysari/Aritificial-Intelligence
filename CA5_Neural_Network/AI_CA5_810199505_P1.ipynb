{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3RAWKc-4P5o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "deS3gt2K9jqe",
        "outputId": "20725e8d-74c4-4cc9-ad36-ca12e0495327"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c0d411cb-7cf9-45fc-bf21-e1842e69f96c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13435</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13436</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13437</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13438</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13439</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13440 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0d411cb-7cf9-45fc-bf21-e1842e69f96c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c0d411cb-7cf9-45fc-bf21-e1842e69f96c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c0d411cb-7cf9-45fc-bf21-e1842e69f96c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label\n",
              "0          1\n",
              "1          1\n",
              "2          1\n",
              "3          1\n",
              "4          1\n",
              "...      ...\n",
              "13435     28\n",
              "13436     28\n",
              "13437     28\n",
              "13438     28\n",
              "13439     28\n",
              "\n",
              "[13440 rows x 1 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_label_df=pd.read_csv('/content/TrainLabels.csv',header=None)\n",
        "train_label_df.rename(columns = {0:'label'}, inplace = True)\n",
        "train_label_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ZnNRnQur9qBy",
        "outputId": "1d7f336d-7479-45c2-9034-a29f212dfe4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-56bf0ebd-29ab-4a1c-a88d-32322316c74a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13435</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13436</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13437</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13438</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13439</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13440 rows Ã— 1024 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56bf0ebd-29ab-4a1c-a88d-32322316c74a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-56bf0ebd-29ab-4a1c-a88d-32322316c74a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-56bf0ebd-29ab-4a1c-a88d-32322316c74a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0     1     2     3     4     5     6     7     8     9     ...  1014  \\\n",
              "0         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "1         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "2         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "3         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "4         0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "13435     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "13436     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "13437     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "13438     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "13439     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
              "\n",
              "       1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
              "0         0     0     0     0     0     0     0     0     0  \n",
              "1         0     0     0     0     0     0     0     0     0  \n",
              "2         0     0     0     0     0     0     0     0     0  \n",
              "3         0     0     0     0     0     0     0     0     0  \n",
              "4         0     0     0     0     0     0     0     0     0  \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "13435     0     0     0     0     0     0     0     0     0  \n",
              "13436     0     0     0     0     0     0     0     0     0  \n",
              "13437     0     0     0     0     0     0     0     0     0  \n",
              "13438     0     0     0     0     0     0     0     0     0  \n",
              "13439     0     0     0     0     0     0     0     0     0  \n",
              "\n",
              "[13440 rows x 1024 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_image_df=pd.read_csv('/content/TrainImgs.csv',header=None)\n",
        "\n",
        "train_image_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mU0cyii09vbr",
        "outputId": "55989e85-9a23-4f3b-907f-e562833afc6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b98e31f-066a-4053-8e3b-e9980e5ce57a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13435</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13436</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13437</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13438</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13439</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13440 rows Ã— 1025 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b98e31f-066a-4053-8e3b-e9980e5ce57a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b98e31f-066a-4053-8e3b-e9980e5ce57a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b98e31f-066a-4053-8e3b-e9980e5ce57a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label  0  1  2  3  4  5  6  7  8  ...  1014  1015  1016  1017  1018  \\\n",
              "0          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "1          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "2          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "4          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "...      ... .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   ...   ...   \n",
              "13435     28  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13436     28  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13437     28  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13438     28  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13439     28  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "\n",
              "       1019  1020  1021  1022  1023  \n",
              "0         0     0     0     0     0  \n",
              "1         0     0     0     0     0  \n",
              "2         0     0     0     0     0  \n",
              "3         0     0     0     0     0  \n",
              "4         0     0     0     0     0  \n",
              "...     ...   ...   ...   ...   ...  \n",
              "13435     0     0     0     0     0  \n",
              "13436     0     0     0     0     0  \n",
              "13437     0     0     0     0     0  \n",
              "13438     0     0     0     0     0  \n",
              "13439     0     0     0     0     0  \n",
              "\n",
              "[13440 rows x 1025 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_df = pd.concat([train_label_df,train_image_df], axis=1)\n",
        "_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaHyYeVI_sGq"
      },
      "outputs": [],
      "source": [
        "test_label_df=pd.read_csv('TestLabels.csv',header=None)\n",
        "test_label_df.rename(columns = {0:'label'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhtiGwKD_uFy"
      },
      "outputs": [],
      "source": [
        "test_image_df=pd.read_csv('TestImgs.csv',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KT_fpzcA_w-e",
        "outputId": "e139a8aa-0030-4c3f-c81d-c5713f0af2be"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-15a7865b-48e1-476c-974e-9bd722c45a87\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3355</th>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3356</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3357</th>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3358</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3359</th>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3360 rows Ã— 1025 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15a7865b-48e1-476c-974e-9bd722c45a87')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15a7865b-48e1-476c-974e-9bd722c45a87 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15a7865b-48e1-476c-974e-9bd722c45a87');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      label  0  1  2  3  4  5  6  7  8  ...  1014  1015  1016  1017  1018  \\\n",
              "0         1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "1         1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "2         2  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3         2  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "4         3  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "...     ... .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   ...   ...   \n",
              "3355     26  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3356     27  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3357     27  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3358     28  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3359     28  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "\n",
              "      1019  1020  1021  1022  1023  \n",
              "0        0     0     0     0     0  \n",
              "1        0     0     0     0     0  \n",
              "2        0     0     0     0     0  \n",
              "3        0     0     0     0     0  \n",
              "4        0     0     0     0     0  \n",
              "...    ...   ...   ...   ...   ...  \n",
              "3355     0     0     0     0     0  \n",
              "3356     0     0     0     0     0  \n",
              "3357     0     0     0     0     0  \n",
              "3358     0     0     0     0     0  \n",
              "3359     0     0     0     0     0  \n",
              "\n",
              "[3360 rows x 1025 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df = pd.concat([test_label_df,test_image_df], axis=1)\n",
        "test_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Analizing and Preprocessing"
      ],
      "metadata": {
        "id": "k0fv6QzNge8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##printing a picture from each class and its label\n",
        "\n",
        "I found number of row of picture of each class and then stired them in an array ,then by the use of imshow I preinted them."
      ],
      "metadata": {
        "id": "le99f_iHgsuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzaZ86oO91bJ",
        "outputId": "c1986c9c-fd0d-44b7-facf-042eb1a414bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0,\n",
              " 8,\n",
              " 16,\n",
              " 24,\n",
              " 32,\n",
              " 40,\n",
              " 48,\n",
              " 56,\n",
              " 64,\n",
              " 72,\n",
              " 80,\n",
              " 88,\n",
              " 96,\n",
              " 104,\n",
              " 112,\n",
              " 120,\n",
              " 128,\n",
              " 136,\n",
              " 144,\n",
              " 152,\n",
              " 160,\n",
              " 168,\n",
              " 176,\n",
              " 184,\n",
              " 192,\n",
              " 200,\n",
              " 208,\n",
              " 216]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diffrent_label_list=[]\n",
        "for i in range(1,29):\n",
        "  for index, row in train_label_df.iterrows():\n",
        "    if(row['label']==i):\n",
        "        diffrent_label_list.append(index)\n",
        "        break\n",
        "\n",
        "diffrent_label_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u6s5xxyw97uj",
        "outputId": "6511ec21-4407-46de-98a7-f55cd6e1c0ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Picture class: 1\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 2\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 3\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 4\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQQElEQVR4nO3df5BV9XnH8ffDsoACJq4gbhFFEWNpGtHZQW0Za2M0atNB047RZlqSGEmd2Kkz2tTRmaqtyWiNGqcz1a6RhiT+bNRoHWpjmHTUMUFXReRHmihCAl1YEZEfVWTZp3/cw3Qh53v37j33nrvwfF4zzN79Pvfc83jcz557z9nzPebuiMjBb1SrGxCRcijsIkEo7CJBKOwiQSjsIkEo7CJBjC6ysJmdB9wFtAHfdvdbqj1/jI31cYwvskoRqeIDdvKh77K8mtV7nt3M2oBfAOcA64GXgEvdfVVqmcOsw0+zs+tan4gMbakvYZtvyQ17kbfxc4A33H2Nu38IPATMK/B6ItJERcI+Ffj1oO/XZ2MiMgIV+sxeCzNbACwAGMehzV6diCQU2bNvAKYN+v7obGwf7t7t7l3u3tXO2AKrE5EiioT9JWCmmR1nZmOAS4AnG9OWiDRa3W/j3b3fzK4E/pPKqbeF7r6yYZ2JSEMV+szu7ouBxQ3qRUSaSH9BJxKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhJEoTvCmNlaYDuwB+h3965GNCUijdeIWzb/obtvbsDriEgT6W28SBBFw+7Aj8zsZTNb0IiGRKQ5ir6Nn+vuG8zsSOAZM/u5uz87+AnZL4EFAOM4tODqRKRehfbs7r4h+9oHPA7MyXlOt7t3uXtXO2OLrE5ECqg77GY23swm7n0MnAusaFRjItJYRd7GTwEeN7O9r/OAuz/dkK5EpOHqDru7rwFObmAvItJEOvUmEoTCLhKEwi4ShMIuEoTCLhJEIy6EkZFkVFvucNsRHclF9ryzJf16A3uKdiQjhPbsIkEo7CJBKOwiQSjsIkEo7CJB6Gj8QWbzl3/jKmMAHrn+tuQyn/3W15K1o+58oXBPMjJozy4ShMIuEoTCLhKEwi4ShMIuEoTCLhKETr0dZHZ1WO74jPYJyWX+6C+eT9Ze7Z6YrA3s3Fl7Y9Jy2rOLBKGwiwShsIsEobCLBKGwiwShsIsEMeSpNzNbCHwG6HP3j2djHcDDwHRgLXCxu7/bvDalVsd+b23ueNfmK5LLHPnc28nawM43kjUbm75Rp5/ysfxlelall+nvT9akuFr27N8Bzttv7FpgibvPBJZk34vICDZk2LP7re8//eg8YFH2eBFwYYP7EpEGq/cz+xR3780eb6RyR1cRGcEKH6Bzdwc8VTezBWbWY2Y9u9lVdHUiUqd6w77JzDoBsq99qSe6e7e7d7l7VzvpAzoi0lz1hv1JYH72eD7wRGPaEZFmqeXU24PAWcAkM1sP3ADcAjxiZpcB64CLm9lkRKOPn56svfX530rWjvvXdbnjR3z7p8ll6r3B0/Z5pyRr37/tm7njZ//71cllZl65tM5OqrD8qwCxKvu5g/SWV0OG3d0vTZTObnAvItJE+gs6kSAUdpEgFHaRIBR2kSAUdpEgNOHkCNU/KT3R4z1f/Odk7Y5PfTp3fM+5Va5Q21XfXzZOXLMjWVvT/5H88c/+S3KZ33vuL9PrevhntTc2yDtfOj13fGDe/pd7/L+jvrQ5Wduz+Z26+hgJtGcXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQqfeRqoXX0+W/mH+F5O1/+3MP8U2kVcLt7Q/71mRrH3j8i/kjm+8+4fp12sr2tFven9K/lVvK7seTi5zwt+mJ+ec8TfpqwdHOu3ZRYJQ2EWCUNhFglDYRYJQ2EWCsMpM0OU4zDr8NIs1m9XozqOStQ9+e2qyNuaFlcnawAcfFOqplUYfnf5v7v+fjekF65wXbtT48bnjc17YmlzmpsnpbX/GNemLdQ57oL6LdRppqS9hm2/JPQWhPbtIEAq7SBAKu0gQCrtIEAq7SBAKu0gQtdz+aSHwGaDP3T+ejd0IXA68nT3tOndf3KwmR7q2WScma3MeTF8scsb4JcnaXedckKwNvJV/i6cDQf/6DaWub2Dnztzxxd86M7nMTV9Pn3prn78pvbIHam6rJWrZs38HOC9n/E53n539Cxt0kQPFkGF392eB9FScInJAKPKZ/UozW25mC83s8IZ1JCJNUW/Y7wZmALOBXuD21BPNbIGZ9ZhZz27qm59cRIqrK+zuvsnd97j7AHAvMKfKc7vdvcvdu9pJ36hARJqrrrCbWeegby8C0oecRWREqOXU24PAWcAkM1sP3ACcZWazAQfWAl9pYo8jxuhpR+eOdz2YPlVzw+RVydpxi7+crJ34Vk/tjcmwTX48/f/ltqtnJGtP/0567ro/mf2FZG1gWXp9ZRky7O5+ac7wfU3oRUSaSH9BJxKEwi4ShMIuEoTCLhKEwi4ShG7/NAx9n5qWO37T5KeSy/T270jWPnZPeuLI8qYBjWnP1veStZe2Tk/WDu14M/2ah7Qna/k3oSqX9uwiQSjsIkEo7CJBKOwiQSjsIkEo7CJB6NTbMIz5XJXJBhPmPvtXydoJPa8WaUcK2H7J6cnaQ8feUWXJQxvfTEm0ZxcJQmEXCUJhFwlCYRcJQmEXCUJH44ehc/y2YS9zzPe1iVtp++fyj7p/4+vdyWUOb0sfcb9580nJ2uif/ypZ25OslEd7dpEgFHaRIBR2kSAUdpEgFHaRIBR2kSBquf3TNOC7wBQqU6N1u/tdZtYBPAxMp3ILqIvd/d3mtdp6/QNtw17mV59OL3Pif41L1gY+SM9Pd7AaNS69PXacf3Ky1nZF+gKlh076Zu74MaMnJJdZ/mF62z/993+QrI1/d2myNhLUsmfvB65291nA6cBXzWwWcC2wxN1nAkuy70VkhBoy7O7e6+6vZI+3A6uBqcA8YFH2tEXAhc1qUkSKG9ZndjObDpwCLAWmuHtvVtpI5W2+iIxQNYfdzCYAjwJXufs+fzfq7k5iqnMzW2BmPWbWs5tdhZoVkfrVFHYza6cS9Pvd/bFseJOZdWb1TqAvb1l373b3LnfvamdsI3oWkToMGXYzMyr3Y1/t7oPn63kSmJ89ng880fj2RKRRrPIOvMoTzOYCzwGvAwPZ8HVUPrc/AhwDrKNy6m1Ltdc6zDr8NDu7aM8t897n86+geuqW25PLTGobn6zd+s7MZO3e5XOTtfE9hyRrHas+zB33tio3IKryIzBm2+5kzXanr+Xq65qYO/7eaenTWhfMWpmsXT9lSbLWWeU0WsqzVc5sXn3zFclax8KfDntdZVrqS9jmW3L/Zw95nt3dnyd9q6oDN7kiwegv6ESCUNhFglDYRYJQ2EWCUNhFghjy1FsjHein3lLenzcnWTvymjXJ2g9m/LgZ7TTUjoH6rr6bMCp9BVujPbrjsGTta0/9We74Sf/UmzsO0P/WusI9tUq1U2/as4sEobCLBKGwiwShsIsEobCLBKGwiwShU29NNurQ9H3DOOGYZGndH3cka+8fn39lG8D5n1iRO37JET9LLnPEqPeTtVFVLolrs3Rt+0B77vh9m89MLvMfr/xusnb4svQ1W50/fCtZ6+/dmKwdjHTqTUQUdpEoFHaRIBR2kSAUdpEgdDT+IJO6hZJ9JH2xiI1qwu/8xM/VwNb3kotEvOVVo+lovIgo7CJRKOwiQSjsIkEo7CJBKOwiQQx5RxgzmwZ8l8otmR3odve7zOxG4HLg7eyp17n74mY1KrVJnr7Saa3whgw70A9c7e6vmNlE4GUzeyar3enu32xeeyLSKLXc660X6M0ebzez1cDUZjcmIo01rM/sZjYdOIXKHVwBrjSz5Wa20MwOb3BvItJANYfdzCYAjwJXufs24G5gBjCbyp4/977FZrbAzHrMrGc3uxrQsojUo6awm1k7laDf7+6PAbj7Jnff4+4DwL1A7p0S3L3b3bvcvaudsY3qW0SGaciwm5kB9wGr3f2OQeOdg552EZA/H5KIjAi1HI3/feDPgdfNbFk2dh1wqZnNpnI6bi3wlaZ0KCINUcvR+OeBvEvmdE5d5ACiv6ATCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQmEXCaKWe72NM7MXzew1M1tpZjdl48eZ2VIze8PMHjazMc1vV0TqVcuefRfwSXc/mcrtmc8zs9OBW4E73f0E4F3gsua1KSJFDRl2r9iRfdue/XPgk8APsvFFwIVN6VBEGqLW+7O3ZXdw7QOeAd4Etrp7f/aU9cDU5rQoIo1QU9jdfY+7zwaOBuYAJ9W6AjNbYGY9Ztazm111tikiRQ3raLy7bwV+ApwBfNTM9t7y+WhgQ2KZbnfvcveudsYWalZE6lfL0fjJZvbR7PEhwDnAaiqh/9PsafOBJ5rVpIgUN3rop9AJLDKzNiq/HB5x96fMbBXwkJndDLwK3NfEPkWkoCHD7u7LgVNyxtdQ+fwuIgcA/QWdSBAKu0gQCrtIEAq7SBAKu0gQ5u7lrczsbWBd9u0kYHNpK09TH/tSH/s60Po41t0n5xVKDfs+KzbrcfeulqxcfaiPgH3obbxIEAq7SBCtDHt3C9c9mPrYl/rY10HTR8s+s4tIufQ2XiSIloTdzM4zs//OJqu8thU9ZH2sNbPXzWyZmfWUuN6FZtZnZisGjXWY2TNm9svs6+Et6uNGM9uQbZNlZnZBCX1MM7OfmNmqbFLTv87GS90mVfoodZs0bZJXdy/1H9BGZVqr44ExwGvArLL7yHpZC0xqwXrPBE4FVgwa+0fg2uzxtcCtLerjRuCakrdHJ3Bq9ngi8AtgVtnbpEofpW4TwIAJ2eN2YClwOvAIcEk2fg9wxXBetxV79jnAG+6+xt0/BB4C5rWgj5Zx92eBLfsNz6MycSeUNIFnoo/SuXuvu7+SPd5OZXKUqZS8Tar0USqvaPgkr60I+1Tg14O+b+VklQ78yMxeNrMFLephrynu3ps93ghMaWEvV5rZ8uxtftM/TgxmZtOpzJ+wlBZuk/36gJK3STMmeY1+gG6uu58KnA981czObHVDUPnNTuUXUSvcDcygco+AXuD2slZsZhOAR4Gr3H3b4FqZ2ySnj9K3iReY5DWlFWHfAEwb9H1ysspmc/cN2dc+4HFaO/POJjPrBMi+9rWiCXfflP2gDQD3UtI2MbN2KgG7390fy4ZL3yZ5fbRqm2TrHvYkrymtCPtLwMzsyOIY4BLgybKbMLPxZjZx72PgXGBF9aWa6kkqE3dCCyfw3BuuzEWUsE3MzKjMYbja3e8YVCp1m6T6KHubNG2S17KOMO53tPECKkc63wSub1EPx1M5E/AasLLMPoAHqbwd3E3ls9dlwBHAEuCXwI+Bjhb18T3gdWA5lbB1ltDHXCpv0ZcDy7J/F5S9Tar0Ueo2AT5BZRLX5VR+sfzdoJ/ZF4E3gH8Dxg7ndfUXdCJBRD9AJxKGwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKEwi4SxP8BWERD7sWYVsEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 6\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 7\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 8\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 9\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 10\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 11\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 12\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 13\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAQ0ElEQVR4nO3dfZBV9X3H8fd3lwXkwQCiSABFECPEiejsoEbHsVqtcZiik8hojSUpI5oJTU1iZyxpGjs1rcmoxHEaE4xEkhAf4kNljFEpY2utEV2QZ1TQYiNZHgwqqAHZ3W//uIfp4pzf3ct9XPb7ec0we+/ve889X4/72XPvOff+jrk7ItL3NTW6ARGpD4VdJAiFXSQIhV0kCIVdJAiFXSSIfpUsbGYXA3cAzcBP3P2WYo/vbwN8IIMrWaWIFLGXD/jI91lezco9z25mzcBrwIXAW8BLwJXuviG1zJE2ws+wC8pan4j0bLkvY7fvyg17JS/jpwGb3f0Nd/8IuB+YUcHziUgNVRL2McDvut1/KxsTkV6oovfspTCzOcAcgIEMqvXqRCShkj37VmBct/tjs7GDuPsCd29199YWBlSwOhGpRCVhfwmYZGYnmFl/4ApgSXXaEpFqK/tlvLt3mNlc4CkKp94Wuvv6qnUmIlVV0Xt2d38CeKJKvYhIDekTdCJBKOwiQSjsIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkHUfCppkVI1DRyYrHXt3VvHTvom7dlFglDYRYJQ2EWCUNhFglDYRYJQ2EWCqOjUm5ltAfYAnUCHu7dWoynpu5o//alkbdu/pJcb9e30fqlr9cZKWgqjGufZ/8Td367C84hIDellvEgQlYbdgafNbIWZzalGQyJSG5W+jD/H3bea2THAUjN7xd2f7f6A7I/AHICBDKpwdSJSror27O6+Nfu5A3gUmJbzmAXu3ururS0MqGR1IlKBssNuZoPNbOiB28BFwLpqNSYi1VXJy/hRwKNmduB5funuT1alK+mzdp88LFm785S7krVvjbk2WRuwuqKWwig77O7+BnBqFXsRkRrSqTeRIBR2kSAUdpEgFHaRIBR2kSA04aTURPPw4bnj701oTi+DJ2v7v/aHZG3QS0cna507dyZr0WjPLhKEwi4ShMIuEoTCLhKEwi4ShI7GS9maBqXnJ9j/0JDc8bWTf1jkGdNH6v/7M48kaxP/7rpk7cRv6Gj8AdqziwShsIsEobCLBKGwiwShsIsEobCLBKFTb1K2piOHJmtDW/bmjk9/7XPJZdZvGpusDV+R/lU96bl3krWuZCUe7dlFglDYRYJQ2EWCUNhFglDYRYJQ2EWC6PHUm5ktBKYDO9z9lGxsBPAAMB7YAsx09/T5D+mTOrZtT9fOPfTnO4n2svoo5/Rav2NHJWsd23ekF/T0PHm9XSl79nuBiz82diOwzN0nAcuy+yLSi/UY9ux667s+NjwDWJTdXgRcWuW+RKTKyn3PPsrdD7zm2kbhiq4i0otVfIDO3R3SE36b2RwzazOztv3sq3R1IlKmcsO+3cxGA2Q/k0c03H2Bu7e6e2sLA8pcnYhUqtywLwFmZbdnAY9Vpx0RqZVSTr3dB5wHjDSzt4DvALcAD5rZbOBNYGYtmxQpV7/xx+WOf2LxnuQyq35zVrI27ubnK+6pUXoMu7tfmShdUOVeRKSG9Ak6kSAUdpEgFHaRIBR2kSAUdpEgNOGk9Gk+aGDu+NdGP5pcZvJ1TyRrF2z/RrJ21N2/Lb2xBtCeXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAidepOirF/6V+S9ma3J2vAX8yej7Nz8P8llmk+amKy9ds0xydpJt76erHVueC13fPZP/jq5zPq5P0zWvnj9b5K1p5eclO6j2CSWdaI9u0gQCrtIEAq7SBAKu0gQCrtIEDoaL0U1F7lM0iO33JqsfWnTFfmFIpOZbZmZXtfmq9JHyD894apk7birdueP/2BVcplrL03PQffjsekvu9xz9SXJ2idv1dF4EakThV0kCIVdJAiFXSQIhV0kCIVdJIhSLv+0EJgO7HD3U7Kxm4BrgJ3Zw+a5e3rirt6mqTlZsiZL1ryjoxbd9G6dncnSGx2DkrWnJj+eOz7loS8ml7nohBdL76ub9WctTta+sPRPc8ff/Xb+ZaEAlr7Ukl5ZkVNvTee8k14ufZaybkrZs98LXJwzPt/dp2b/Dp+giwTVY9jd/VlgVx16EZEaquQ9+1wzW2NmC81seNU6EpGaKDfsdwETgalAO3Bb6oFmNsfM2sysbT/7ylydiFSqrLC7+3Z373T3LuBuYFqRxy5w91Z3b21hQLl9ikiFygq7mY3udvcyYF112hGRWinl1Nt9wHnASDN7C/gOcJ6ZTQUc2AJcW8Meq+73N5yRrHUWOesy7rvP16Cb3q2jfVuyds1P5yZrG76S/y21DZ/9RVl9dHpXsva/HR8ma4sn5M8Zt/cX6dOozaRPv0L+5aQAPnxlWJHlGq/HsLv7lTnD99SgFxGpIX2CTiQIhV0kCIVdJAiFXSQIhV0kiD474WTz5EnJ2q/nfj9ZO/+Bv61FO33S+DvXJ2v/fPmncsfnjXy1rHVNW5mYwBI45u/T32LcfFX+6bBfXf6D5DJTB6Q//DXt5cuTtRP/aU2ylj5xWD/as4sEobCLBKGwiwShsIsEobCLBKGwiwTRZ0+9dQxLT4Z4XL8hydpRa2vRTd/U+e57ydqj88/PHZ/33fSpt/v3pCc8GvWXO5O1znfSEz1OWJ0/Pu+n6Ykv/3h8+ttrR/3XhmSt64MPkrXeQHt2kSAUdpEgFHaRIBR2kSAUdpEg+uzR+HJ98Mn0/GO9e4ax3uXo5/OPnrd3vJ9cZvrgvcnaj6d9Plnr/1Rb6Y1lOjduSj/fxvRyveELLeXSnl0kCIVdJAiFXSQIhV0kCIVdJAiFXSSIUi7/NA74GTCKwuWeFrj7HWY2AngAGE/hElAz3T39jYTDxHF/tiVZ67ylbm0c9jpf3Zw7/qVN6bnknpr8eLK2a0r/ZO3Yp0rvK7JS9uwdwDfdfQpwJvBVM5sC3Agsc/dJwLLsvoj0Uj2G3d3b3X1ldnsPsBEYA8wAFmUPWwRcWqsmRaRyh/Se3czGA6cBy4FR7t6elbZReJkvIr1UyWE3syHAw8D17r67e83dncL7+bzl5phZm5m17WdfRc2KSPlKCruZtVAI+mJ3fyQb3m5mo7P6aGBH3rLuvsDdW929tYX05PsiUls9ht3MjML12De6++3dSkuAWdntWcBj1W9PRKqllG+9nQ1cDaw1s1XZ2DzgFuBBM5sNvAnMrE2L5Wna25GsvdP5YbL2o4kPJmuf/3L+paFGLHox3UhXZ7oW0Ja3R5S13Nl/sTJZe31+ud3E0mPY3f05IPW9zwuq246I1Io+QScShMIuEoTCLhKEwi4ShMIuEkSfnXDSX16frF3w8peTtZWtDyRrL9z8r7njJ1/4V8lljvr1wGRt8Lb9yVr/F15J1nr7ZYYAmgbm/3efOmZrWc/35IYpydok0qfl5P9pzy4ShMIuEoTCLhKEwi4ShMIuEoTCLhJEnz31VsyxN6S/EXfunZcla8+c8nDu+Kbz7k2v7Lx06b2uPyZrj70/Llm7v31asrb5t8fnjg9qT1/Dzov8yd87MndOEgAmnvNmsnbd2P/IHf/zwelvHL6wN/0NwYl3H85XWesdtGcXCUJhFwlCYRcJQmEXCUJhFwnCCrNA18eRNsLPsMN3JqttX/9s7vis2U8ml5k+dG2yNra5JVkb1JS+3NHhYL/nH1n/+u/ztyHAqzekv+zS9J8vV9xTBMt9Gbt9V+6pF+3ZRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgujx1JuZjQN+RuGSzA4scPc7zOwm4BpgZ/bQee7+RLHnOtxPvSVZ+ksmdnr6dNKH4wYnax8c05ysvTs5/f+sa1j+vHaDjtybXOaYI99P1rb+4RPJ2uBnhyRrQ7bln3ob9G9tyWV0qazKFTv1Vsq33jqAb7r7SjMbCqwws6VZbb6731qtRkWkdkq51ls70J7d3mNmG4ExtW5MRKrrkN6zm9l44DRgeTY018zWmNlCMxte5d5EpIpKDruZDQEeBq53993AXcBEYCqFPf9tieXmmFmbmbXtZ18VWhaRcpQUdjNroRD0xe7+CIC7b3f3TnfvAu4GcqdPcfcF7t7q7q0tDKhW3yJyiHoMu5kZcA+w0d1v7zY+utvDLgPWVb89EamWUo7Gnw1cDaw1s1XZ2DzgSjObSuF03Bbg2pp0eDgocvrSV6QvQ3XEivRTHlFkdSNLaKlaTqjjuqS2Sjka/xyQd96u6Dl1Eeld9Ak6kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSBKudbbQDN70cxWm9l6M/vHbPwEM1tuZpvN7AEz61/7dkWkXKXs2fcB57v7qRQuz3yxmZ0JfA+Y7+4nAu8As2vXpohUqsewe8H72d2W7J8D5wMPZeOLgEtr0qGIVEWp12dvzq7gugNYCrwOvOvuHdlD3gLG1KZFEamGksLu7p3uPhUYC0wDTi51BWY2x8zazKxtP/vKbFNEKnVIR+Pd/V3gGeAsYJiZHbjk81hga2KZBe7e6u6tLQyoqFkRKV8pR+OPNrNh2e0jgAuBjRRC/4XsYbOAx2rVpIhUrl/PD2E0sMjMmin8cXjQ3R83sw3A/WZ2M/AycE8N+xSRCvUYdndfA5yWM/4GhffvInIY0CfoRIJQ2EWCUNhFglDYRYJQ2EWCMHev38rMdgJvZndHAm/XbeVp6uNg6uNgh1sfx7v70XmFuob9oBWbtbl7a0NWrj7UR8A+9DJeJAiFXSSIRoZ9QQPX3Z36OJj6OFif6aNh79lFpL70Ml4kiIaE3cwuNrNXs8kqb2xED1kfW8xsrZmtMrO2Oq53oZntMLN13cZGmNlSM9uU/RzeoD5uMrOt2TZZZWaX1KGPcWb2jJltyCY1/ZtsvK7bpEgfdd0mNZvk1d3r+g9opjCt1QSgP7AamFLvPrJetgAjG7Dec4HTgXXdxr4P3JjdvhH4XoP6uAm4oc7bYzRwenZ7KPAaMKXe26RIH3XdJoABQ7LbLcBy4EzgQeCKbPxHwFcO5XkbsWefBmx29zfc/SPgfmBGA/poGHd/Ftj1seEZFCbuhDpN4Jnoo+7cvd3dV2a391CYHGUMdd4mRfqoKy+o+iSvjQj7GOB33e43crJKB542sxVmNqdBPRwwyt3bs9vbgFEN7GWuma3JXubX/O1Ed2Y2nsL8Cctp4Db5WB9Q521Si0leox+gO8fdTwc+B3zVzM5tdENQ+MtO4Q9RI9wFTKRwjYB24LZ6rdjMhgAPA9e7++7utXpuk5w+6r5NvIJJXlMaEfatwLhu95OTVdaau2/Nfu4AHqWxM+9sN7PRANnPHY1owt23Z79oXcDd1GmbmFkLhYAtdvdHsuG6b5O8Phq1TbJ1H/IkrymNCPtLwKTsyGJ/4ApgSb2bMLPBZjb0wG3gImBd8aVqagmFiTuhgRN4HghX5jLqsE3MzCjMYbjR3W/vVqrrNkn1Ue9tUrNJXut1hPFjRxsvoXCk83XgWw3qYQKFMwGrgfX17AO4j8LLwf0U3nvNBo4ClgGbgH8HRjSoj58Da4E1FMI2ug59nEPhJfoaYFX275J6b5MifdR1mwCfoTCJ6xoKf1j+odvv7IvAZuBXwIBDeV59gk4kiOgH6ETCUNhFglDYRYJQ2EWCUNhFglDYRYJQ2EWCUNhFgvg/ijJJiDMuQJUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 14\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 15\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 16\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 17\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 18\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 19\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 20\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 21\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 22\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 23\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 24\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 25\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 26\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARpElEQVR4nO3dfZBV9X3H8feXZdnlSQRRXBEFCcQxpiLZoCaO0TCmhNgSZ4yVjIZkNJta6VRrHyjNqJnJpImJj52qXZWKHYMSHzFhfAhjtTZKWBUXFIuIoNDlQUGeFFh2v/3jHtqFnN/du/fh3F1/n9cMs3d/33v2fD3jZ8+997fnd8zdEZFPv37VbkBEsqGwi0RCYReJhMIuEgmFXSQSCrtIJPqXsrGZTQNuA2qAe9z9p/meP8DqvJ7BpexSRPLYyx72+z5Lq1mx8+xmVgOsBs4HNgDLgJnu/mZomyNshJ9hU4van4h0b6kvYadvSw17KS/jpwBr3H2tu+8HHgRmlPDzRKSCSgn7aOD9Lt9vSMZEpBcq6T17IcysCWgCqGdQpXcnIgGlnNk3AmO6fH98MnYId29290Z3b6ylroTdiUgpSgn7MmCCmY0zswHAJcCi8rQlIuVW9Mt4dz9gZrOBp8lNvc1z9zfK1pmIlFVJ79ndfTGwuEy9iEgF6S/oRCKhsItEQmEXiYTCLhIJhV0kEgq7SCQUdpFIKOwikVDYRSKhsItEQmEXiYTCLhIJhV0kEgq7SCQUdpFIKOwikVDYRSKhsItEQmEXiYTCLhIJhV0kEgq7SCQUdpFIKOwikVDYRSJR0h1hzGwdsAvoAA64e2M5mhKR8ivHLZvPc/cPyvBzRKSC9DJeJBKlht2BZ8zsFTNrKkdDIlIZpb6MP9vdN5rZMcCzZvaWu7/Q9QnJL4EmgHoGlbg7ESlWSWd2d9+YfN0CPAZMSXlOs7s3untjLXWl7E5ESlB02M1ssJkNPfgY+BqwslyNiUh5lfIyfhTwmJkd/Dm/dPenytKV9H39anq8ifWzYM0PHCilG6GEsLv7WuC0MvYiIhWkqTeRSCjsIpFQ2EUiobCLREJhF4lEOS6Ekb4uzzTZjm9/MVgb/N3/CdamHftG6nh7Z/h/ufp+7cHai9vGB2uvvxqujXwlfTpvxK9eC27TuXdvsNaX6cwuEgmFXSQSCrtIJBR2kUgo7CKRMHfPbGdH2Ag/w6Zmtj8pzIdXnBWsPXndz4O1hv5DKtFOJr797nnB2kffGxGsdax+pxLtlM1SX8JO35Y6BaEzu0gkFHaRSCjsIpFQ2EUiobCLREJhF4mELoSJxCcz/mDh3//zi3/412At3/Ta+av+JFjbvuD49EJ4mTnoDJfah4Y3HPGNjcHaHRMWpI7/ctxzwW0uv//sYK3tgqOCtY4PPgzWegOd2UUiobCLREJhF4mEwi4SCYVdJBIKu0gkur3qzczmARcAW9z91GRsBPAQMBZYB1zs7tu725muequ8/ieOSR0/7fH1wW1+Mqo1WBu/5HvB2sQ/Xx2sde7ZE6xlad/09DX05tx+f3CbaYP2BWsT77syWBs396XCG6uQUq96uw+YdtjYHGCJu08AliTfi0gv1m3Yk/utbztseAYwP3k8H/hmmfsSkTIr9j37KHdvSx5vIndHVxHpxUr+gM5zb/qDb/zNrMnMWsyspZ3weyERqaxiw77ZzBoAkq9bQk9092Z3b3T3xlrqitydiJSq2LAvAmYlj2cBT5SnHRGplEKm3hYA5wIjgc3A9cDjwELgBGA9uam3wz/E+wOaequ8t28/I3V87UXhK9u++OrFwdrIi94L1vrybZJ2zjwzWHvppruCtVu3jw3WnvlK+DZUWV0Rl2/qrdtLXN19ZqCk1Ir0IfoLOpFIKOwikVDYRSKhsItEQmEXiYQWnOyDao4cFqxdM/Wp1PG2A7vDP29B+N5mEJ56w/KsHpnhPQSLMezt8PFY3R6+Yu/8wauCtWeOTr/CDoBesBilzuwikVDYRSKhsItEQmEXiYTCLhIJhV0kEpp664Pev+JzwdpfDn8+dXzRnmOC2wz4zuZg7cIfhqfe7rgjvBrZqH/+XbDWG3j/8Hmu3sLThh35phTzTUX2Ajqzi0RCYReJhMIuEgmFXSQSCrtIJPRpfB/UeNGKHm/z9UG7grU/PnVhsFZntcHaF/761mDth89/J3W8s/Wt4DZZ+mRUfbB2Qv8hwdoju48I1mzPJyX1VGk6s4tEQmEXiYTCLhIJhV0kEgq7SCQUdpFIdDv1ZmbzgAuALe5+ajJ2A/B9YGvytLnuvrhSTcao/7gTg7VZRz/Z459XazXB2paO8G2camkP1r5QNyhYe2v20NTxiU3BTTL1wanFzTrf9m74RkgD179bbDuZKOTMfh8wLWX8FneflPxT0EV6uW7D7u4vAN3etFFEerdS3rPPNrNWM5tnZsPL1pGIVESxYb8TGA9MAtqAm0JPNLMmM2sxs5Z29hW5OxEpVVFhd/fN7t7h7p3A3cCUPM9tdvdGd2+spa7YPkWkREWF3cwaunx7IbCyPO2ISKUUMvW2ADgXGGlmG4DrgXPNbBLgwDrgBxXsMU551jrrILu1zmqtuHd690ydlzp+08TwunUdq98pal/51Ew4KXX87y57uKift+fRY4O1gfTuqbduw+7uM1OG761ALyJSQfoLOpFIKOwikVDYRSKhsItEQmEXiYQWnOylOrd+GKxtPRBe9BC293hfx9QM7vE23Zk6sCN1/O+/Er4N1VEVmHpbde3I1PHvHrEluM3C3cOCtWOf2hCsHSi8rarQmV0kEgq7SCQUdpFIKOwikVDYRSKhsItEQlNvvdSOCz4frF0y9L+CtQd3pS8adOMtlwS3GbkifI+yTWeEF5Vcdu1twVroHnH7hpX/ir2O8yYHa/ec3/NrtuYuSrv2K2f8+pd7/PN6C53ZRSKhsItEQmEXiYTCLhIJhV0kEvo0vpc65i+KW8/sx/+W/kny6Lt+F9ym/+jjgrVdVzQEa6FP3PPpV+TVIn7WacHayTe+EayFLshp3hH+b/7sre8Ha739Ypd8dGYXiYTCLhIJhV0kEgq7SCQUdpFIKOwikSjk9k9jgPuBUeRu99Ts7reZ2QjgIWAsuVtAXezuPV8ALWK7/uzMYO3pCXcFa/fuCN+C6OjX9qeOv3fdl4LbXDPz8WDtN8MWB2v5tO7fmzreOSC8zfofhXu869Lw8Th3YGew9m777tTx+df/aXCbIRv67sUu+RRyZj8AXOvupwBnAleZ2SnAHGCJu08AliTfi0gv1W3Y3b3N3V9NHu8CVgGjgRnA/ORp84HwHftEpOp69J7dzMYCpwNLgVHu3paUNpF7mS8ivVTBYTezIcAjwNXuvrNrzd2d3Pv5tO2azKzFzFra2VdSsyJSvILCbma15IL+gLs/mgxvNrOGpN4ApK667+7N7t7o7o211JWjZxEpQrdhNzMjdz/2Ve5+c5fSImBW8ngW8ET52xORcinkqrcvA5cBK8xseTI2F/gpsNDMLgfWAxdXpsVPr92ji/szh8/Xh6/KuvTWX6eOXz5sU1H7Kta2jvS1637eFF4Tbtqg4t7mrW7fE6xdev3fpo4PX/hSUfvqy7oNu7u/CIRWCZxa3nZEpFL0F3QikVDYRSKhsItEQmEXiYTCLhIJLThZRQ3feK+o7abUhRd6nFKX7RRbSPhKtPD0WrunLw4J8K0104O1HT8ZE6wNfzq+KbYQndlFIqGwi0RCYReJhMIuEgmFXSQSCrtIJDT1VmGbrg4vovgfE3+RZ8v0q8aylm86bNGe4cHags1TUseXvzwhuM3YxeFpudqX3gzWBuzdHKzJ/9OZXSQSCrtIJBR2kUgo7CKRUNhFIqFP43ug/9gTUsffuXFYcJulX7opWBvWr7hP3Ld3fBysPbknvcf5G8KzAmtXh28n1fB8+Hxw5G9XB2sd29PvBDa+s7gLU8I3eJJC6cwuEgmFXSQSCrtIJBR2kUgo7CKRUNhFItHt1JuZjQHuJ3dLZgea3f02M7sB+D6wNXnqXHdfXKlGy6pfTbC0bVb6BRwA58xemjr+m4ZFeXY2MFi5d0d4yuuOWy4M1o5csz9YG7D0rdTx/nvC691NpLi18MKXyEhvVMg8+wHgWnd/1cyGAq+Y2bNJ7RZ3z3fploj0EoXc660NaEse7zKzVcDoSjcmIuXVo/fsZjYWOB04+Hp2tpm1mtk8Mwtf3CwiVVdw2M1sCPAIcLW77wTuBMYDk8id+VP/LtTMmsysxcxa2vOsGS4ilVVQ2M2sllzQH3D3RwHcfbO7d7h7J3A3kPrJlrs3u3ujuzfWUleuvkWkh7oNu5kZcC+wyt1v7jLe0OVpFwIry9+eiJRLIZ/Gfxm4DFhhZsuTsbnATDObRG46bh3wg4p0mEe/+vpgbd/ZnwvW3v1W+HfcsunhyYWRNYNTx3d37g1uM/k/w4dl/D+F39aMbNXVYVJehXwa/yJgKaW+MacuIoD+gk4kGgq7SCQUdpFIKOwikVDYRSLRpxecfO+aycHa0qtuDtaG9AtP2UH69BpA847j0sdvnhHcZtzd4Sk0TZNJlnRmF4mEwi4SCYVdJBIKu0gkFHaRSCjsIpHo01NvnxwXXvIw3/TaMx/XBmtXPnl5sPbZf9mcOn7UmuKuUBPJks7sIpFQ2EUiobCLREJhF4mEwi4SCYVdJBJ9eupt4v0fB2sn5Vn/8uTbtwZrn3n75WBN9zaTvkxndpFIKOwikVDYRSKhsItEQmEXiUS3n8abWT3wAlCXPP9hd7/ezMYBDwJHAa8Al7n7/ko2ezhftiJYm7AsvJ0+VZcYFXJm3wd81d1PI3d75mlmdibwM+AWd/8MsB0IXy4mIlXXbdg9Z3fybW3yz4GvAg8n4/OBb1akQxEpi0Lvz16T3MF1C/As8A7wkbsfSJ6yARhdmRZFpBwKCru7d7j7JOB4YApwcqE7MLMmM2sxs5Z2wrcoFpHK6tGn8e7+EfAccBZwpJkd/IDveGBjYJtmd29098Za6kpqVkSK123YzexoMzsyeTwQOB9YRS70FyVPmwU8UakmRaR0hVwI0wDMN7Macr8cFrr7r83sTeBBM/sx8BpwbwX7FJESdRt2d28FTk8ZX0vu/buI9AH6CzqRSCjsIpFQ2EUiobCLREJhF4mEuXt2OzPbCqxPvh0JfJDZzsPUx6HUx6H6Wh8nuvvRaYVMw37Ijs1a3L2xKjtXH+ojwj70Ml4kEgq7SCSqGfbmKu67K/VxKPVxqE9NH1V7zy4i2dLLeJFIVCXsZjbNzP7bzNaY2Zxq9JD0sc7MVpjZcjNryXC/88xsi5mt7DI2wsyeNbO3k6/Dq9THDWa2MTkmy81segZ9jDGz58zsTTN7w8z+KhnP9Jjk6SPTY2Jm9Wb2ezN7PenjR8n4ODNbmuTmITMb0KMf7O6Z/gNqyC1rdRIwAHgdOCXrPpJe1gEjq7Dfc4DJwMouYzcCc5LHc4CfVamPG4C/yfh4NACTk8dDgdXAKVkfkzx9ZHpMAAOGJI9rgaXAmcBC4JJk/C7gyp783Gqc2acAa9x9reeWnn4QmFGFPqrG3V8Ath02PIPcwp2Q0QKegT4y5+5t7v5q8ngXucVRRpPxMcnTR6Y8p+yLvFYj7KOB97t8X83FKh14xsxeMbOmKvVw0Ch3b0sebwJGVbGX2WbWmrzMr/jbia7MbCy59ROWUsVjclgfkPExqcQir7F/QHe2u08Gvg5cZWbnVLshyP1mJ/eLqBruBMaTu0dAG3BTVjs2syHAI8DV7r6zay3LY5LSR+bHxEtY5DWkGmHfCIzp8n1wscpKc/eNydctwGNUd+WdzWbWAJB83VKNJtx9c/I/WidwNxkdEzOrJRewB9z90WQ482OS1ke1jkmy7x4v8hpSjbAvAyYknywOAC4BFmXdhJkNNrOhBx8DXwNW5t+qohaRW7gTqriA58FwJS4kg2NiZkZuDcNV7n5zl1KmxyTUR9bHpGKLvGb1CeNhnzZOJ/dJ5zvAP1aph5PIzQS8DryRZR/AAnIvB9vJvfe6nNw985YAbwO/BUZUqY9/B1YAreTC1pBBH2eTe4neCixP/k3P+pjk6SPTYwL8EblFXFvJ/WK5rsv/s78H1gC/Aup68nP1F3QikYj9AzqRaCjsIpFQ2EUiobCLREJhF4mEwi4SCYVdJBIKu0gk/hdADo2ZG5o8IgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 27\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Picture class: 28\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "j=1\n",
        "\n",
        "for diff_img in diffrent_label_list:\n",
        "  tmp=train_image_df.iloc[diff_img]\n",
        "  np_arr=np.asarray(tmp)\n",
        "\n",
        "  np_arr2=np.resize(np_arr,(32, 32))\n",
        "  np_arr2=np.transpose(np_arr2)\n",
        "  print(\"Picture class:\",j)\n",
        "  plt.figure()\n",
        "  plt.imshow(np_arr2)\n",
        "  plt.show()\n",
        "  print()\n",
        "  j+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6hSxug5-jYf"
      },
      "source": [
        "##Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aETPwOPn-lsS",
        "outputId": "262e9bde-21b6-4841-b54e-d845371863ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "255"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "min_arr=[]\n",
        "max_arr=[]\n",
        "for column in train_image_df:\n",
        "    tmp_min=train_image_df[column].max()\n",
        "    max_arr.append(tmp_min)\n",
        "\n",
        "len(max_arr)\n",
        "max(max_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the range is from 0 to 255"
      ],
      "metadata": {
        "id": "f2Jfk1Xwhbrp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkaVBs3-oLn"
      },
      "source": [
        "##Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3YK0tL3-n2Y",
        "outputId": "ca645207-8801-482c-ad90-e5a2f01a8b9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13440\n"
          ]
        }
      ],
      "source": [
        "print(len(train_image_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 13440 rows in dataset"
      ],
      "metadata": {
        "id": "uB7mhbcJidwN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhTizFpe-8dx",
        "outputId": "238cd989-a59d-4fb5-9ef3-9585c54d29cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of values in dataset 13440\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"number of values in dataset\",len(_df))\n",
        "_df['label'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejg6YkyF_1Tn"
      },
      "source": [
        "##Q4  (seperating 16 classes from 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First I made a list of allowed labels then for each picture I checked wheter the label is in allowed labels or not :"
      ],
      "metadata": {
        "id": "Td-GuJzPoEVU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "iwwIk8dg_BNu",
        "outputId": "e9c73431-a0c5-408d-b3d8-2205af42dd9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e77e58af-fcad-4d6f-a08b-a082a80ca648\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13339</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13340</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13341</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13342</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13343</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7680 rows Ã— 1025 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e77e58af-fcad-4d6f-a08b-a082a80ca648')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e77e58af-fcad-4d6f-a08b-a082a80ca648 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e77e58af-fcad-4d6f-a08b-a082a80ca648');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label  0  1  2  3  4  5  6  7  8  ...  1014  1015  1016  1017  1018  \\\n",
              "0          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "1          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "2          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "4          1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "...      ... .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   ...   ...   \n",
              "13339     16  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13340     16  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13341     16  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13342     16  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "13343     16  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "\n",
              "       1019  1020  1021  1022  1023  \n",
              "0         0     0     0     0     0  \n",
              "1         0     0     0     0     0  \n",
              "2         0     0     0     0     0  \n",
              "3         0     0     0     0     0  \n",
              "4         0     0     0     0     0  \n",
              "...     ...   ...   ...   ...   ...  \n",
              "13339     0     0     0     0     0  \n",
              "13340     0     0     0     0     0  \n",
              "13341     0     0     0     0     0  \n",
              "13342     0     0     0     0     0  \n",
              "13343     0     0     0     0     0  \n",
              "\n",
              "[7680 rows x 1025 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "allowed_labels=[x+1 for x  in range(16)]\n",
        "\n",
        "selected_train_set=_df.loc[_df['label'].isin(allowed_labels)]\n",
        "selected_train_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "encKYnnX_6VZ",
        "outputId": "e4a3169e-ee23-4656-e33b-e30766f2bd61"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7173465f-7c6f-4231-8511-93cbb259911a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3333</th>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3334</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3335</th>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1920 rows Ã— 1025 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7173465f-7c6f-4231-8511-93cbb259911a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7173465f-7c6f-4231-8511-93cbb259911a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7173465f-7c6f-4231-8511-93cbb259911a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      label  0  1  2  3  4  5  6  7  8  ...  1014  1015  1016  1017  1018  \\\n",
              "0         1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "1         1  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "2         2  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3         2  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "4         3  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "...     ... .. .. .. .. .. .. .. .. ..  ...   ...   ...   ...   ...   ...   \n",
              "3331     14  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3332     15  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3333     15  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3334     16  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "3335     16  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0   \n",
              "\n",
              "      1019  1020  1021  1022  1023  \n",
              "0        0     0     0     0     0  \n",
              "1        0     0     0     0     0  \n",
              "2        0     0     0     0     0  \n",
              "3        0     0     0     0     0  \n",
              "4        0     0     0     0     0  \n",
              "...    ...   ...   ...   ...   ...  \n",
              "3331     0     0     0     0     0  \n",
              "3332     0     0     0     0     0  \n",
              "3333     0     0     0     0     0  \n",
              "3334     0     0     0     0     0  \n",
              "3335     0     0     0     0     0  \n",
              "\n",
              "[1920 rows x 1025 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_test_set=test_df.loc[test_df['label'].isin(allowed_labels)]\n",
        "selected_test_set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWLMqoVsAJhz"
      },
      "source": [
        "##Q5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train set:"
      ],
      "metadata": {
        "id": "XIQWPdBEk3TO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAbDCD__AFAt",
        "outputId": "2b19693c-3e02-4028-ea3a-ce8b41f7f1d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480,\n",
              " 480]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value_occurencies_train=[]\n",
        "for i in range(16):\n",
        "  value_occurencies_train.append(selected_train_set['label'].value_counts()[i+1])\n",
        "\n",
        "value_occurencies_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "We4zEWknAPiA",
        "outputId": "3007d497-6095-4bfb-d3e2-bd7637e4a37b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "val_arr=[x+1 for x in range(16)]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(val_arr,value_occurencies_train)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test set :"
      ],
      "metadata": {
        "id": "UB8m7E1Rk7Zp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVbco5TQAa12",
        "outputId": "7bcce328-1d83-45cc-eee8-f67114f3a115"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120,\n",
              " 120]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value_occurencies_test=[]\n",
        "for i in range(16):\n",
        "  value_occurencies_test.append(selected_test_set['label'].value_counts()[i+1])\n",
        "\n",
        "value_occurencies_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "dM6UX0_NAmlO",
        "outputId": "ccddfc37-e003-4fbf-afbc-f620c70e0659"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "val_arr=[x+1 for x in range(16)]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(val_arr,value_occurencies_test)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY6zEboaAsWm"
      },
      "source": [
        "##Q6(Scaling)\n",
        "\n",
        "with the knowledge ,we have scaling would be very easy , because min value is 0 and it's eanough to divide every pixel to 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGXYFBwcApwc",
        "outputId": "5d28e9c7-bf6e-4fc7-b61b-f5ed775e08ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7680\n"
          ]
        }
      ],
      "source": [
        "label_selected_df=selected_train_set['label']\n",
        "print(len(label_selected_df))\n",
        "del selected_train_set['label']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "qt_3GJZzEgKH",
        "outputId": "9a9cf534-39f7-43a6-a8ee-2d80e53cdf1f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-73e6667c-2b13-4445-9b5f-66cada385106\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1014</th>\n",
              "      <th>1015</th>\n",
              "      <th>1016</th>\n",
              "      <th>1017</th>\n",
              "      <th>1018</th>\n",
              "      <th>1019</th>\n",
              "      <th>1020</th>\n",
              "      <th>1021</th>\n",
              "      <th>1022</th>\n",
              "      <th>1023</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13339</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13340</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13341</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13342</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13343</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7680 rows Ã— 1024 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-73e6667c-2b13-4445-9b5f-66cada385106')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-73e6667c-2b13-4445-9b5f-66cada385106 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-73e6667c-2b13-4445-9b5f-66cada385106');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       0     1     2     3     4     5     6     7     8     9     ...  1014  \\\n",
              "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
              "13339   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "13340   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "13341   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "13342   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "13343   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
              "\n",
              "       1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
              "0       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "1       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "2       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "3       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "4       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
              "13339   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "13340   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "13341   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "13342   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "13343   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
              "\n",
              "[7680 rows x 1024 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_train_set=selected_train_set/255\n",
        "selected_train_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4-Lzc6YFmhA",
        "outputId": "082859ae-fcd0-47fc-ac88-13b4a4c02ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1920\n"
          ]
        }
      ],
      "source": [
        "label_selected_df=selected_test_set['label']\n",
        "print(len(label_selected_df))\n",
        "del selected_test_set['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVtN1_85F07b"
      },
      "outputs": [],
      "source": [
        "selected_test_set=selected_test_set/255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7\n",
        "\n",
        "the one hot conding process is handeled in Dataloader class"
      ],
      "metadata": {
        "id": "Aub7Tvk1oxtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##part 2"
      ],
      "metadata": {
        "id": "eQxbu5_To9Lt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOc7nzdCGBFe"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "class Dataloader:\n",
        "    '''\n",
        "    This class prepares the dataset for the neural network.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, data, labels, n_classes, batch_size=None, shuffle=False):\n",
        "        '''\n",
        "        This is the constructor. It gets dataset information and initializes the \n",
        "        Dataloader class fields.\n",
        "            Parameters:\n",
        "                data: features your dataset in pandas.Dataframe format.\n",
        "                labels: labels of your dataset in pandas.Dataframe format.\n",
        "                n_classes: number of classes you have in your dataset.\n",
        "                batch_size: the number of samples that will be propagated through the network.\n",
        "                shuffle: boolean value indicating whether or not the dataset should be shuffled\n",
        "        '''\n",
        "\n",
        "        assert len(data)==len(labels)\n",
        "        self.__n_classes = n_classes\n",
        "        self.__batch_size = batch_size\n",
        "        self.__shuffle = shuffle\n",
        "        self.__data = data\n",
        "        self.__onehot_labels = self.__onehot(labels, self.__n_classes)\n",
        "    \n",
        "    def __onehot(self, labels, n_classes):\n",
        "        '''\n",
        "        This private method gets labels and provides one_hot vectors of labels.\n",
        "        For categorical variables where no such ordinal relationship exists,\n",
        "        the integer encoding is not enough.\n",
        "        In this case, a one-hot encoding can be applied to the integer representation.\n",
        "        This is where the integer encoded variable is removed, and a new binary variable is\n",
        "        added for each unique integer value.\n",
        "        example:\n",
        "            red,    green,    blue\n",
        "            1,      0,        0\n",
        "            0,      1,        0\n",
        "            0,      0,        1\n",
        "                Parameters:\n",
        "                        label: lables of your dataset in pandas.Dataframe format.\n",
        "                        n_classes: number of classes you have in your dataset.\n",
        "                \n",
        "                Returns:\n",
        "                    onehot_vectors: onehot vectors of the labels\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        onehot_vectors = pd.DataFrame(OneHotEncoder().fit_transform(labels).toarray())\n",
        "        return onehot_vectors\n",
        "    \n",
        "    def __shuffle_dataset(self):\n",
        "        '''\n",
        "        This private method shuffles your dataset.\n",
        "        It uses data and onehot_labels to shuffle them\n",
        "        symmetrical.\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        self.__data, self.__onehot_labels = shuffle(self.__data, self.__onehot_labels)\n",
        "    \n",
        "    def __iter__(self):\n",
        "        '''\n",
        "        The __iter__() function returns an iterator for the\n",
        "        given object (array, set, tuple, etc., or custom objects).\n",
        "        This will return your dataset in the batch_size given. This should\n",
        "        be used to provide data for the neural network.\n",
        "        '''\n",
        "        \n",
        "        if self.__shuffle:\n",
        "            self.__shuffle_dataset()\n",
        "            \n",
        "        if self.__batch_size==None:\n",
        "            yield (np.matrix(self.__data), np.matrix(self.__onehot_labels))\n",
        "            return\n",
        "            \n",
        "        for idx in range(0, len(self.__data), self.__batch_size):\n",
        "            yield (np.matrix(self.__data[idx:idx+self.__batch_size]), \n",
        "                   np.matrix(self.__onehot_labels[idx:idx+self.__batch_size]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni4GzL-IGMC3"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "class Identical:\n",
        "    '''\n",
        "    This is the Identical activation function. This activation function just\n",
        "    return the value it gets.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self): pass\n",
        "\n",
        "    \n",
        "    def __val(self, matrix):\n",
        "        '''\n",
        "        This private method gets a matrix and uses the activity function on that.\n",
        "        As this is an identical activity function, it just \n",
        "        returns np.matrix of the input.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                identical_value: np.matrix of input with float datatypes\n",
        "        '''\n",
        "        identical_value = np.matrix(matrix, dtype=float)\n",
        "        return identical_value\n",
        "\n",
        "    def derivative(self, matrix):\n",
        "        '''\n",
        "        This method returns the derivation of the input.\n",
        "        As the derivation of x is one, this method returns\n",
        "        a matrix of one with the shape of the input matrix.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                identical_derivative: np.matrix of ones with matrix shape\n",
        "        '''\n",
        "        temp = np.matrix(matrix, dtype=float)\n",
        "        identical_derivative = np.matrix(np.full(np.shape(temp), 1.))\n",
        "        return identical_derivative\n",
        "    \n",
        "    def __call__(self, matrix):\n",
        "        '''\n",
        "        __call__ is a special function in Python that, when implemented inside a class,\n",
        "        gives its instances (objects) the ability to behave like a function.\n",
        "        Here we return the _value method output.\n",
        "            \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                __val(matrix): __val return value for the input matrix\n",
        "        '''\n",
        "        return self.__val(matrix)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ8vt0m7GRk7"
      },
      "outputs": [],
      "source": [
        "class Relu:\n",
        "    '''\n",
        "    This is the Relu activation function. \n",
        "    The rectified linear activation function or ReLU for short\n",
        "    is a piecewise linear function that will output the input directly\n",
        "    if it is positive, otherwise, it will output zero.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self): pass\n",
        "\n",
        "    \n",
        "    def __val(self, matrix):\n",
        "        '''\n",
        "        This private method gets a matrix and uses the activity function on that.\n",
        "        It will set 0 in the matrix if the value is less than 0 else, it returns the value itself.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                relu_value: np.matrix of relu activation function result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        temp = np.matrix(matrix, dtype=float)\n",
        "        relu_value = np.maximum(0, temp)\n",
        "        return relu_value\n",
        "\n",
        "    def derivative(self, matrix):\n",
        "        '''\n",
        "        Returns the derivation value of relu function on input matrix.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                relu_derivative: np.matrix of relu activation function derivation result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        temp = np.matrix(matrix, dtype=float)\n",
        "        relu_derivative = np.matrix(np.full(np.shape(temp), np.where(temp >= 0, 1, 0)))\n",
        "\n",
        "        return relu_derivative\n",
        "    \n",
        "    def __call__(self, matrix):\n",
        "        '''\n",
        "        __call__ is a special function in Python that, when implemented inside a class,\n",
        "        gives its instances (objects) the ability to behave like a function.\n",
        "        Here we return the _relu method output.\n",
        "            \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                __relu(matrix): __relu return value for the input matrix\n",
        "        '''\n",
        "        return self.__val(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVN119zjHh5H"
      },
      "outputs": [],
      "source": [
        "class LeakyRelu:\n",
        "    '''\n",
        "    This is the Leaky Relu activation function. \n",
        "    Leaky Rectified Linear Unit, or Leaky ReLU,\n",
        "    is a type of activation function based on a ReLU,\n",
        "    but it has a small slope for negative values instead\n",
        "    of a flat slope.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, negative_slope=0.01):\n",
        "        '''\n",
        "        This is the constructor.\n",
        "        It sets negative_slope field.\n",
        "            Parameters:\n",
        "                negative_slope: slope for negative input values\n",
        "        '''\n",
        "        self.negative_slope = 0.01\n",
        "    \n",
        "    def __val(self, matrix):\n",
        "        '''\n",
        "        This private method gets a matrix and uses the activity function on that.\n",
        "        It will set negative_slope*value in the matrix if the value is less than 0, else it\n",
        "        returns the value itself.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                relu_value: np.matrix of relu activation function result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        pre_leacky_relu_value=np.matrix(matrix, dtype=float)\n",
        "        leacky_relu_value = np.where(pre_leacky_relu_value < 0, pre_leacky_relu_value * self.negative_slope, pre_leacky_relu_value)\n",
        "            \n",
        "        return leacky_relu_value\n",
        "\n",
        "    def derivative(self, matrix):\n",
        "        '''\n",
        "        Returns the derivation value of leaky relu function on input matrix.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                leacky_relu_derivative: np.matrix of leaky relu activation function derivation result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        pre_leacky_relu_value = np.matrix(matrix, dtype=float)\n",
        "        leaky_relu_derivative = np.matrix(np.full(np.shape(pre_leacky_relu_value), np.where(pre_leacky_relu_value >= 0, 1, self.negative_slope)))\n",
        "        return leaky_relu_derivative\n",
        "    \n",
        "    def __call__(self, matrix):\n",
        "        '''\n",
        "        __call__ is a special function in Python that, when implemented inside a class,\n",
        "        gives its instances (objects) the ability to behave like a function.\n",
        "        Here we return the _val method output.\n",
        "            \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                __val(matrix): __val return value for the input matrix\n",
        "        '''\n",
        "        return self.__val(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7czelWxIo0l"
      },
      "outputs": [],
      "source": [
        "class Sigmoid:\n",
        "    '''\n",
        "    A sigmoid function is a mathematical function having a\n",
        "    characteristic \"S\"-shaped curve or sigmoid curve.\n",
        "    It return S(x)=1/(1+e^-x)\n",
        "    '''\n",
        "    \n",
        "    def __init__(self): pass\n",
        "\n",
        "    def __val(self, matrix):\n",
        "        '''\n",
        "        Returns 1/(1+e^-x) of values\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                sigmoid_value: np.matrix of relu activation function result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        sigmoid_value= np.matrix(1/(1 + np.exp(-matrix)), dtype = float)\n",
        "\n",
        "        return sigmoid_value\n",
        "\n",
        "    def derivative(self, matrix):\n",
        "        '''\n",
        "        Returns the derivation value of sigmoid function on input matrix.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                sigmoid_derivative: np.matrix of sigmoid activation function derivation result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        _sigmoid=self.__val(matrix)\n",
        "        sigmoid_derivative=np.multiply(_sigmoid, np.matrix(1 - _sigmoid))\n",
        "\n",
        "        return sigmoid_derivative\n",
        "    \n",
        "    def __call__(self, matrix):\n",
        "        '''\n",
        "        __call__ is a special function in Python that, when implemented inside a class,\n",
        "        gives its instances (objects) the ability to behave like a function.\n",
        "        Here we return the _val method output.\n",
        "            \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                __val(matrix): __val return value for the input matrix\n",
        "        '''\n",
        "        return self.__val(matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NWhh7btJIKs"
      },
      "outputs": [],
      "source": [
        "class Softmax:\n",
        "    '''\n",
        "    The softmax function, also known as softargmaxâ€Š or normalized\n",
        "    exponential function is a generalization of the logistic\n",
        "    function to multiple dimensions. It is used in multinomial logistic\n",
        "    regression and is often used as the last activation function of a neural\n",
        "    network to normalize the output of a network to a probability distribution\n",
        "    over predicted output classes, based on Luce's choice axiom.\n",
        "    Softmax return (e^x_i / (Î£e^x_j for j = 1, ..., J))\n",
        "    '''\n",
        "        \n",
        "    def __init__(self): pass\n",
        "\n",
        "\n",
        "    def __val(self, matrix):\n",
        "        '''\n",
        "        This private method gets a matrix and uses the softmax on that.\n",
        "        Softmax return (e^x_i / (Î£e^x_j for j = 1, ..., J))\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                relu_value: np.matrix of relu activation function result\n",
        "        '''\n",
        "        # TODO: Implement 1 \n",
        "        #row_num=matrix.shape\n",
        "        #softmax_value = np.zeros(matrix.shape)\n",
        "        #for i in range(0, len(matrix)):\n",
        "        #    softmax_value[i] = np.exp(matrix[i] - np.max(matrix[i]))\n",
        "        #    softmax_value[i] /= np.sum(softmax_value[i])\n",
        "\n",
        "\n",
        "        #implement 2\n",
        "        matrix -= matrix.max(1)\n",
        "\n",
        "        \n",
        "        softmax_value = np.matrix(np.exp(matrix)/np.exp(matrix).sum(1), dtype=float)\n",
        "        \n",
        "        return softmax_value\n",
        "    \n",
        "    def __call__(self, matrix):\n",
        "        '''\n",
        "        __call__ is a special function in Python that, when implemented inside a class,\n",
        "        gives its instances (objects) the ability to behave like a function.\n",
        "        Here we return the _val method output.\n",
        "            \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                __val(matrix): __val return value for the input matrix\n",
        "        '''\n",
        "        return self.__val(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp17YREgJjO7"
      },
      "outputs": [],
      "source": [
        "class Tanh:\n",
        "    \n",
        "    def __init__(self): pass\n",
        "\n",
        "\n",
        "    def __val(self, matrix):\n",
        "        '''\n",
        "        This private method gets a matrix and uses the activity function on that.\n",
        "        It performs Tanh on the values.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                tanh_value: np.matrix of Tanh activation function result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        tanh_value = np.tanh(matrix)\n",
        "        return tanh_value\n",
        "\n",
        "    def derivative(self, matrix):\n",
        "        '''\n",
        "        Returns the derivation value of Tanh function on input matrix.\n",
        "        \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                sigmoid_derivative: np.matrix of Tanh activation function derivation result\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        a=np.tanh(matrix)\n",
        "        tanh_derivative=1-np.power(a, 2)\n",
        "        return tanh_derivative\n",
        "    \n",
        "    def __call__(self, matrix):\n",
        "        '''\n",
        "        __call__ is a special function in Python that, when implemented inside a class,\n",
        "        gives its instances (objects) the ability to behave like a function.\n",
        "        Here we return the _val method output.\n",
        "            \n",
        "            Parameters:\n",
        "                matrix: np.matrix of values\n",
        "            Returns:\n",
        "                __val(matrix): __val return value for the input matrix\n",
        "        '''\n",
        "        return self.__val(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4jsFyGaJzpl"
      },
      "outputs": [],
      "source": [
        "class CrossEntropy: #(with softmax)\n",
        "    '''\n",
        "    Cross-entropy is a measure of the difference between two probability\n",
        "    distributions for a given random variable or set of events. You might\n",
        "    recall that information quantifies the number of bits required to encode\n",
        "    and transmit an event.\n",
        "    The above image can help you.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self): pass\n",
        "\n",
        "\n",
        "    def __val(self, true_val, expected_val):\n",
        "        '''\n",
        "        L(y^, y) = - Î£ (y^(k)log (y^)^(k)) for k in K\n",
        "        Parameters:\n",
        "            true_val: calculated values (generated by neural network)\n",
        "            expected_val: real values in dataset\n",
        "        Returns:\n",
        "            cross_entropy_value: cross entropy of inputs\n",
        "        '''\n",
        "\n",
        "        assert np.shape(true_val)==np.shape(expected_val)\n",
        "        \n",
        "        soft_true = Softmax()(true_val)\n",
        "        \n",
        "        cross_entropy_value = -np.multiply(expected_val, np.ma.log(soft_true)).sum(1)\n",
        "        \n",
        "        return cross_entropy_value\n",
        "        \n",
        "    def derivative(self, true_val, expected_val):\n",
        "        '''\n",
        "        Returns derivation of cross entropy.\n",
        "            Parameters:\n",
        "                true_val: calculated values (generated by neural network)\n",
        "                expected_val: real values in dataset\n",
        "            Returns:\n",
        "                cross_entropy_derivative: cross entropy derivation of inputs\n",
        "        '''\n",
        "        assert np.shape(true_val)==np.shape(expected_val)\n",
        "        # TODO: Implement 1\n",
        "        #temp_true = np.matrix(true_val, dtype=float)\n",
        "        #temp_expected=np.matrix(expected_val, dtype=float)\n",
        "\n",
        "        #implent 2\n",
        "        true_val_soft=Softmax()(true_val)\n",
        "        cross_entropy_derivative=true_val_soft-expected_val\n",
        "        return cross_entropy_derivative\n",
        "    \n",
        "    def __call__(self, true_val, expected_val):\n",
        "        '''\n",
        "        __call__ is a special function in Python that, when implemented inside a class,\n",
        "        gives its instances (objects) the ability to behave like a function.\n",
        "        Here we return the _val method output.\n",
        "            \n",
        "            Parameters:\n",
        "                true_val: calculated values (generated by neural network)\n",
        "                expected_val: real values in dataset\n",
        "            Returns:\n",
        "                __val(matrix): __val return value for the input matrix\n",
        "        '''\n",
        "\n",
        "        return self.__val(true_val, expected_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EiQKoczLPZv"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    '''\n",
        "    The layer class is used to define neural network layers.\n",
        "    It stores all needed information for each layer, such as neurons count,\n",
        "    weight matrix, bias, the output after applying the activation function, etc.\n",
        "    '''\n",
        "\n",
        "    DEFAULT_LOW, DEFAULT_HIGH, DEFAULT_MEAN, DEFAULT_VAR = 0, 0.05, 0., 1.\n",
        "  \n",
        "    def __init__(self, input_size, output_size, activation=Identical(), initial_weight='uniform', \n",
        "                 **initializing_parameters):\n",
        "        '''\n",
        "        Parameters:\n",
        "            input_size: the size of the input of this layer.\n",
        "            output_size: the size of the output after this layer.\n",
        "            activation: the activation function. It can be initialized to either of the previously defined activation classes.\n",
        "                               default is an Identical activation function.\n",
        "            initial_weight: either normal or uniform. It defines the method for weight initialization.\n",
        "        '''\n",
        "        \n",
        "        assert type(initial_weight)==str, 'Undefined activation function!'\n",
        "        \n",
        "        self.__weight_initializer_dict = {'uniform':self.__uniform_weight, 'normal':self.__normal_weight}\n",
        "        \n",
        "        assert initial_weight in self.__weight_initializer_dict, 'Undefined weight initialization function!'\n",
        "\n",
        "\n",
        "        self.__n_neurons = output_size\n",
        "        weight_initializer = self.__weight_initializer_dict[initial_weight]\n",
        "        self.__weight = weight_initializer(input_size, self.__n_neurons, **initializing_parameters)\n",
        "        self.__bias = weight_initializer(1, self.__n_neurons, **initializing_parameters)\n",
        "        self.__activation = activation\n",
        "        \n",
        "        self.__last_input = None\n",
        "        self.__last_activation_input = None\n",
        "        self.__last_activation_output = None\n",
        "        self.__last_activation_derivative = None\n",
        "        \n",
        "    def forward(self, layer_input):\n",
        "        '''\n",
        "        It calculates the output of this layer for the layer_input argument.\n",
        "        This method also stores __last_input, __last_activation_input, and __last_activation_derivative\n",
        "        for future use in backpropagation.\n",
        "        Parameters:\n",
        "            layer_input: 2d np.matrix representing the input matrix of this layer.\n",
        "        Returns:\n",
        "            Final output of this layer after applying the activation function.\n",
        "        '''\n",
        "        assert np.ndim(layer_input)==2\n",
        "        assert np.size(self.__weight,0) == np.size(layer_input,1)\n",
        "        #print(\"sizdah\",layer_input)\n",
        "\n",
        "        \n",
        "        # TODO: Implement 1\n",
        "        #self.__last_input=np.matrix(layer_input, dtype=float)\n",
        "        #temp_mult=(layer_input@self.__weight)\n",
        "        #self.__last_activation_input=np.add(temp_mult,self.__bias)\n",
        "        #self.__last_activation_derivative=self.__activation.derivative(self.__last_activation_input)\n",
        "        #self.__last_activation_output=self.__activation(self.__last_activation_input)\n",
        "\n",
        "\n",
        "\n",
        "        #new implement \n",
        "        self.__last_input = layer_input\n",
        "        self.__last_activation_input =  (layer_input@self.__weight)+self.__bias\n",
        "        self.__last_activation_output = self.__activation(self.__last_activation_input)\n",
        "        self.__last_activation_derivative = self.__activation.derivative(self.__last_activation_input)\n",
        "        return self.__last_activation_output\n",
        "        \n",
        "    \n",
        "    def update_weights(self, backprop_tensor, lr):\n",
        "        '''\n",
        "        It updates Layer weights according to the backpropagation matrix and learning rate.\n",
        "        This method updates bias values as well.\n",
        "        Parameters:\n",
        "            backprop_tensor: 2d np.matrix passed from the next layer containing gradient values.\n",
        "            lr: learning rate\n",
        "        Returns:\n",
        "            backprop_tensor to be used by the previous layer.\n",
        "        '''\n",
        "        assert np.ndim(backprop_tensor)==2\n",
        "        assert np.size(backprop_tensor,0) == np.size(self.__last_activation_derivative,0)\n",
        "        assert np.size(backprop_tensor,1) == self.__n_neurons\n",
        "        # TODO: Implement\n",
        "        inputT = self.__last_input.transpose()\n",
        "        dy = np.multiply(backprop_tensor, self.__last_activation_derivative)\n",
        "        dw = np.matmul(inputT, dy)\n",
        "        backprop_tensor = np.matmul(dy, self.__weight.transpose())\n",
        "        self.__weight -= dw * lr\n",
        "        db = np.matmul(np.matrix(np.tile(1, (1, dy.shape[0]))), dy)\n",
        "        self.__bias -= db * lr\n",
        "        \n",
        "        \n",
        "        return backprop_tensor\n",
        "\n",
        "    def __uniform_weight(self, dim1, dim2, **initializing_parameters):\n",
        "        '''\n",
        "        Initializes weights as a uniform distribution between low and high values.\n",
        "        It uses default low and high values unless low or high are passed in initializing_parameters.\n",
        "        Parameters:\n",
        "            dim1: the size of the first dimension of weights.\n",
        "            dim2: the size of the second dimension of weights.\n",
        "            initializing_parameters: other initializing parameters; it can include custom low or high values.\n",
        "        Returns:\n",
        "            np.matrix with size (dim1, dim2) initialized using uniformly distributed values.\n",
        "        '''\n",
        "        low, high = self.DEFAULT_LOW, self.DEFAULT_HIGH\n",
        "        if 'low' in initializing_parameters.keys(): low = initializing_parameters['low']\n",
        "        if 'high' in initializing_parameters.keys(): high = initializing_parameters['high']\n",
        "        # TODO: Implement\n",
        "        weights=np.random.uniform(low=low, high=high, size=(dim1, dim2))\n",
        "        return weights\n",
        "\n",
        "    def __normal_weight(self, dim1, dim2, **initializing_parameters):\n",
        "        '''\n",
        "        Initializes weights as a normal distribution with mean and var values.\n",
        "        It uses default mean and variance values unless mean or var are passed in initializing_parameters.\n",
        "        Parameters:\n",
        "            dim1: the size of the first dimension of weights.\n",
        "            dim2: the size of the second dimension of weights.\n",
        "            initializing_parameters: other initializing parameters; it can include custom mean or var values.\n",
        "        Returns:\n",
        "            np.matrix with size (dim1, dim2) initialized using normaly distributed values.\n",
        "        ''' \n",
        "        mean, var = self.DEFAULT_MEAN, self.DEFAULT_VAR\n",
        "        if 'mean' in initializing_parameters.keys(): mean = initializing_parameters['mean']\n",
        "        if 'var' in initializing_parameters.keys(): var = initializing_parameters['var']\n",
        "        # TODO: Implement\n",
        "        _std=np.sqrt(var)\n",
        "        weights=np.random.uniform(loc=mean,scale=_std , size=(dim1, dim2))\n",
        "        return weights\n",
        "    \n",
        "    @property\n",
        "    def n_neurons(self): return self.__n_neurons\n",
        "    \n",
        "    @property\n",
        "    def weight(self): return self.__weight\n",
        "    \n",
        "    @property\n",
        "    def bias(self): return self.__bias\n",
        "    \n",
        "    @property\n",
        "    def activation(self): return self.__activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kntKPVj5R1k3"
      },
      "outputs": [],
      "source": [
        "class FeedForwardNN:\n",
        "    '''\n",
        "    This class is used in order to implement custom feed-forward neural networks.\n",
        "    The FeedForwardNN class stores a list of layers that determines all network layers.\n",
        "    It also consists of the learning rate and loss function.\n",
        "    '''\n",
        "    def __init__(self, input_shape):\n",
        "        '''\n",
        "        Parameters:\n",
        "            input_shape: the size of the first input to our neural network.\n",
        "        '''\n",
        "        \n",
        "        self.__input_shape = input_shape\n",
        "        self.__output_shape = None\n",
        "        \n",
        "        self.__layers_list = []\n",
        "        \n",
        "        self.__lr = None\n",
        "        self.__loss = None\n",
        "\n",
        "        \n",
        "    def add_layer(self, n_neurons, activation=Relu(), initial_weight='uniform', **initializing_parameters):\n",
        "        '''\n",
        "         This method adds a new custom layer to the layers_list.\n",
        "         Parameters:\n",
        "             n_neurons: number of neurons in this layer\n",
        "             activation: the activation function of this layer, default is Relu\n",
        "             initial_weight: either a uniform or normal, default is uniform\n",
        "             initializing_parameters: other initializing parameters such as low, high, mean, var, etc\n",
        "        '''\n",
        "         \n",
        "        assert type(n_neurons)==int, \"Invalid number of neurons for the layer!\"\n",
        "        assert n_neurons>0, \"Invalid number of neurons for the layer!\"\n",
        "        \n",
        "        n_prev_neurons = self.__input_shape if len(self.__layers_list)==0 else self.__layers_list[-1].n_neurons\n",
        "        new_layer = Layer(n_prev_neurons, n_neurons, activation, initial_weight, **initializing_parameters)\n",
        "        self.__layers_list.append(new_layer)\n",
        "        self.__output_shape = self.__layers_list[-1].n_neurons \n",
        "      \n",
        "    \n",
        "    def set_training_param(self, loss=CrossEntropy(), lr=1e-3):\n",
        "        '''\n",
        "        This method is used to set training parameters.\n",
        "        Parameters:\n",
        "            loss: loss function, default is CrossEntropy\n",
        "            lr: learning rate, default is 1e-3\n",
        "        '''\n",
        "        assert self.__layers_list, \"Uncomplete model!\"\n",
        "        self.__loss = loss\n",
        "        self.__lr = lr\n",
        "    \n",
        "    \n",
        "    def forward(self, network_input):\n",
        "        '''\n",
        "        This method calculates the output of the complete neural network for a passed input.\n",
        "        Parameters:\n",
        "            network_input: input of the neural network\n",
        "        Returns:\n",
        "            network_output: output of the neural network after forwarding the network_input\n",
        "        '''\n",
        "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
        "        network_output = network_input\n",
        "\n",
        "        for layer in self.__layers_list:\n",
        "            network_output = layer.forward(network_output)\n",
        " \n",
        "        return network_output\n",
        "    \n",
        "    \n",
        "    def fit(self, epochs, trainloader, testloader=None, print_results=True):\n",
        "        '''\n",
        "        This method trains the neural network using specified parameters.\n",
        "        It runs the __train private method epoch times and fills the log dictionary.\n",
        "        Parameters:\n",
        "            epochs: number of epochs to run\n",
        "            trainloader: DataLoader for train data\n",
        "            testloader: DataLoader for test data\n",
        "            print_results: whether or not to print the results\n",
        "        Returns:\n",
        "            log: complete log of the training process as a dictionary consisting of\n",
        "            train_accuracy, train_loss, test_accuracy, test_loss\n",
        "        '''\n",
        "        \n",
        "        assert type(self.__output_shape) != None, \"Model is not compiled!\"\n",
        "        assert type(self.__lr) != None and type(self.__loss) != None, \"Training paramenters are not set!\"\n",
        "\n",
        "        log = {\"train_accuracy\":[], \"train_loss\":[], \"test_accuracy\":[], \"test_loss\":[]}\n",
        "        \n",
        "        for epoch in range(1, epochs+1):\n",
        "            \n",
        "            if print_results: \n",
        "                print('Epoch {}:'.format(epoch)) \n",
        "                \n",
        "            average_accuracy, average_loss = self.__train(trainloader)\n",
        "            log['train_accuracy'].append(average_accuracy)\n",
        "            log['train_loss'].append(average_loss)\n",
        "            if print_results:\n",
        "                print('\\tTrain: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
        "            \n",
        "            if type(testloader) != type(None):\n",
        "                average_accuracy, average_loss = self.__test(testloader)\n",
        "                log['test_accuracy'].append(average_accuracy)\n",
        "                log['test_loss'].append(average_loss)\n",
        "                if print_results:\n",
        "                    print('\\tTest: Average Accuracy: {}\\tAverage Loss: {}'.format(average_accuracy, average_loss))\n",
        "                    \n",
        "        return log\n",
        "    \n",
        "    \n",
        "    def __train(self, trainloader):\n",
        "        '''\n",
        "        Trains the neural network for one epoch.\n",
        "        Parameters:\n",
        "            trainloader: A DataLoader consisting of train data\n",
        "        Returns:\n",
        "            batch_accuracy, batch_loss: mean of all batch_accuracies, batch_losses\n",
        "        '''\n",
        "        bach_accuracies, batch_losses = [], []\n",
        "        for x_train, y_train in trainloader:\n",
        "            \n",
        "            batch_accuracy, batch_loss = self.__train_on_batch(x_train, y_train)\n",
        "            bach_accuracies.append(batch_accuracy)\n",
        "            batch_losses.append(batch_loss)\n",
        "        \n",
        "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
        "    \n",
        "    \n",
        "    def __test(self, testloader):\n",
        "        '''\n",
        "        Test the neural network using a testloader.\n",
        "        Parameters:\n",
        "            testloader: A DataLoader of test data\n",
        "        Returns:\n",
        "            batch_accuracy, batch_loss: mean of all batch_accuracies, batch_losses\n",
        "        '''\n",
        "        bach_accuracies, batch_losses = [], []\n",
        "        for x_test, y_test in testloader:\n",
        "            batch_accuracy, batch_loss = self.__test_on_batch(x_test, y_test)\n",
        "            bach_accuracies.append(batch_accuracy)\n",
        "            batch_losses.append(batch_loss)\n",
        "        return np.mean(bach_accuracies), np.mean(batch_losses)\n",
        "\n",
        "    \n",
        "    def __train_on_batch(self, x_batch, y_batch):\n",
        "        '''\n",
        "        Trains the neural network for one batch of train data.\n",
        "        Parameters:\n",
        "            x_batch: one batch data\n",
        "            y_batch: labels for one batch\n",
        "        Returns:\n",
        "            (batch_accuracy, batch_average_loss)\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "\n",
        "        #result=self.forward(x_batch)        \n",
        "        #batch_accuracy=self.__compute_accuracy(result,y_batch)\n",
        "        #batch_average_loss=np.mean(self.__loss(result, y_batch))\n",
        "        #self.__update_weights(result, y_batch)\n",
        "\n",
        "        ###new_implement\n",
        "\n",
        "        out = self.forward(x_batch)\n",
        "        aaaa=self.__update_weights(out, y_batch)\n",
        "        return (self.__compute_accuracy(out,y_batch),aaaa )\n",
        "        \n",
        "        \n",
        "    def __test_on_batch(self, x_batch, y_batch):\n",
        "        '''\n",
        "        Tests the neural network for one batch of test data.\n",
        "        Parameters:\n",
        "            x_batch: one batch data\n",
        "            y_batch: labels for one batch\n",
        "        Returns:\n",
        "            (batch_accuracy, batch_average_loss)\n",
        "        '''  \n",
        "        # TODO: Implement\n",
        "        result=self.forward(x_batch)\n",
        "        batch_accuracy=self.__compute_accuracy(result,y_batch)\n",
        "\n",
        "        batch_average_loss=np.mean(self.__loss(result, y_batch))\n",
        "        return (batch_accuracy, batch_average_loss)\n",
        "            \n",
        "        \n",
        "    def __get_labels(self, outputs):\n",
        "        '''\n",
        "        Parameters:\n",
        "            outputs: output of the neural network\n",
        "        Returns:\n",
        "            labels: labels generated from the outputs of the neural network\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        labels=outputs.argmax(1)\n",
        "        return labels\n",
        "    \n",
        "    \n",
        "    def __compute_accuracy(self, output, expected_output):\n",
        "        '''\n",
        "        Computes accuracy by comparing output and expected_output.\n",
        "        Parameters:\n",
        "            output: actual output of the neural network\n",
        "            expected_output: expected output\n",
        "        Returns:\n",
        "            accuracy\n",
        "        '''\n",
        "        # TODO: Implement\n",
        "        output_labels=self.__get_labels(output)\n",
        "        expected_labels=self.__get_labels(expected_output)\n",
        "        correct_predictions=(output_labels==expected_labels).sum()\n",
        "        accuracy=correct_predictions/(expected_output.shape[0])\n",
        "        return accuracy\n",
        "    \n",
        "    \n",
        "    def __update_weights(self, output, y_train):\n",
        "        '''\n",
        "        Updates weights of all layers according to neural network output and labels.\n",
        "        Parameters:\n",
        "            output: output of the neural network\n",
        "            y_train: y labels for one batch of train data\n",
        "        Returns:\n",
        "            None\n",
        "        '''\n",
        "\n",
        "        \n",
        "        # TODO: Implement without output version\n",
        "        #grd=self.__loss.derivative(output, y_train)\n",
        "        #for layer in reversed(self.__layers_list):\n",
        "        #    grd = layer.update_weights(grd, self.__lr)\n",
        "        #return\n",
        "\n",
        "        #new_implement with putput version\n",
        "\n",
        "        cross_entropy = CrossEntropy()\n",
        "        batch_loss = cross_entropy(output, y_train)\n",
        "        batch_average_loss = np.sum(batch_loss)/len(output)\n",
        "        this_val = cross_entropy.derivative(output, y_train)\n",
        "        for i in reversed(self.__layers_list):\n",
        "            this_val = i.update_weights(this_val, self.__lr)\n",
        "        return batch_average_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Classification"
      ],
      "metadata": {
        "id": "Zpxi4tCb32By"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LJg_cdgnUTii",
        "outputId": "7461c88d-3ff4-4a02-e570-cde53975ba0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1e77d607-f2ec-42ef-986d-027280c978dc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13339</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13340</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13341</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13342</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13343</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7680 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e77d607-f2ec-42ef-986d-027280c978dc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e77d607-f2ec-42ef-986d-027280c978dc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e77d607-f2ec-42ef-986d-027280c978dc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       label\n",
              "0          1\n",
              "1          1\n",
              "2          1\n",
              "3          1\n",
              "4          1\n",
              "...      ...\n",
              "13339     16\n",
              "13340     16\n",
              "13341     16\n",
              "13342     16\n",
              "13343     16\n",
              "\n",
              "[7680 rows x 1 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_labels=train_label_df.loc[train_label_df['label'].isin(allowed_labels)]\n",
        "selected_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "XMgsv_ZjUWu-",
        "outputId": "cb26a7a3-be31-4750-ba79-9eef01e2d2b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5500a165-1b05-41aa-b62b-6aa9dcd92640\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3331</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3333</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3334</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3335</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1920 rows Ã— 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5500a165-1b05-41aa-b62b-6aa9dcd92640')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5500a165-1b05-41aa-b62b-6aa9dcd92640 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5500a165-1b05-41aa-b62b-6aa9dcd92640');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      label\n",
              "0         1\n",
              "1         1\n",
              "2         2\n",
              "3         2\n",
              "4         3\n",
              "...     ...\n",
              "3331     14\n",
              "3332     15\n",
              "3333     15\n",
              "3334     16\n",
              "3335     16\n",
              "\n",
              "[1920 rows x 1 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_labels_test=test_label_df.loc[test_label_df['label'].isin(allowed_labels)]\n",
        "selected_labels_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part 1 : training a network \n",
        "\n",
        "we use given in the project description"
      ],
      "metadata": {
        "id": "PondbbTv4rRY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aPV37mWT-cz",
        "outputId": "03e882de-a1d4-4d76-ecc9-ba980e257590"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7680, 1024)\n",
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.11692708333333333\tAverage Loss: 2.6896217705735017\n",
            "\tTest: Average Accuracy: 0.309375\tAverage Loss: 2.115328297973075\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.3287760416666667\tAverage Loss: 1.94638382414692\n",
            "\tTest: Average Accuracy: 0.39375\tAverage Loss: 1.7392925757591338\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.42721354166666664\tAverage Loss: 1.618488381628172\n",
            "\tTest: Average Accuracy: 0.45208333333333334\tAverage Loss: 1.5460156727959282\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.48541666666666666\tAverage Loss: 1.4132202719868465\n",
            "\tTest: Average Accuracy: 0.5005208333333333\tAverage Loss: 1.4017269683562634\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.5291666666666667\tAverage Loss: 1.2774126905662895\n",
            "\tTest: Average Accuracy: 0.5265625\tAverage Loss: 1.314453683617064\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.5657552083333334\tAverage Loss: 1.1694791598698415\n",
            "\tTest: Average Accuracy: 0.5333333333333333\tAverage Loss: 1.2727419794416448\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.596484375\tAverage Loss: 1.0808822066011627\n",
            "\tTest: Average Accuracy: 0.5494791666666666\tAverage Loss: 1.2296635605007546\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.6212239583333333\tAverage Loss: 0.9982636875326415\n",
            "\tTest: Average Accuracy: 0.5703125\tAverage Loss: 1.1782318137445247\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.6513020833333333\tAverage Loss: 0.9258699744604262\n",
            "\tTest: Average Accuracy: 0.5911458333333334\tAverage Loss: 1.1437664996353734\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.6759114583333333\tAverage Loss: 0.8610655554297779\n",
            "\tTest: Average Accuracy: 0.603125\tAverage Loss: 1.119962107165994\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.69921875\tAverage Loss: 0.8055690671342322\n",
            "\tTest: Average Accuracy: 0.61875\tAverage Loss: 1.1032653347709962\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.7203125\tAverage Loss: 0.7536257521862034\n",
            "\tTest: Average Accuracy: 0.6260416666666667\tAverage Loss: 1.096972788827589\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.7380208333333333\tAverage Loss: 0.7080227103868512\n",
            "\tTest: Average Accuracy: 0.6328125\tAverage Loss: 1.083520691929347\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.7553385416666667\tAverage Loss: 0.6686084851931684\n",
            "\tTest: Average Accuracy: 0.6442708333333333\tAverage Loss: 1.0687007585783554\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.773828125\tAverage Loss: 0.6345464895020055\n",
            "\tTest: Average Accuracy: 0.6536458333333334\tAverage Loss: 1.0681239571424554\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.7888020833333333\tAverage Loss: 0.5878300405861359\n",
            "\tTest: Average Accuracy: 0.65625\tAverage Loss: 1.0610955337119652\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.8010416666666667\tAverage Loss: 0.5588944617480051\n",
            "\tTest: Average Accuracy: 0.6640625\tAverage Loss: 1.0608356186976187\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.8200520833333333\tAverage Loss: 0.5133770416045788\n",
            "\tTest: Average Accuracy: 0.6661458333333333\tAverage Loss: 1.061813996116708\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.8373697916666667\tAverage Loss: 0.4783261436783802\n",
            "\tTest: Average Accuracy: 0.6723958333333333\tAverage Loss: 1.0556150095385621\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.8444010416666666\tAverage Loss: 0.4561787628638277\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 1.0524950077305961\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.8536458333333333\tAverage Loss: 0.42721949201731196\n",
            "\tTest: Average Accuracy: 0.6786458333333333\tAverage Loss: 1.0604168317445701\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.8661458333333333\tAverage Loss: 0.39703100526310614\n",
            "\tTest: Average Accuracy: 0.6848958333333334\tAverage Loss: 1.0663434743992863\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.8854166666666666\tAverage Loss: 0.35966916534034027\n",
            "\tTest: Average Accuracy: 0.6916666666666667\tAverage Loss: 1.0713389854942494\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.890625\tAverage Loss: 0.3435213141998844\n",
            "\tTest: Average Accuracy: 0.6875\tAverage Loss: 1.0659462723163495\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.9002604166666667\tAverage Loss: 0.31709096009893994\n",
            "\tTest: Average Accuracy: 0.6875\tAverage Loss: 1.0613331210884953\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.9138020833333333\tAverage Loss: 0.29512774370596373\n",
            "\tTest: Average Accuracy: 0.6854166666666667\tAverage Loss: 1.0887647896125934\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.9162760416666667\tAverage Loss: 0.27933505278106535\n",
            "\tTest: Average Accuracy: 0.6911458333333333\tAverage Loss: 1.077639616958748\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.9255208333333333\tAverage Loss: 0.25511885628015285\n",
            "\tTest: Average Accuracy: 0.6911458333333333\tAverage Loss: 1.0923607263975272\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.93203125\tAverage Loss: 0.23773388751309102\n",
            "\tTest: Average Accuracy: 0.6916666666666667\tAverage Loss: 1.1116442181648354\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.935546875\tAverage Loss: 0.22944555638114475\n",
            "\tTest: Average Accuracy: 0.6921875\tAverage Loss: 1.1129168215282659\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.9453125\tAverage Loss: 0.20657671793931076\n",
            "\tTest: Average Accuracy: 0.6963541666666667\tAverage Loss: 1.1303613289809098\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.95234375\tAverage Loss: 0.18966949109321782\n",
            "\tTest: Average Accuracy: 0.6953125\tAverage Loss: 1.1368060419061305\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.9572916666666667\tAverage Loss: 0.17860670184825994\n",
            "\tTest: Average Accuracy: 0.696875\tAverage Loss: 1.1481054687967573\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.9626302083333333\tAverage Loss: 0.16366817509368728\n",
            "\tTest: Average Accuracy: 0.7046875\tAverage Loss: 1.1571791889440852\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.9638020833333333\tAverage Loss: 0.15527341107293752\n",
            "\tTest: Average Accuracy: 0.7026041666666667\tAverage Loss: 1.1568891529669598\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.965234375\tAverage Loss: 0.148994629728321\n",
            "\tTest: Average Accuracy: 0.7078125\tAverage Loss: 1.1756104565599454\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.9506510416666667\tAverage Loss: 0.1893794195733354\n",
            "\tTest: Average Accuracy: 0.703125\tAverage Loss: 1.2160098417728693\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.9673177083333333\tAverage Loss: 0.14299761890621313\n",
            "\tTest: Average Accuracy: 0.7083333333333334\tAverage Loss: 1.1948798291093319\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.9756510416666667\tAverage Loss: 0.1197288104664465\n",
            "\tTest: Average Accuracy: 0.7109375\tAverage Loss: 1.1889793400916748\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.9803385416666667\tAverage Loss: 0.11062582457313394\n",
            "\tTest: Average Accuracy: 0.7125\tAverage Loss: 1.1940610948222188\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.9825520833333333\tAverage Loss: 0.10360425805170172\n",
            "\tTest: Average Accuracy: 0.7130208333333333\tAverage Loss: 1.2047875169366298\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.9859375\tAverage Loss: 0.09623979611018997\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.2112131467693898\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.9868489583333333\tAverage Loss: 0.09091169089917063\n",
            "\tTest: Average Accuracy: 0.7130208333333333\tAverage Loss: 1.2232711724823961\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.9889322916666666\tAverage Loss: 0.08580781133314838\n",
            "\tTest: Average Accuracy: 0.7140625\tAverage Loss: 1.2329207077947708\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.98984375\tAverage Loss: 0.08116489619842185\n",
            "\tTest: Average Accuracy: 0.7135416666666666\tAverage Loss: 1.2406080489090583\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.9915364583333334\tAverage Loss: 0.07685052882408519\n",
            "\tTest: Average Accuracy: 0.7140625\tAverage Loss: 1.2492652404696851\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.9927083333333333\tAverage Loss: 0.07303703363479709\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.2638845035626018\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.9938802083333333\tAverage Loss: 0.06934295633584574\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.2695220951565944\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.994140625\tAverage Loss: 0.06610639601049546\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.2790445730465292\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.994921875\tAverage Loss: 0.06305233970396265\n",
            "\tTest: Average Accuracy: 0.7130208333333333\tAverage Loss: 1.29632775721131\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.9955729166666667\tAverage Loss: 0.060205386170217846\n",
            "\tTest: Average Accuracy: 0.7135416666666666\tAverage Loss: 1.302567914465313\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.9959635416666667\tAverage Loss: 0.05750568928065494\n",
            "\tTest: Average Accuracy: 0.7135416666666666\tAverage Loss: 1.312989737294782\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.996484375\tAverage Loss: 0.05493977541467992\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.3200994683490208\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.9971354166666667\tAverage Loss: 0.05256741450504429\n",
            "\tTest: Average Accuracy: 0.7151041666666667\tAverage Loss: 1.3278394096042907\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.9973958333333334\tAverage Loss: 0.050462195639185525\n",
            "\tTest: Average Accuracy: 0.7151041666666667\tAverage Loss: 1.3365814681240897\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.9975260416666667\tAverage Loss: 0.04834242692517885\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.343104296711119\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.9975260416666667\tAverage Loss: 0.04639989117301542\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 1.351773586486981\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.99765625\tAverage Loss: 0.0446128427184836\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.3616179907616164\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.9977864583333333\tAverage Loss: 0.042886491058356714\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.3660086274260086\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.9977864583333333\tAverage Loss: 0.04125187489433409\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 1.3747102051602365\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.998046875\tAverage Loss: 0.0396915193666102\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.3815602497317123\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.9984375\tAverage Loss: 0.0382385950434049\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.3883565731617327\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.9984375\tAverage Loss: 0.0368935329685988\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.3957482746602274\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.9986979166666666\tAverage Loss: 0.03549441222450362\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.399712179586302\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.034374157410571975\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 1.4070314717642145\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.03316432078508238\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.4120394998726344\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.03219852500304359\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.4175689379518448\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.03119889920389108\n",
            "\tTest: Average Accuracy: 0.7151041666666667\tAverage Loss: 1.4231060632687667\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.03016078223215614\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 1.4302981271749653\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.029238596324456703\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.4330454010489304\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.028319405175777593\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.4390633103401202\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.027463094216010547\n",
            "\tTest: Average Accuracy: 0.71875\tAverage Loss: 1.4445272028232532\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.026692673292506144\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 1.4483050008400724\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.02588638428343763\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 1.4530989295022279\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.025167332167855952\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 1.4584534895746406\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.024446897245805378\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 1.4623232779347604\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.023745535744154906\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 1.4671036895575915\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.023153946544241143\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 1.4714246809452454\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.022544225643682685\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.4758686014209383\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.02191167316038566\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 1.4794876802246613\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02137506698596748\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 1.4843130849000195\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02080697817978364\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4876874688728343\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.02028395336472769\n",
            "\tTest: Average Accuracy: 0.7270833333333333\tAverage Loss: 1.4916455706040561\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.019789540679263758\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4944800573350698\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.019283685354165043\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 1.4992228563892598\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.018810593909094783\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 1.5032818157087489\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.018389947225452168\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.5069703880282255\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.01795018650341233\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.5103672095920821\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.01751847037454372\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 1.5131705914262625\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.017126223889976547\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.5182705164917825\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.016732323526585942\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 1.5223104903967741\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.016355138325302332\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 1.525196846101025\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.015995087940180102\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 1.5289957190238714\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.015667363958069325\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.5328791143851952\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.01531237709603696\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.536338379390773\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.01499250491158282\n",
            "\tTest: Average Accuracy: 0.728125\tAverage Loss: 1.5393319524500313\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.014689681848505038\n",
            "\tTest: Average Accuracy: 0.728125\tAverage Loss: 1.5425431072695717\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.014386475893664874\n",
            "\tTest: Average Accuracy: 0.7286458333333333\tAverage Loss: 1.5463292733586609\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.014100201403854533\n",
            "\tTest: Average Accuracy: 0.7286458333333333\tAverage Loss: 1.5494364730036876\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.013807831942348\n",
            "\tTest: Average Accuracy: 0.728125\tAverage Loss: 1.5531877805810455\n"
          ]
        }
      ],
      "source": [
        "# Sample code for building and training a model\n",
        "\n",
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "X_train=selected_train_set\n",
        "Y_train=selected_labels\n",
        "X_test=selected_test_set\n",
        "Y_test=selected_labels_test\n",
        "\n",
        "print(np.shape(X_train))\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network = FeedForwardNN(INPUT_SHAPE)\n",
        "network.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I trained network for multiple times , I used diffrent number of neuron and layers ,Finally the current architechture gives the acceptable result. "
      ],
      "metadata": {
        "id": "brdZJSdb5Iuh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR5tNQqEp8f8"
      },
      "source": [
        "##Part two : Weight Initialization in Neural Network\n",
        "\n",
        "\n",
        "\n",
        "If we used zero initiallization , the performance and accuracy would decrease. The reason is that this method serves almost no purpose as it causes neurons to perform the same calculation in each iterations and produces same outputs.In each iteration we calculate derivations , when weights are initiallized to zero the derivative remains same for each of weights.\n",
        "\n",
        "Totally we can say that using random initallization result in better performances in training model but for random initiallizing we need to consider some points,too.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ihoEZxfuC7q"
      },
      "source": [
        "##Part three : Learning Rate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-OE6sxG_lwoe",
        "outputId": "cd5b86e0-baed-4c05-a568-1ee333dd5515"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 3.3685603153487316\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.7794906687923078\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.9310234457246898\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.0\tAverage Loss: 2.931023445724677\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.779490668792043\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.05\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xtsmDjMExWCP",
        "outputId": "e2d08517-54a0-4df5-a176-b3192bd5d168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.027604166666666666\tAverage Loss: 2.852055679004442\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.7105716186045883\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.052473958333333334\tAverage Loss: 2.7775656608051187\n",
            "\tTest: Average Accuracy: 0.08541666666666667\tAverage Loss: 2.6162720450729484\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.11015625\tAverage Loss: 2.615945550424287\n",
            "\tTest: Average Accuracy: 0.1484375\tAverage Loss: 2.434251646722439\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.16276041666666666\tAverage Loss: 2.427941708678848\n",
            "\tTest: Average Accuracy: 0.24427083333333333\tAverage Loss: 2.2819372740151125\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.245703125\tAverage Loss: 2.2823458888575328\n",
            "\tTest: Average Accuracy: 0.30520833333333336\tAverage Loss: 2.152079628483508\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.3079427083333333\tAverage Loss: 2.1523744979924713\n",
            "\tTest: Average Accuracy: 0.3359375\tAverage Loss: 2.034115691576526\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.35\tAverage Loss: 2.039637973130708\n",
            "\tTest: Average Accuracy: 0.36302083333333335\tAverage Loss: 1.937622391982755\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.378515625\tAverage Loss: 1.9497695494320944\n",
            "\tTest: Average Accuracy: 0.3880208333333333\tAverage Loss: 1.862941149548694\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.39817708333333335\tAverage Loss: 1.8790573412098022\n",
            "\tTest: Average Accuracy: 0.4083333333333333\tAverage Loss: 1.8048182590286361\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.411328125\tAverage Loss: 1.8220080355509902\n",
            "\tTest: Average Accuracy: 0.4244791666666667\tAverage Loss: 1.758491483823881\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.425\tAverage Loss: 1.7745165103553495\n",
            "\tTest: Average Accuracy: 0.43697916666666664\tAverage Loss: 1.7204000463656715\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.4401041666666667\tAverage Loss: 1.7338014560352513\n",
            "\tTest: Average Accuracy: 0.44114583333333335\tAverage Loss: 1.6879206762211114\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.45078125\tAverage Loss: 1.697786454102443\n",
            "\tTest: Average Accuracy: 0.4552083333333333\tAverage Loss: 1.6591786686941792\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.4622395833333333\tAverage Loss: 1.6649198030087884\n",
            "\tTest: Average Accuracy: 0.46145833333333336\tAverage Loss: 1.6328634818255068\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.473046875\tAverage Loss: 1.634186222664113\n",
            "\tTest: Average Accuracy: 0.465625\tAverage Loss: 1.6082389670441015\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.4837239583333333\tAverage Loss: 1.6050422484074567\n",
            "\tTest: Average Accuracy: 0.471875\tAverage Loss: 1.5848538430679013\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.4928385416666667\tAverage Loss: 1.5771111838873577\n",
            "\tTest: Average Accuracy: 0.47604166666666664\tAverage Loss: 1.562534984126961\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.5037760416666667\tAverage Loss: 1.5502123612076908\n",
            "\tTest: Average Accuracy: 0.48541666666666666\tAverage Loss: 1.5411977298596669\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.5111979166666667\tAverage Loss: 1.5242186295662634\n",
            "\tTest: Average Accuracy: 0.5010416666666667\tAverage Loss: 1.520452056631205\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.519140625\tAverage Loss: 1.4990159554908584\n",
            "\tTest: Average Accuracy: 0.5026041666666666\tAverage Loss: 1.5004375643048244\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.5276041666666667\tAverage Loss: 1.474591797908898\n",
            "\tTest: Average Accuracy: 0.5119791666666667\tAverage Loss: 1.4811908327749224\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.5358072916666666\tAverage Loss: 1.4508900487475946\n",
            "\tTest: Average Accuracy: 0.5229166666666667\tAverage Loss: 1.4626292490039308\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.5408854166666667\tAverage Loss: 1.4277807672034861\n",
            "\tTest: Average Accuracy: 0.5307291666666667\tAverage Loss: 1.444662365592696\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.5471354166666667\tAverage Loss: 1.4053132030959365\n",
            "\tTest: Average Accuracy: 0.5322916666666667\tAverage Loss: 1.4271261028635178\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.55390625\tAverage Loss: 1.3833677354193792\n",
            "\tTest: Average Accuracy: 0.5369791666666667\tAverage Loss: 1.4104310980781352\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.5587239583333333\tAverage Loss: 1.3616883910550777\n",
            "\tTest: Average Accuracy: 0.5380208333333333\tAverage Loss: 1.394060210236731\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.564453125\tAverage Loss: 1.3403937545015052\n",
            "\tTest: Average Accuracy: 0.5411458333333333\tAverage Loss: 1.3779334673151566\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.5709635416666666\tAverage Loss: 1.319475332596663\n",
            "\tTest: Average Accuracy: 0.5463541666666667\tAverage Loss: 1.362067819389529\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.576953125\tAverage Loss: 1.2991204956456928\n",
            "\tTest: Average Accuracy: 0.5526041666666667\tAverage Loss: 1.346817201709253\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.5817708333333333\tAverage Loss: 1.2792373075879682\n",
            "\tTest: Average Accuracy: 0.55625\tAverage Loss: 1.3317425716975797\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.5872395833333334\tAverage Loss: 1.2597953870022873\n",
            "\tTest: Average Accuracy: 0.5572916666666666\tAverage Loss: 1.3174175530627121\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.5912760416666667\tAverage Loss: 1.2410264759825635\n",
            "\tTest: Average Accuracy: 0.5614583333333333\tAverage Loss: 1.3032095436210087\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.5981770833333333\tAverage Loss: 1.222749522489511\n",
            "\tTest: Average Accuracy: 0.565625\tAverage Loss: 1.289550943120233\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.6053385416666667\tAverage Loss: 1.205167472478949\n",
            "\tTest: Average Accuracy: 0.5671875\tAverage Loss: 1.2764451798269552\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.611328125\tAverage Loss: 1.1880417970718204\n",
            "\tTest: Average Accuracy: 0.5671875\tAverage Loss: 1.2639285138573124\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.6153645833333333\tAverage Loss: 1.171493699813505\n",
            "\tTest: Average Accuracy: 0.5682291666666667\tAverage Loss: 1.251966116863215\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.6182291666666667\tAverage Loss: 1.1553464995013576\n",
            "\tTest: Average Accuracy: 0.5682291666666667\tAverage Loss: 1.2403159372746768\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.6213541666666667\tAverage Loss: 1.1395729205981981\n",
            "\tTest: Average Accuracy: 0.571875\tAverage Loss: 1.229181332618467\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.627734375\tAverage Loss: 1.1243563810820418\n",
            "\tTest: Average Accuracy: 0.5708333333333333\tAverage Loss: 1.2185187432033984\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.6330729166666667\tAverage Loss: 1.1096303741418592\n",
            "\tTest: Average Accuracy: 0.5760416666666667\tAverage Loss: 1.208151524034343\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.6360677083333334\tAverage Loss: 1.0953969332217548\n",
            "\tTest: Average Accuracy: 0.578125\tAverage Loss: 1.19822816409752\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.6412760416666666\tAverage Loss: 1.0815256802829025\n",
            "\tTest: Average Accuracy: 0.5796875\tAverage Loss: 1.1887834098634715\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.6453125\tAverage Loss: 1.0681001686327367\n",
            "\tTest: Average Accuracy: 0.5828125\tAverage Loss: 1.1796200279735907\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.65\tAverage Loss: 1.0549954597539029\n",
            "\tTest: Average Accuracy: 0.5859375\tAverage Loss: 1.1708705304425604\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.6536458333333334\tAverage Loss: 1.0423251173500563\n",
            "\tTest: Average Accuracy: 0.5901041666666667\tAverage Loss: 1.1626041279322692\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.655078125\tAverage Loss: 1.0300484645448114\n",
            "\tTest: Average Accuracy: 0.5911458333333334\tAverage Loss: 1.1546082147493064\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.6592447916666667\tAverage Loss: 1.0180573640545816\n",
            "\tTest: Average Accuracy: 0.590625\tAverage Loss: 1.1469943912566565\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.6638020833333333\tAverage Loss: 1.0064121152297705\n",
            "\tTest: Average Accuracy: 0.590625\tAverage Loss: 1.1396694222098644\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.668359375\tAverage Loss: 0.9950406456293391\n",
            "\tTest: Average Accuracy: 0.5932291666666667\tAverage Loss: 1.1326144119959207\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.6725260416666666\tAverage Loss: 0.9839231077967069\n",
            "\tTest: Average Accuracy: 0.5947916666666667\tAverage Loss: 1.1259983817975778\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.6760416666666667\tAverage Loss: 0.9730609724323476\n",
            "\tTest: Average Accuracy: 0.5963541666666666\tAverage Loss: 1.1195962697884572\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.6795572916666667\tAverage Loss: 0.9623882699724258\n",
            "\tTest: Average Accuracy: 0.5984375\tAverage Loss: 1.1133389929718553\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.682421875\tAverage Loss: 0.9520253533106349\n",
            "\tTest: Average Accuracy: 0.5989583333333334\tAverage Loss: 1.107453558481345\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.6856770833333333\tAverage Loss: 0.9419457803251732\n",
            "\tTest: Average Accuracy: 0.6005208333333333\tAverage Loss: 1.1017521180376517\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.68984375\tAverage Loss: 0.9321077934514376\n",
            "\tTest: Average Accuracy: 0.6020833333333333\tAverage Loss: 1.0962665692402436\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.6921875\tAverage Loss: 0.922493902960363\n",
            "\tTest: Average Accuracy: 0.6026041666666667\tAverage Loss: 1.0911195838482066\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.6942708333333333\tAverage Loss: 0.913147112720997\n",
            "\tTest: Average Accuracy: 0.6052083333333333\tAverage Loss: 1.0862419571586353\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.6973958333333333\tAverage Loss: 0.9039549243445639\n",
            "\tTest: Average Accuracy: 0.6067708333333334\tAverage Loss: 1.0814386944556509\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.69921875\tAverage Loss: 0.8949510152134188\n",
            "\tTest: Average Accuracy: 0.6088541666666667\tAverage Loss: 1.0770103654520056\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.702734375\tAverage Loss: 0.8862281879971737\n",
            "\tTest: Average Accuracy: 0.6130208333333333\tAverage Loss: 1.0726726398469884\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.7059895833333333\tAverage Loss: 0.8776265149498379\n",
            "\tTest: Average Accuracy: 0.6135416666666667\tAverage Loss: 1.0684303833007198\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.7092447916666667\tAverage Loss: 0.8691500198593044\n",
            "\tTest: Average Accuracy: 0.6135416666666667\tAverage Loss: 1.0642065705235666\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.7110677083333333\tAverage Loss: 0.8608238873534267\n",
            "\tTest: Average Accuracy: 0.6140625\tAverage Loss: 1.0602532182210818\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.7126302083333333\tAverage Loss: 0.8526760093186332\n",
            "\tTest: Average Accuracy: 0.6130208333333333\tAverage Loss: 1.0563455378459157\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.7153645833333333\tAverage Loss: 0.8446384155725007\n",
            "\tTest: Average Accuracy: 0.6171875\tAverage Loss: 1.052643276904196\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.7180989583333334\tAverage Loss: 0.8367430262658107\n",
            "\tTest: Average Accuracy: 0.6182291666666667\tAverage Loss: 1.0490073612805362\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.7216145833333333\tAverage Loss: 0.8289271376056272\n",
            "\tTest: Average Accuracy: 0.6208333333333333\tAverage Loss: 1.0455173409849834\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.7244791666666667\tAverage Loss: 0.8212001392163434\n",
            "\tTest: Average Accuracy: 0.6208333333333333\tAverage Loss: 1.0420959243370647\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.7272135416666666\tAverage Loss: 0.8136401383001298\n",
            "\tTest: Average Accuracy: 0.6223958333333334\tAverage Loss: 1.0389311393192833\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.7315104166666667\tAverage Loss: 0.8062405002083339\n",
            "\tTest: Average Accuracy: 0.6213541666666667\tAverage Loss: 1.0356465902525072\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.7333333333333333\tAverage Loss: 0.7988680539841858\n",
            "\tTest: Average Accuracy: 0.6197916666666666\tAverage Loss: 1.0327732280172492\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.7358072916666667\tAverage Loss: 0.791651338797548\n",
            "\tTest: Average Accuracy: 0.621875\tAverage Loss: 1.0298898741688836\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.7388020833333333\tAverage Loss: 0.7844794971224417\n",
            "\tTest: Average Accuracy: 0.6255208333333333\tAverage Loss: 1.0272632103121035\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.7408854166666666\tAverage Loss: 0.7773837489589913\n",
            "\tTest: Average Accuracy: 0.6255208333333333\tAverage Loss: 1.0244478479662587\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.7444010416666667\tAverage Loss: 0.7703935258953204\n",
            "\tTest: Average Accuracy: 0.6260416666666667\tAverage Loss: 1.0217369119724933\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.7473958333333334\tAverage Loss: 0.7634909291706492\n",
            "\tTest: Average Accuracy: 0.625\tAverage Loss: 1.0192725397628337\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.75\tAverage Loss: 0.7566820828817796\n",
            "\tTest: Average Accuracy: 0.6234375\tAverage Loss: 1.0168300895779245\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.7526041666666666\tAverage Loss: 0.7499233492888498\n",
            "\tTest: Average Accuracy: 0.625\tAverage Loss: 1.01472462168546\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.7540364583333333\tAverage Loss: 0.7433174478608784\n",
            "\tTest: Average Accuracy: 0.6255208333333333\tAverage Loss: 1.0125009762893362\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.755859375\tAverage Loss: 0.7367826247802323\n",
            "\tTest: Average Accuracy: 0.628125\tAverage Loss: 1.0102019520948118\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.7575520833333333\tAverage Loss: 0.7303062140346172\n",
            "\tTest: Average Accuracy: 0.6286458333333333\tAverage Loss: 1.0079662375345735\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.7609375\tAverage Loss: 0.7239221184243211\n",
            "\tTest: Average Accuracy: 0.6302083333333334\tAverage Loss: 1.0059262404392126\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.7623697916666666\tAverage Loss: 0.7176157075158496\n",
            "\tTest: Average Accuracy: 0.63125\tAverage Loss: 1.003923481449878\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.766015625\tAverage Loss: 0.7113393610963195\n",
            "\tTest: Average Accuracy: 0.6307291666666667\tAverage Loss: 1.0017476492274264\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.7669270833333334\tAverage Loss: 0.7050836852793315\n",
            "\tTest: Average Accuracy: 0.6302083333333334\tAverage Loss: 0.9998422970321973\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.7692708333333333\tAverage Loss: 0.6988804375408545\n",
            "\tTest: Average Accuracy: 0.6307291666666667\tAverage Loss: 0.9980726377073978\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.7716145833333333\tAverage Loss: 0.6927752653387476\n",
            "\tTest: Average Accuracy: 0.6333333333333333\tAverage Loss: 0.9961856272711679\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.7727864583333334\tAverage Loss: 0.6867285829627188\n",
            "\tTest: Average Accuracy: 0.6338541666666667\tAverage Loss: 0.994199301623767\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.7747395833333334\tAverage Loss: 0.6807793939501329\n",
            "\tTest: Average Accuracy: 0.6364583333333333\tAverage Loss: 0.9924345573004333\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.7779947916666666\tAverage Loss: 0.6747784624196491\n",
            "\tTest: Average Accuracy: 0.6369791666666667\tAverage Loss: 0.9909175195838323\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.7809895833333333\tAverage Loss: 0.6689661115010779\n",
            "\tTest: Average Accuracy: 0.6395833333333333\tAverage Loss: 0.9888828615713144\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.7841145833333333\tAverage Loss: 0.6631105455804397\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 0.9871852040056538\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.786328125\tAverage Loss: 0.6573855648608465\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 0.9854000613948746\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.7875\tAverage Loss: 0.6516671041043656\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 0.9837587612576554\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.7899739583333333\tAverage Loss: 0.646064690448307\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 0.981883106883614\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.7921875\tAverage Loss: 0.6404090944989915\n",
            "\tTest: Average Accuracy: 0.6411458333333333\tAverage Loss: 0.980407504471685\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.7942708333333334\tAverage Loss: 0.6348630787121058\n",
            "\tTest: Average Accuracy: 0.6427083333333333\tAverage Loss: 0.9787298299441602\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.796875\tAverage Loss: 0.6292838974296211\n",
            "\tTest: Average Accuracy: 0.6447916666666667\tAverage Loss: 0.9770109989410479\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.799609375\tAverage Loss: 0.6238528817651743\n",
            "\tTest: Average Accuracy: 0.6479166666666667\tAverage Loss: 0.9756309193337196\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.8010416666666667\tAverage Loss: 0.6184765798228133\n",
            "\tTest: Average Accuracy: 0.6484375\tAverage Loss: 0.9742214450702867\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JoANozvyz-vA",
        "outputId": "72c3b618-a853-49a8-db5e-7ae6c061f3fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.020703125\tAverage Loss: 2.9176330163854813\n",
            "\tTest: Average Accuracy: 0.06770833333333333\tAverage Loss: 2.6401314788130383\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.12565104166666666\tAverage Loss: 2.5736998984181136\n",
            "\tTest: Average Accuracy: 0.24635416666666668\tAverage Loss: 2.3066986018475766\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.24322916666666666\tAverage Loss: 2.2643496896559507\n",
            "\tTest: Average Accuracy: 0.31979166666666664\tAverage Loss: 2.0763413041851475\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.32708333333333334\tAverage Loss: 2.051326440478117\n",
            "\tTest: Average Accuracy: 0.3703125\tAverage Loss: 1.903876161591737\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.3829427083333333\tAverage Loss: 1.9010167608340223\n",
            "\tTest: Average Accuracy: 0.4088541666666667\tAverage Loss: 1.791569235691792\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.4178385416666667\tAverage Loss: 1.795065838861873\n",
            "\tTest: Average Accuracy: 0.43645833333333334\tAverage Loss: 1.7139057214615996\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.44479166666666664\tAverage Loss: 1.7131742543317212\n",
            "\tTest: Average Accuracy: 0.4473958333333333\tAverage Loss: 1.6548484388934226\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.46393229166666666\tAverage Loss: 1.644708976138234\n",
            "\tTest: Average Accuracy: 0.46041666666666664\tAverage Loss: 1.6047745577073012\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.48528645833333334\tAverage Loss: 1.5838155528907139\n",
            "\tTest: Average Accuracy: 0.46875\tAverage Loss: 1.5585477800892382\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.5028645833333333\tAverage Loss: 1.527343831815727\n",
            "\tTest: Average Accuracy: 0.48489583333333336\tAverage Loss: 1.5154075339996091\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.520703125\tAverage Loss: 1.4742553656105482\n",
            "\tTest: Average Accuracy: 0.49947916666666664\tAverage Loss: 1.474440613698196\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.536328125\tAverage Loss: 1.4239835704564567\n",
            "\tTest: Average Accuracy: 0.5078125\tAverage Loss: 1.4358759106600971\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.55078125\tAverage Loss: 1.3764017344410706\n",
            "\tTest: Average Accuracy: 0.5145833333333333\tAverage Loss: 1.39908702379393\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.562109375\tAverage Loss: 1.3312939879159538\n",
            "\tTest: Average Accuracy: 0.5260416666666666\tAverage Loss: 1.3651136029556814\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.572265625\tAverage Loss: 1.2883998778796772\n",
            "\tTest: Average Accuracy: 0.5369791666666667\tAverage Loss: 1.3335151149957554\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.585546875\tAverage Loss: 1.2480792272363739\n",
            "\tTest: Average Accuracy: 0.5458333333333333\tAverage Loss: 1.3040769559154022\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.5975260416666667\tAverage Loss: 1.2098984944781341\n",
            "\tTest: Average Accuracy: 0.5541666666666667\tAverage Loss: 1.2766397686406856\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.607421875\tAverage Loss: 1.1738920595579985\n",
            "\tTest: Average Accuracy: 0.5619791666666667\tAverage Loss: 1.251008837903341\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.61875\tAverage Loss: 1.1402025467516765\n",
            "\tTest: Average Accuracy: 0.5677083333333334\tAverage Loss: 1.227744561881413\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.6287760416666667\tAverage Loss: 1.1087449528858004\n",
            "\tTest: Average Accuracy: 0.5729166666666666\tAverage Loss: 1.2061953232682276\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.6375\tAverage Loss: 1.0793492279983237\n",
            "\tTest: Average Accuracy: 0.584375\tAverage Loss: 1.1860237334746937\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.6454427083333333\tAverage Loss: 1.051462957046257\n",
            "\tTest: Average Accuracy: 0.5927083333333333\tAverage Loss: 1.1670696142694477\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.65390625\tAverage Loss: 1.0251754447104142\n",
            "\tTest: Average Accuracy: 0.5932291666666667\tAverage Loss: 1.1503974617544717\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.6625\tAverage Loss: 1.000368926685766\n",
            "\tTest: Average Accuracy: 0.5973958333333333\tAverage Loss: 1.134759017642222\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.6696614583333333\tAverage Loss: 0.9767821996120218\n",
            "\tTest: Average Accuracy: 0.5973958333333333\tAverage Loss: 1.1200219285077082\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.6763020833333333\tAverage Loss: 0.9542106777067012\n",
            "\tTest: Average Accuracy: 0.5994791666666667\tAverage Loss: 1.1064677353247754\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.6846354166666667\tAverage Loss: 0.9328242141322901\n",
            "\tTest: Average Accuracy: 0.6036458333333333\tAverage Loss: 1.0938656471395851\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.6893229166666667\tAverage Loss: 0.9123414942303631\n",
            "\tTest: Average Accuracy: 0.6109375\tAverage Loss: 1.082295155956151\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.6963541666666667\tAverage Loss: 0.8927225508112433\n",
            "\tTest: Average Accuracy: 0.6140625\tAverage Loss: 1.071632049404461\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.7024739583333334\tAverage Loss: 0.8739505440052701\n",
            "\tTest: Average Accuracy: 0.6192708333333333\tAverage Loss: 1.0617133335816693\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.7080729166666667\tAverage Loss: 0.8559922818990308\n",
            "\tTest: Average Accuracy: 0.61875\tAverage Loss: 1.0525432719085763\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.7145833333333333\tAverage Loss: 0.8387350694440511\n",
            "\tTest: Average Accuracy: 0.6177083333333333\tAverage Loss: 1.0442102926151522\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.7203125\tAverage Loss: 0.8220447871360731\n",
            "\tTest: Average Accuracy: 0.6213541666666667\tAverage Loss: 1.035483467367881\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.726171875\tAverage Loss: 0.805899775788948\n",
            "\tTest: Average Accuracy: 0.625\tAverage Loss: 1.028478095634379\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.7333333333333333\tAverage Loss: 0.79044740777401\n",
            "\tTest: Average Accuracy: 0.6291666666666667\tAverage Loss: 1.021168102292921\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.737890625\tAverage Loss: 0.7753500462453519\n",
            "\tTest: Average Accuracy: 0.6317708333333333\tAverage Loss: 1.0145516154258916\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.7432291666666667\tAverage Loss: 0.7609653253713428\n",
            "\tTest: Average Accuracy: 0.6354166666666666\tAverage Loss: 1.008490278811053\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.7484375\tAverage Loss: 0.7467199864917317\n",
            "\tTest: Average Accuracy: 0.6369791666666667\tAverage Loss: 1.0028973920316133\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.7540364583333333\tAverage Loss: 0.7331490889079507\n",
            "\tTest: Average Accuracy: 0.6375\tAverage Loss: 0.9978141563858011\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.7576822916666667\tAverage Loss: 0.7198018229365502\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 0.9925616411735999\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.7619791666666667\tAverage Loss: 0.7068187917116968\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 0.9877314467739621\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.7666666666666667\tAverage Loss: 0.694586514746117\n",
            "\tTest: Average Accuracy: 0.6427083333333333\tAverage Loss: 0.9823579775743277\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.77109375\tAverage Loss: 0.6822018390012867\n",
            "\tTest: Average Accuracy: 0.6432291666666666\tAverage Loss: 0.9781448819179296\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.7755208333333333\tAverage Loss: 0.6703136951105716\n",
            "\tTest: Average Accuracy: 0.6463541666666667\tAverage Loss: 0.9738866121661796\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.7802083333333333\tAverage Loss: 0.6585810899269068\n",
            "\tTest: Average Accuracy: 0.6463541666666667\tAverage Loss: 0.970266853998944\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.7841145833333333\tAverage Loss: 0.6472513001566924\n",
            "\tTest: Average Accuracy: 0.6489583333333333\tAverage Loss: 0.9667571499987702\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.7877604166666666\tAverage Loss: 0.636175302573475\n",
            "\tTest: Average Accuracy: 0.6515625\tAverage Loss: 0.963873322728798\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.7916666666666666\tAverage Loss: 0.6254546443561797\n",
            "\tTest: Average Accuracy: 0.6505208333333333\tAverage Loss: 0.9603675207559541\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.7958333333333333\tAverage Loss: 0.61477865424219\n",
            "\tTest: Average Accuracy: 0.6520833333333333\tAverage Loss: 0.9581889063980938\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.79921875\tAverage Loss: 0.6044098646982283\n",
            "\tTest: Average Accuracy: 0.6515625\tAverage Loss: 0.9556675399225427\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.803515625\tAverage Loss: 0.5942557062777243\n",
            "\tTest: Average Accuracy: 0.6557291666666667\tAverage Loss: 0.9531989747476786\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.8076822916666667\tAverage Loss: 0.5843863039028635\n",
            "\tTest: Average Accuracy: 0.6598958333333333\tAverage Loss: 0.9506528418815671\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.8109375\tAverage Loss: 0.5747425923361515\n",
            "\tTest: Average Accuracy: 0.6630208333333333\tAverage Loss: 0.9477394933605313\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.8145833333333333\tAverage Loss: 0.5650624162286995\n",
            "\tTest: Average Accuracy: 0.6635416666666667\tAverage Loss: 0.946042705437799\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.8173177083333333\tAverage Loss: 0.5558692253343811\n",
            "\tTest: Average Accuracy: 0.665625\tAverage Loss: 0.94354302855904\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.82109375\tAverage Loss: 0.5468146983627338\n",
            "\tTest: Average Accuracy: 0.6666666666666666\tAverage Loss: 0.9424140625803857\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.8240885416666667\tAverage Loss: 0.5379465277604029\n",
            "\tTest: Average Accuracy: 0.6697916666666667\tAverage Loss: 0.9409433581916543\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.8278645833333333\tAverage Loss: 0.5294320562350378\n",
            "\tTest: Average Accuracy: 0.66875\tAverage Loss: 0.938785781125571\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.8322916666666667\tAverage Loss: 0.5209289204227991\n",
            "\tTest: Average Accuracy: 0.6682291666666667\tAverage Loss: 0.9382545765608664\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.8346354166666666\tAverage Loss: 0.512611549153459\n",
            "\tTest: Average Accuracy: 0.66875\tAverage Loss: 0.936162507101568\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.8380208333333333\tAverage Loss: 0.5044397301148373\n",
            "\tTest: Average Accuracy: 0.6677083333333333\tAverage Loss: 0.9354660426096643\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.840234375\tAverage Loss: 0.4964306970460657\n",
            "\tTest: Average Accuracy: 0.66875\tAverage Loss: 0.9355687480768472\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.8434895833333333\tAverage Loss: 0.48849894731369403\n",
            "\tTest: Average Accuracy: 0.6713541666666667\tAverage Loss: 0.9341181342854327\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.8451822916666667\tAverage Loss: 0.48087415521815424\n",
            "\tTest: Average Accuracy: 0.671875\tAverage Loss: 0.9338244334483533\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.848046875\tAverage Loss: 0.47325086248276876\n",
            "\tTest: Average Accuracy: 0.671875\tAverage Loss: 0.9342894916632966\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.8526041666666667\tAverage Loss: 0.46565081396882224\n",
            "\tTest: Average Accuracy: 0.6729166666666667\tAverage Loss: 0.9339094522797888\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.85546875\tAverage Loss: 0.45845872656097236\n",
            "\tTest: Average Accuracy: 0.6739583333333333\tAverage Loss: 0.9340903580864347\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.8596354166666667\tAverage Loss: 0.45130422814426935\n",
            "\tTest: Average Accuracy: 0.675\tAverage Loss: 0.93448306633269\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.8619791666666666\tAverage Loss: 0.4442620501672111\n",
            "\tTest: Average Accuracy: 0.6755208333333333\tAverage Loss: 0.9346679745283432\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.8645833333333334\tAverage Loss: 0.4373316067122505\n",
            "\tTest: Average Accuracy: 0.6760416666666667\tAverage Loss: 0.9352890264870978\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.867578125\tAverage Loss: 0.4304784534685388\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 0.9355255582898159\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.8697916666666666\tAverage Loss: 0.42386658902070523\n",
            "\tTest: Average Accuracy: 0.6765625\tAverage Loss: 0.9364023469449781\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.873046875\tAverage Loss: 0.41734602503255724\n",
            "\tTest: Average Accuracy: 0.6791666666666667\tAverage Loss: 0.9370516635472653\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.876171875\tAverage Loss: 0.4108930214996148\n",
            "\tTest: Average Accuracy: 0.6796875\tAverage Loss: 0.9381093626330868\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.8783854166666667\tAverage Loss: 0.404541169316173\n",
            "\tTest: Average Accuracy: 0.6802083333333333\tAverage Loss: 0.9389000983930291\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.880859375\tAverage Loss: 0.3983471083538331\n",
            "\tTest: Average Accuracy: 0.6807291666666667\tAverage Loss: 0.9402094625297426\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.8825520833333333\tAverage Loss: 0.3921686613521371\n",
            "\tTest: Average Accuracy: 0.6802083333333333\tAverage Loss: 0.941482541831449\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.8841145833333334\tAverage Loss: 0.38610097467357346\n",
            "\tTest: Average Accuracy: 0.68125\tAverage Loss: 0.9429123866731614\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.8856770833333333\tAverage Loss: 0.38020386214188756\n",
            "\tTest: Average Accuracy: 0.68125\tAverage Loss: 0.9449292946214315\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.8885416666666667\tAverage Loss: 0.3743363336564128\n",
            "\tTest: Average Accuracy: 0.684375\tAverage Loss: 0.9461321250161601\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.8912760416666666\tAverage Loss: 0.36856595511555773\n",
            "\tTest: Average Accuracy: 0.6859375\tAverage Loss: 0.9476888955665737\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.8928385416666667\tAverage Loss: 0.36290932698242917\n",
            "\tTest: Average Accuracy: 0.6848958333333334\tAverage Loss: 0.9494770869192087\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.8959635416666667\tAverage Loss: 0.35758842328934975\n",
            "\tTest: Average Accuracy: 0.6880208333333333\tAverage Loss: 0.9509050698861021\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.8981770833333333\tAverage Loss: 0.35206381022128674\n",
            "\tTest: Average Accuracy: 0.6875\tAverage Loss: 0.9526672539753365\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.901953125\tAverage Loss: 0.3466976776641173\n",
            "\tTest: Average Accuracy: 0.6875\tAverage Loss: 0.9546215857149118\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.90390625\tAverage Loss: 0.34141154309354677\n",
            "\tTest: Average Accuracy: 0.6869791666666667\tAverage Loss: 0.9559629634470526\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.90625\tAverage Loss: 0.3361554006215769\n",
            "\tTest: Average Accuracy: 0.6859375\tAverage Loss: 0.9585022349241344\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.9078125\tAverage Loss: 0.3307976343052484\n",
            "\tTest: Average Accuracy: 0.6854166666666667\tAverage Loss: 0.9600023110542837\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.9095052083333334\tAverage Loss: 0.32584892216281863\n",
            "\tTest: Average Accuracy: 0.6885416666666667\tAverage Loss: 0.9622782578054906\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.91171875\tAverage Loss: 0.32073923663552634\n",
            "\tTest: Average Accuracy: 0.6869791666666667\tAverage Loss: 0.9645780289201481\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.913671875\tAverage Loss: 0.3158170365352915\n",
            "\tTest: Average Accuracy: 0.6880208333333333\tAverage Loss: 0.9668029180856337\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.9157552083333333\tAverage Loss: 0.31102176253821195\n",
            "\tTest: Average Accuracy: 0.6885416666666667\tAverage Loss: 0.9692275264995279\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.9174479166666667\tAverage Loss: 0.30611254011415323\n",
            "\tTest: Average Accuracy: 0.6895833333333333\tAverage Loss: 0.9720145156723585\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.9188802083333333\tAverage Loss: 0.30143759774114326\n",
            "\tTest: Average Accuracy: 0.6890625\tAverage Loss: 0.9747001671633003\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.9208333333333333\tAverage Loss: 0.29699365386555565\n",
            "\tTest: Average Accuracy: 0.6911458333333333\tAverage Loss: 0.9772805198089831\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.9229166666666667\tAverage Loss: 0.2924344304256779\n",
            "\tTest: Average Accuracy: 0.6916666666666667\tAverage Loss: 0.9799008438808144\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.923828125\tAverage Loss: 0.2879244063223861\n",
            "\tTest: Average Accuracy: 0.6932291666666667\tAverage Loss: 0.9827272836670345\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.9256510416666667\tAverage Loss: 0.28371002336122697\n",
            "\tTest: Average Accuracy: 0.69375\tAverage Loss: 0.9856061033010516\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.9272135416666667\tAverage Loss: 0.2793245048141156\n",
            "\tTest: Average Accuracy: 0.6932291666666667\tAverage Loss: 0.9882076995306471\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.9286458333333333\tAverage Loss: 0.27519275672858373\n",
            "\tTest: Average Accuracy: 0.69375\tAverage Loss: 0.9914268989606282\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvHYwDBq5fbE",
        "outputId": "c021a43b-11ef-466d-fa9d-1fc432adf311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.10299479166666667\tAverage Loss: 2.6829006906221053\n",
            "\tTest: Average Accuracy: 0.2203125\tAverage Loss: 2.25064009533523\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.209375\tAverage Loss: 2.183150272683167\n",
            "\tTest: Average Accuracy: 0.2682291666666667\tAverage Loss: 2.0076256315859826\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.25638020833333336\tAverage Loss: 1.9773822517308124\n",
            "\tTest: Average Accuracy: 0.3182291666666667\tAverage Loss: 1.895328861154482\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.3184895833333333\tAverage Loss: 1.8028600808735191\n",
            "\tTest: Average Accuracy: 0.37552083333333336\tAverage Loss: 1.7775057911366228\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.3782552083333333\tAverage Loss: 1.6695570729990694\n",
            "\tTest: Average Accuracy: 0.4161458333333333\tAverage Loss: 1.6810049278387897\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.421875\tAverage Loss: 1.5331466045605198\n",
            "\tTest: Average Accuracy: 0.44635416666666666\tAverage Loss: 1.5621216139148228\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.473046875\tAverage Loss: 1.384879472832712\n",
            "\tTest: Average Accuracy: 0.46145833333333336\tAverage Loss: 1.5285784399486062\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.5022135416666667\tAverage Loss: 1.3100162388351855\n",
            "\tTest: Average Accuracy: 0.4817708333333333\tAverage Loss: 1.4686978491866147\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.5274739583333333\tAverage Loss: 1.2384084625148783\n",
            "\tTest: Average Accuracy: 0.5046875\tAverage Loss: 1.4182811728837181\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.5600260416666667\tAverage Loss: 1.164051067743708\n",
            "\tTest: Average Accuracy: 0.5286458333333334\tAverage Loss: 1.3880095970133135\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.5834635416666667\tAverage Loss: 1.096902028366901\n",
            "\tTest: Average Accuracy: 0.5458333333333333\tAverage Loss: 1.3524602352378083\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.6092447916666667\tAverage Loss: 1.0186131530924378\n",
            "\tTest: Average Accuracy: 0.55625\tAverage Loss: 1.3351299238590806\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.6291666666666667\tAverage Loss: 0.9646418799205899\n",
            "\tTest: Average Accuracy: 0.575\tAverage Loss: 1.3169331372104613\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.6552083333333333\tAverage Loss: 0.9038440006551106\n",
            "\tTest: Average Accuracy: 0.5786458333333333\tAverage Loss: 1.3046807597349537\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.6686197916666666\tAverage Loss: 0.868492323624653\n",
            "\tTest: Average Accuracy: 0.5880208333333333\tAverage Loss: 1.3133768802093633\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.6919270833333333\tAverage Loss: 0.8160320298003171\n",
            "\tTest: Average Accuracy: 0.5885416666666666\tAverage Loss: 1.3028341978976394\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.7095052083333333\tAverage Loss: 0.7717007124446656\n",
            "\tTest: Average Accuracy: 0.6026041666666667\tAverage Loss: 1.2719509357422998\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.7248697916666667\tAverage Loss: 0.7294967885123557\n",
            "\tTest: Average Accuracy: 0.5927083333333333\tAverage Loss: 1.2873143726313152\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.7419270833333333\tAverage Loss: 0.6938808641015489\n",
            "\tTest: Average Accuracy: 0.6052083333333333\tAverage Loss: 1.25822426563561\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.7578125\tAverage Loss: 0.6629636718670272\n",
            "\tTest: Average Accuracy: 0.6104166666666667\tAverage Loss: 1.2657138398902552\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.7743489583333333\tAverage Loss: 0.6231276733391499\n",
            "\tTest: Average Accuracy: 0.61875\tAverage Loss: 1.2521831156890353\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.7833333333333333\tAverage Loss: 0.5976683744765878\n",
            "\tTest: Average Accuracy: 0.6239583333333333\tAverage Loss: 1.2613690678162552\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.798046875\tAverage Loss: 0.5562366584977556\n",
            "\tTest: Average Accuracy: 0.6265625\tAverage Loss: 1.2700366603363047\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.816015625\tAverage Loss: 0.5207110418462836\n",
            "\tTest: Average Accuracy: 0.6411458333333333\tAverage Loss: 1.2681777591030208\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.8272135416666667\tAverage Loss: 0.4886081323262768\n",
            "\tTest: Average Accuracy: 0.64375\tAverage Loss: 1.2800567790261703\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.83203125\tAverage Loss: 0.4771907165810475\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 1.2968658462155058\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.8450520833333334\tAverage Loss: 0.43779549614196295\n",
            "\tTest: Average Accuracy: 0.6484375\tAverage Loss: 1.304123107605041\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.8563802083333333\tAverage Loss: 0.4151037996001758\n",
            "\tTest: Average Accuracy: 0.6515625\tAverage Loss: 1.3153404434796598\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.8682291666666667\tAverage Loss: 0.3916975744246715\n",
            "\tTest: Average Accuracy: 0.653125\tAverage Loss: 1.322137699042186\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.875390625\tAverage Loss: 0.37191083720257845\n",
            "\tTest: Average Accuracy: 0.6489583333333333\tAverage Loss: 1.3573082205049616\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.8877604166666667\tAverage Loss: 0.3465531272300783\n",
            "\tTest: Average Accuracy: 0.6541666666666667\tAverage Loss: 1.3639338582068368\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.89375\tAverage Loss: 0.32954236807861803\n",
            "\tTest: Average Accuracy: 0.6520833333333333\tAverage Loss: 1.377855204593669\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.90234375\tAverage Loss: 0.3073333532335319\n",
            "\tTest: Average Accuracy: 0.6526041666666667\tAverage Loss: 1.3942854132086855\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.9075520833333334\tAverage Loss: 0.290385815805891\n",
            "\tTest: Average Accuracy: 0.65\tAverage Loss: 1.4197044170281634\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.9186197916666666\tAverage Loss: 0.27100300338785693\n",
            "\tTest: Average Accuracy: 0.6604166666666667\tAverage Loss: 1.4383249647822822\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.9213541666666667\tAverage Loss: 0.2569157202475118\n",
            "\tTest: Average Accuracy: 0.6609375\tAverage Loss: 1.4273704613660831\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.9256510416666667\tAverage Loss: 0.24389988537068857\n",
            "\tTest: Average Accuracy: 0.6536458333333334\tAverage Loss: 1.4822277323102593\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.9303385416666666\tAverage Loss: 0.23402674122254322\n",
            "\tTest: Average Accuracy: 0.6630208333333333\tAverage Loss: 1.4924456669495025\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.9393229166666667\tAverage Loss: 0.21170869021666683\n",
            "\tTest: Average Accuracy: 0.6666666666666666\tAverage Loss: 1.4805128715205187\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.9463541666666667\tAverage Loss: 0.19771924261422535\n",
            "\tTest: Average Accuracy: 0.6645833333333333\tAverage Loss: 1.4766048193087296\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.9522135416666667\tAverage Loss: 0.18361943436227518\n",
            "\tTest: Average Accuracy: 0.6635416666666667\tAverage Loss: 1.5068341399790157\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.9536458333333333\tAverage Loss: 0.1753724226044164\n",
            "\tTest: Average Accuracy: 0.66875\tAverage Loss: 1.5244207049951255\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.96328125\tAverage Loss: 0.15959231123569867\n",
            "\tTest: Average Accuracy: 0.6640625\tAverage Loss: 1.5632168131412325\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.9643229166666667\tAverage Loss: 0.1515398681197868\n",
            "\tTest: Average Accuracy: 0.665625\tAverage Loss: 1.5445845320997285\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.9678385416666667\tAverage Loss: 0.14188069321044014\n",
            "\tTest: Average Accuracy: 0.6588541666666666\tAverage Loss: 1.57440518687504\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.973828125\tAverage Loss: 0.13001303674790982\n",
            "\tTest: Average Accuracy: 0.66875\tAverage Loss: 1.5788519781987989\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.9760416666666667\tAverage Loss: 0.12111438755589404\n",
            "\tTest: Average Accuracy: 0.6666666666666666\tAverage Loss: 1.5997205965963037\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.978125\tAverage Loss: 0.11169279464568843\n",
            "\tTest: Average Accuracy: 0.6713541666666667\tAverage Loss: 1.6267003254983476\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.9817708333333334\tAverage Loss: 0.10277284567945091\n",
            "\tTest: Average Accuracy: 0.6729166666666667\tAverage Loss: 1.6318283025470748\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.9841145833333333\tAverage Loss: 0.09622115488210659\n",
            "\tTest: Average Accuracy: 0.6770833333333334\tAverage Loss: 1.6449991070690104\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.9854166666666667\tAverage Loss: 0.08972279339569639\n",
            "\tTest: Average Accuracy: 0.6744791666666666\tAverage Loss: 1.665035340101061\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.987109375\tAverage Loss: 0.08366804691829555\n",
            "\tTest: Average Accuracy: 0.6729166666666667\tAverage Loss: 1.6810923256716035\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.9881510416666667\tAverage Loss: 0.07895529185497585\n",
            "\tTest: Average Accuracy: 0.6744791666666666\tAverage Loss: 1.6926323235603653\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.9890625\tAverage Loss: 0.07451099395034845\n",
            "\tTest: Average Accuracy: 0.6692708333333334\tAverage Loss: 1.7121280571805102\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.9903645833333333\tAverage Loss: 0.07029894826167592\n",
            "\tTest: Average Accuracy: 0.6770833333333334\tAverage Loss: 1.7235083596977383\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.9911458333333333\tAverage Loss: 0.06602878375519511\n",
            "\tTest: Average Accuracy: 0.6770833333333334\tAverage Loss: 1.7403852848281551\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.9921875\tAverage Loss: 0.06246423785365944\n",
            "\tTest: Average Accuracy: 0.675\tAverage Loss: 1.7523165158537142\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.992578125\tAverage Loss: 0.0589023052369126\n",
            "\tTest: Average Accuracy: 0.6744791666666666\tAverage Loss: 1.7688894815213574\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.993359375\tAverage Loss: 0.05560253235767356\n",
            "\tTest: Average Accuracy: 0.6796875\tAverage Loss: 1.784082331313511\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.99375\tAverage Loss: 0.05268835216137851\n",
            "\tTest: Average Accuracy: 0.6796875\tAverage Loss: 1.7941140112470597\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.99453125\tAverage Loss: 0.05023874994125515\n",
            "\tTest: Average Accuracy: 0.6807291666666667\tAverage Loss: 1.8076733817191328\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.9955729166666667\tAverage Loss: 0.04773403178895647\n",
            "\tTest: Average Accuracy: 0.6807291666666667\tAverage Loss: 1.8189884701807173\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.9962239583333333\tAverage Loss: 0.04561097004202733\n",
            "\tTest: Average Accuracy: 0.6802083333333333\tAverage Loss: 1.8334265931971385\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.996484375\tAverage Loss: 0.04352185412938248\n",
            "\tTest: Average Accuracy: 0.6822916666666666\tAverage Loss: 1.841856376944879\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.9970052083333333\tAverage Loss: 0.04173264086109849\n",
            "\tTest: Average Accuracy: 0.6817708333333333\tAverage Loss: 1.8595770865470418\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.9973958333333334\tAverage Loss: 0.03998971694546056\n",
            "\tTest: Average Accuracy: 0.6828125\tAverage Loss: 1.8699838585596444\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.9975260416666667\tAverage Loss: 0.03826598749799479\n",
            "\tTest: Average Accuracy: 0.6833333333333333\tAverage Loss: 1.8816435654764176\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.998046875\tAverage Loss: 0.03659113529678868\n",
            "\tTest: Average Accuracy: 0.6791666666666667\tAverage Loss: 1.8948037867493204\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.9979166666666667\tAverage Loss: 0.03516672933050488\n",
            "\tTest: Average Accuracy: 0.6765625\tAverage Loss: 1.905459504469533\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.9979166666666667\tAverage Loss: 0.03382097001192141\n",
            "\tTest: Average Accuracy: 0.6786458333333333\tAverage Loss: 1.9158056462794864\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.9981770833333333\tAverage Loss: 0.03268912322285074\n",
            "\tTest: Average Accuracy: 0.6822916666666666\tAverage Loss: 1.921866731175103\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.9983072916666667\tAverage Loss: 0.031241428484032153\n",
            "\tTest: Average Accuracy: 0.68125\tAverage Loss: 1.9358670335732737\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.9985677083333333\tAverage Loss: 0.030326794360169346\n",
            "\tTest: Average Accuracy: 0.6822916666666666\tAverage Loss: 1.9458873878612153\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.9985677083333333\tAverage Loss: 0.02900380227601298\n",
            "\tTest: Average Accuracy: 0.68125\tAverage Loss: 1.953110930113517\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.9986979166666666\tAverage Loss: 0.02804018277708397\n",
            "\tTest: Average Accuracy: 0.6833333333333333\tAverage Loss: 1.9630330916875376\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.9986979166666666\tAverage Loss: 0.027015124988757615\n",
            "\tTest: Average Accuracy: 0.6822916666666666\tAverage Loss: 1.9747568181999462\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.9986979166666666\tAverage Loss: 0.02621867112340637\n",
            "\tTest: Average Accuracy: 0.6833333333333333\tAverage Loss: 1.9836861509457826\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.02522976662265802\n",
            "\tTest: Average Accuracy: 0.6817708333333333\tAverage Loss: 1.9880010919020268\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.024399018160839\n",
            "\tTest: Average Accuracy: 0.6817708333333333\tAverage Loss: 1.9974619777439706\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.02365186155423934\n",
            "\tTest: Average Accuracy: 0.6828125\tAverage Loss: 2.008525702941545\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.022846349934900798\n",
            "\tTest: Average Accuracy: 0.6822916666666666\tAverage Loss: 2.0165946320120742\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.9990885416666667\tAverage Loss: 0.022125367355625744\n",
            "\tTest: Average Accuracy: 0.684375\tAverage Loss: 2.027156677848462\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.9990885416666667\tAverage Loss: 0.021403355927192648\n",
            "\tTest: Average Accuracy: 0.6817708333333333\tAverage Loss: 2.03532245445084\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.9990885416666667\tAverage Loss: 0.020782119834046802\n",
            "\tTest: Average Accuracy: 0.6828125\tAverage Loss: 2.042750144677344\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.99921875\tAverage Loss: 0.020147757988645387\n",
            "\tTest: Average Accuracy: 0.6802083333333333\tAverage Loss: 2.052023725061405\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.99921875\tAverage Loss: 0.019478528622797715\n",
            "\tTest: Average Accuracy: 0.6838541666666667\tAverage Loss: 2.0603943948920684\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.99921875\tAverage Loss: 0.01895914325118115\n",
            "\tTest: Average Accuracy: 0.68125\tAverage Loss: 2.0684615345944644\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.9993489583333334\tAverage Loss: 0.0184303593177502\n",
            "\tTest: Average Accuracy: 0.684375\tAverage Loss: 2.0737645279035495\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.9993489583333334\tAverage Loss: 0.01787670169138881\n",
            "\tTest: Average Accuracy: 0.6838541666666667\tAverage Loss: 2.0830908527072847\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.9993489583333334\tAverage Loss: 0.01736958392817196\n",
            "\tTest: Average Accuracy: 0.6848958333333334\tAverage Loss: 2.0896098847003173\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.9993489583333334\tAverage Loss: 0.01689827573611605\n",
            "\tTest: Average Accuracy: 0.6828125\tAverage Loss: 2.098273522968535\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.9993489583333334\tAverage Loss: 0.01641370045473565\n",
            "\tTest: Average Accuracy: 0.684375\tAverage Loss: 2.1043248193593542\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.015967049738873248\n",
            "\tTest: Average Accuracy: 0.6864583333333333\tAverage Loss: 2.111601028364548\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.015554696813429783\n",
            "\tTest: Average Accuracy: 0.6875\tAverage Loss: 2.120129185619743\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.015162859106357745\n",
            "\tTest: Average Accuracy: 0.6854166666666667\tAverage Loss: 2.126106697921498\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.014650109730052836\n",
            "\tTest: Average Accuracy: 0.6859375\tAverage Loss: 2.1305606538993733\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.014241079107611148\n",
            "\tTest: Average Accuracy: 0.6885416666666667\tAverage Loss: 2.1375724927210547\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.01385195413736121\n",
            "\tTest: Average Accuracy: 0.6864583333333333\tAverage Loss: 2.145419030263262\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.013512650321225431\n",
            "\tTest: Average Accuracy: 0.6880208333333333\tAverage Loss: 2.150738076008978\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.013186579280881256\n",
            "\tTest: Average Accuracy: 0.6869791666666667\tAverage Loss: 2.1574225799996265\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.01\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-bMR4yr9QiY"
      },
      "source": [
        "By larger learning rates , the precoess of training speeds up but as we see the accuracy decreases a lot. By smaller learning rates , the speed of process decreade but usually the accuracy increase.About the small learning rates it's possible that they get stuck on local minimums and that's why sometimes they don't do well. ( Sometimes the accuracy on train data doesn't change a lot but the variance decrease and model do better on test data)\n",
        "\n",
        "\n",
        "In our case the learning rate of : 0.005 did the best"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part four : Activation Function"
      ],
      "metadata": {
        "id": "4qV0actn91qu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RNOR-ak4_Lvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18688807-9f6c-419a-cde9-a383c53b96a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.0009114583333333333\tAverage Loss: 3.1682552513344433\n",
            "\tTest: Average Accuracy: 0.0625\tAverage Loss: 2.7810177584994014\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.004557291666666667\tAverage Loss: 2.8823910093332206\n",
            "\tTest: Average Accuracy: 0.17135416666666667\tAverage Loss: 2.490173407858597\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.09505208333333333\tAverage Loss: 2.487250460483216\n",
            "\tTest: Average Accuracy: 0.296875\tAverage Loss: 2.1880712962136664\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.22734375\tAverage Loss: 2.1969376426985776\n",
            "\tTest: Average Accuracy: 0.36302083333333335\tAverage Loss: 1.9567126764471916\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.30390625\tAverage Loss: 1.982356824075588\n",
            "\tTest: Average Accuracy: 0.3875\tAverage Loss: 1.804118177830772\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.352734375\tAverage Loss: 1.8310836437699425\n",
            "\tTest: Average Accuracy: 0.4140625\tAverage Loss: 1.7016866879654555\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.3826822916666667\tAverage Loss: 1.7194600898815575\n",
            "\tTest: Average Accuracy: 0.4197916666666667\tAverage Loss: 1.6312380889386024\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.4119791666666667\tAverage Loss: 1.6339093737182935\n",
            "\tTest: Average Accuracy: 0.43697916666666664\tAverage Loss: 1.5783582807206826\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.4427083333333333\tAverage Loss: 1.5633981974362143\n",
            "\tTest: Average Accuracy: 0.45416666666666666\tAverage Loss: 1.5335946099322824\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.471484375\tAverage Loss: 1.5013706860904115\n",
            "\tTest: Average Accuracy: 0.4744791666666667\tAverage Loss: 1.492335367681297\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.49700520833333334\tAverage Loss: 1.4447709441404182\n",
            "\tTest: Average Accuracy: 0.49322916666666666\tAverage Loss: 1.4530879888487482\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.5186197916666667\tAverage Loss: 1.39248049021264\n",
            "\tTest: Average Accuracy: 0.5104166666666666\tAverage Loss: 1.4158909259410726\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.534765625\tAverage Loss: 1.3440278634585732\n",
            "\tTest: Average Accuracy: 0.5270833333333333\tAverage Loss: 1.380742218664677\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.5553385416666666\tAverage Loss: 1.2988882370244903\n",
            "\tTest: Average Accuracy: 0.5421875\tAverage Loss: 1.3474087753280628\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.5680989583333333\tAverage Loss: 1.2566103279480436\n",
            "\tTest: Average Accuracy: 0.5505208333333333\tAverage Loss: 1.3157330548893218\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.5859375\tAverage Loss: 1.2168584151419093\n",
            "\tTest: Average Accuracy: 0.5604166666666667\tAverage Loss: 1.2856416019577912\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.6\tAverage Loss: 1.1793758889906631\n",
            "\tTest: Average Accuracy: 0.5682291666666667\tAverage Loss: 1.2571282683394756\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.61171875\tAverage Loss: 1.1439755216874559\n",
            "\tTest: Average Accuracy: 0.5765625\tAverage Loss: 1.2302214717456947\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.6221354166666667\tAverage Loss: 1.1105070124722005\n",
            "\tTest: Average Accuracy: 0.58125\tAverage Loss: 1.204917342473051\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.6322916666666667\tAverage Loss: 1.0788221434867018\n",
            "\tTest: Average Accuracy: 0.5875\tAverage Loss: 1.1811524092836625\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.6420572916666667\tAverage Loss: 1.048767775855011\n",
            "\tTest: Average Accuracy: 0.5973958333333333\tAverage Loss: 1.1588256764181744\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.6514322916666667\tAverage Loss: 1.02019560049036\n",
            "\tTest: Average Accuracy: 0.6046875\tAverage Loss: 1.1378268771641573\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.6584635416666667\tAverage Loss: 0.9929710339560087\n",
            "\tTest: Average Accuracy: 0.6171875\tAverage Loss: 1.118051764075188\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.666796875\tAverage Loss: 0.9669766013325948\n",
            "\tTest: Average Accuracy: 0.6208333333333333\tAverage Loss: 1.0994063951375013\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.6743489583333333\tAverage Loss: 0.9421112197795177\n",
            "\tTest: Average Accuracy: 0.621875\tAverage Loss: 1.0818062241935442\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.682421875\tAverage Loss: 0.9182875478902187\n",
            "\tTest: Average Accuracy: 0.6276041666666666\tAverage Loss: 1.0651740380911454\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.6932291666666667\tAverage Loss: 0.8954289593260943\n",
            "\tTest: Average Accuracy: 0.6333333333333333\tAverage Loss: 1.0494383213055096\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.7009114583333333\tAverage Loss: 0.873466966007474\n",
            "\tTest: Average Accuracy: 0.6380208333333334\tAverage Loss: 1.0345322026947124\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.711328125\tAverage Loss: 0.852339471951431\n",
            "\tTest: Average Accuracy: 0.6442708333333333\tAverage Loss: 1.0203928909341486\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.7178385416666667\tAverage Loss: 0.8319899038160009\n",
            "\tTest: Average Accuracy: 0.6489583333333333\tAverage Loss: 1.006961651766934\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.72421875\tAverage Loss: 0.8123668265747175\n",
            "\tTest: Average Accuracy: 0.653125\tAverage Loss: 0.9941843120665903\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.7317708333333334\tAverage Loss: 0.793423461394343\n",
            "\tTest: Average Accuracy: 0.6572916666666667\tAverage Loss: 0.9820119860029662\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.7393229166666667\tAverage Loss: 0.7751170105889646\n",
            "\tTest: Average Accuracy: 0.6598958333333333\tAverage Loss: 0.9704015166261805\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.7451822916666667\tAverage Loss: 0.7574082933977154\n",
            "\tTest: Average Accuracy: 0.6640625\tAverage Loss: 0.9593152879828015\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.7522135416666667\tAverage Loss: 0.7402619489594824\n",
            "\tTest: Average Accuracy: 0.6671875\tAverage Loss: 0.9487204865310811\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.759765625\tAverage Loss: 0.7236468023584589\n",
            "\tTest: Average Accuracy: 0.6697916666666667\tAverage Loss: 0.9385881710232648\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.76640625\tAverage Loss: 0.7075358966699556\n",
            "\tTest: Average Accuracy: 0.6744791666666666\tAverage Loss: 0.9288924924488656\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.7720052083333333\tAverage Loss: 0.6919060670054378\n",
            "\tTest: Average Accuracy: 0.6760416666666667\tAverage Loss: 0.9196102466794857\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.7774739583333333\tAverage Loss: 0.6767372333200499\n",
            "\tTest: Average Accuracy: 0.6786458333333333\tAverage Loss: 0.9107207780095664\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.7829427083333333\tAverage Loss: 0.6620116601230098\n",
            "\tTest: Average Accuracy: 0.6828125\tAverage Loss: 0.9022061092620149\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.7901041666666667\tAverage Loss: 0.6477133496485666\n",
            "\tTest: Average Accuracy: 0.6859375\tAverage Loss: 0.8940510799254336\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.7951822916666667\tAverage Loss: 0.6338276032354511\n",
            "\tTest: Average Accuracy: 0.6911458333333333\tAverage Loss: 0.886243283863198\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.8006510416666667\tAverage Loss: 0.6203406976767715\n",
            "\tTest: Average Accuracy: 0.69375\tAverage Loss: 0.8787727190773276\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.805859375\tAverage Loss: 0.6072396202113334\n",
            "\tTest: Average Accuracy: 0.6984375\tAverage Loss: 0.871631216406616\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.8109375\tAverage Loss: 0.5945118541123164\n",
            "\tTest: Average Accuracy: 0.6989583333333333\tAverage Loss: 0.8648118036144273\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.815234375\tAverage Loss: 0.5821452443847818\n",
            "\tTest: Average Accuracy: 0.6994791666666667\tAverage Loss: 0.8583081488723604\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.8208333333333333\tAverage Loss: 0.5701279665090195\n",
            "\tTest: Average Accuracy: 0.7020833333333333\tAverage Loss: 0.8521141550212538\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.8248697916666666\tAverage Loss: 0.5584485841385347\n",
            "\tTest: Average Accuracy: 0.7036458333333333\tAverage Loss: 0.8462237068058954\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.828515625\tAverage Loss: 0.5470961490402875\n",
            "\tTest: Average Accuracy: 0.70625\tAverage Loss: 0.840630536463293\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.83359375\tAverage Loss: 0.5360602873778272\n",
            "\tTest: Average Accuracy: 0.7078125\tAverage Loss: 0.835328162537979\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.837890625\tAverage Loss: 0.525331226868633\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 0.8303098601583403\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.84375\tAverage Loss: 0.5148997425955703\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 0.825568634547346\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.84921875\tAverage Loss: 0.5047570332569156\n",
            "\tTest: Average Accuracy: 0.7140625\tAverage Loss: 0.8210971910599224\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.8515625\tAverage Loss: 0.4948945719070167\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 0.8168879136208108\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.8545572916666667\tAverage Loss: 0.4853039819511025\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 0.8129328669185697\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.8579427083333333\tAverage Loss: 0.47597696458742383\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 0.8092238274540261\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.86171875\tAverage Loss: 0.46690527243215957\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 0.8057523367356253\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.8654947916666667\tAverage Loss: 0.4580807103059541\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 0.8025097649050359\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.8684895833333334\tAverage Loss: 0.44949514841512367\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 0.7994873744381515\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.87265625\tAverage Loss: 0.4411405417356501\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 0.7966763776111773\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.8748697916666667\tAverage Loss: 0.43300895341980294\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 0.7940679856126268\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.877734375\tAverage Loss: 0.425092579803293\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 0.7916534503433577\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.880859375\tAverage Loss: 0.41738377391358267\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 0.7894241014706308\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.884375\tAverage Loss: 0.4098750654052134\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 0.7873713811076491\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.8868489583333333\tAverage Loss: 0.40255917702329047\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 0.7854868772108097\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.8890625\tAverage Loss: 0.39542903937334195\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 0.7837623554725963\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.892578125\tAverage Loss: 0.3884778059115375\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 0.7821897889173912\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.8947916666666667\tAverage Loss: 0.38169886881104553\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 0.7807613846399962\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.8962239583333333\tAverage Loss: 0.3750858746365882\n",
            "\tTest: Average Accuracy: 0.7234375\tAverage Loss: 0.7794696076550915\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.8986979166666667\tAverage Loss: 0.368632737546353\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 0.7783072020751736\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.901953125\tAverage Loss: 0.3623336475622515\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 0.7772672095341429\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.9052083333333333\tAverage Loss: 0.3561830722839028\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 0.7763429840217231\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.9083333333333333\tAverage Loss: 0.35017575186992655\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 0.775528201437832\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.9098958333333333\tAverage Loss: 0.3443066886199129\n",
            "\tTest: Average Accuracy: 0.7276041666666667\tAverage Loss: 0.77481686164654\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.912109375\tAverage Loss: 0.33857113354930607\n",
            "\tTest: Average Accuracy: 0.728125\tAverage Loss: 0.7742032809335287\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.914453125\tAverage Loss: 0.33296457266355206\n",
            "\tTest: Average Accuracy: 0.728125\tAverage Loss: 0.7736820736060146\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.916796875\tAverage Loss: 0.3274827152644465\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 0.7732481227964975\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.9190104166666667\tAverage Loss: 0.32212148593658585\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 0.7728965420819929\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.9203125\tAverage Loss: 0.31687702129735257\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 0.7726226313772965\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.9223958333333333\tAverage Loss: 0.3117456722510036\n",
            "\tTest: Average Accuracy: 0.7302083333333333\tAverage Loss: 0.7724218332282266\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.924609375\tAverage Loss: 0.30672401184742604\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 0.772289699596529\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.9270833333333334\tAverage Loss: 0.30180884685386994\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 0.7722218836048179\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.930078125\tAverage Loss: 0.2969972270428636\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 0.7722141716603748\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.9319010416666667\tAverage Loss: 0.2922864412814803\n",
            "\tTest: Average Accuracy: 0.7333333333333333\tAverage Loss: 0.7722625625549893\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.9328125\tAverage Loss: 0.2876739885250554\n",
            "\tTest: Average Accuracy: 0.7364583333333333\tAverage Loss: 0.7723633784922044\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.934375\tAverage Loss: 0.2831575203596431\n",
            "\tTest: Average Accuracy: 0.7364583333333333\tAverage Loss: 0.772513368038036\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.9354166666666667\tAverage Loss: 0.2787347683399843\n",
            "\tTest: Average Accuracy: 0.7359375\tAverage Loss: 0.7727097541970742\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.938671875\tAverage Loss: 0.27440348149290006\n",
            "\tTest: Average Accuracy: 0.7359375\tAverage Loss: 0.7729502049017264\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.9403645833333333\tAverage Loss: 0.27016139463594285\n",
            "\tTest: Average Accuracy: 0.7354166666666667\tAverage Loss: 0.7732327423724181\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.9420572916666666\tAverage Loss: 0.26600623018648584\n",
            "\tTest: Average Accuracy: 0.7369791666666666\tAverage Loss: 0.7735556315051846\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.9432291666666667\tAverage Loss: 0.26193572074618693\n",
            "\tTest: Average Accuracy: 0.7390625\tAverage Loss: 0.7739172831033019\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.944921875\tAverage Loss: 0.25794763658701336\n",
            "\tTest: Average Accuracy: 0.7390625\tAverage Loss: 0.7743161881165241\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.9463541666666667\tAverage Loss: 0.2540398079009579\n",
            "\tTest: Average Accuracy: 0.7385416666666667\tAverage Loss: 0.7747508817837918\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.9477864583333333\tAverage Loss: 0.2502101386381243\n",
            "\tTest: Average Accuracy: 0.7390625\tAverage Loss: 0.7752199288121417\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.9497395833333333\tAverage Loss: 0.24645661290599405\n",
            "\tTest: Average Accuracy: 0.7390625\tAverage Loss: 0.7757219203345775\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.9510416666666667\tAverage Loss: 0.2427772962125595\n",
            "\tTest: Average Accuracy: 0.7395833333333334\tAverage Loss: 0.7762554760269903\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.9518229166666666\tAverage Loss: 0.23917033364793605\n",
            "\tTest: Average Accuracy: 0.7390625\tAverage Loss: 0.7768192476148155\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.952734375\tAverage Loss: 0.23563394647075778\n",
            "\tTest: Average Accuracy: 0.7375\tAverage Loss: 0.7774119220458038\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.9532552083333333\tAverage Loss: 0.23216642798229561\n",
            "\tTest: Average Accuracy: 0.7369791666666666\tAverage Loss: 0.7780322237907881\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.9544270833333334\tAverage Loss: 0.22876613916103328\n",
            "\tTest: Average Accuracy: 0.7359375\tAverage Loss: 0.778678916307029\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=Sigmoid(), weight_initializer='uniform')\n",
        "\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that accuracy decreases a bit"
      ],
      "metadata": {
        "id": "quX-babH-sfV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuH4brMgB8UX",
        "outputId": "8e4fdad9-5684-4fb0-fb18-b629fde22dc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.0020833333333333333\tAverage Loss: 2.8478067757193704\n",
            "\tTest: Average Accuracy: 0.0703125\tAverage Loss: 2.746364898766791\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.00026041666666666666\tAverage Loss: 2.80980420758366\n",
            "\tTest: Average Accuracy: 0.09322916666666667\tAverage Loss: 2.7006727433540125\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.03515625\tAverage Loss: 2.7100830285907507\n",
            "\tTest: Average Accuracy: 0.17395833333333333\tAverage Loss: 2.5627408445360778\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.15859375\tAverage Loss: 2.5006455074163796\n",
            "\tTest: Average Accuracy: 0.2390625\tAverage Loss: 2.3170082693570913\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.24739583333333334\tAverage Loss: 2.2382328286849638\n",
            "\tTest: Average Accuracy: 0.2869791666666667\tAverage Loss: 2.092417892975507\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.31471354166666665\tAverage Loss: 2.038811124980955\n",
            "\tTest: Average Accuracy: 0.33229166666666665\tAverage Loss: 1.9332704689870976\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.3515625\tAverage Loss: 1.8930214901111104\n",
            "\tTest: Average Accuracy: 0.36041666666666666\tAverage Loss: 1.8170097286831564\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.391796875\tAverage Loss: 1.7836134800783099\n",
            "\tTest: Average Accuracy: 0.390625\tAverage Loss: 1.7302638668682522\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.42408854166666665\tAverage Loss: 1.6980424570700103\n",
            "\tTest: Average Accuracy: 0.40729166666666666\tAverage Loss: 1.6627948262187513\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.44778645833333336\tAverage Loss: 1.628079515472218\n",
            "\tTest: Average Accuracy: 0.4265625\tAverage Loss: 1.6080399444074769\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.4671875\tAverage Loss: 1.5685950622426428\n",
            "\tTest: Average Accuracy: 0.4395833333333333\tAverage Loss: 1.561749304409857\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.4884114583333333\tAverage Loss: 1.516285387090998\n",
            "\tTest: Average Accuracy: 0.45677083333333335\tAverage Loss: 1.5211796158915531\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.5045572916666666\tAverage Loss: 1.469087258110839\n",
            "\tTest: Average Accuracy: 0.47239583333333335\tAverage Loss: 1.4846114952955745\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.51953125\tAverage Loss: 1.4257619485412614\n",
            "\tTest: Average Accuracy: 0.48333333333333334\tAverage Loss: 1.4510186773663523\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.533984375\tAverage Loss: 1.3855746007117398\n",
            "\tTest: Average Accuracy: 0.49947916666666664\tAverage Loss: 1.4198262030694053\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.5483072916666667\tAverage Loss: 1.3480896215965867\n",
            "\tTest: Average Accuracy: 0.5130208333333334\tAverage Loss: 1.390722218592104\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.560546875\tAverage Loss: 1.31303597499238\n",
            "\tTest: Average Accuracy: 0.5270833333333333\tAverage Loss: 1.3635272946789778\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.5735677083333334\tAverage Loss: 1.2802038786607264\n",
            "\tTest: Average Accuracy: 0.5322916666666667\tAverage Loss: 1.338099102415559\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.5805989583333333\tAverage Loss: 1.2493779604383726\n",
            "\tTest: Average Accuracy: 0.5432291666666667\tAverage Loss: 1.314281977000491\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.5884114583333333\tAverage Loss: 1.2203203218132443\n",
            "\tTest: Average Accuracy: 0.5557291666666667\tAverage Loss: 1.2919017759211509\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.5967447916666667\tAverage Loss: 1.1927874001090075\n",
            "\tTest: Average Accuracy: 0.5583333333333333\tAverage Loss: 1.2707813153350525\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.6061197916666666\tAverage Loss: 1.1665535742580009\n",
            "\tTest: Average Accuracy: 0.5625\tAverage Loss: 1.250755571832475\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.612890625\tAverage Loss: 1.141426509267606\n",
            "\tTest: Average Accuracy: 0.5651041666666666\tAverage Loss: 1.2316807395001432\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.6203125\tAverage Loss: 1.117252383516465\n",
            "\tTest: Average Accuracy: 0.5697916666666667\tAverage Loss: 1.2134378177029501\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.6278645833333333\tAverage Loss: 1.093914451900704\n",
            "\tTest: Average Accuracy: 0.5817708333333333\tAverage Loss: 1.1959317836186056\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.6365885416666667\tAverage Loss: 1.071327934811213\n",
            "\tTest: Average Accuracy: 0.5890625\tAverage Loss: 1.1790877760906713\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.6436197916666667\tAverage Loss: 1.049432671750113\n",
            "\tTest: Average Accuracy: 0.5979166666666667\tAverage Loss: 1.1628465014735168\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.6510416666666666\tAverage Loss: 1.0281849831132372\n",
            "\tTest: Average Accuracy: 0.6046875\tAverage Loss: 1.1471607125289498\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.658203125\tAverage Loss: 1.0075507961226127\n",
            "\tTest: Average Accuracy: 0.6098958333333333\tAverage Loss: 1.1319931694316157\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.666796875\tAverage Loss: 0.9875013673375034\n",
            "\tTest: Average Accuracy: 0.6161458333333333\tAverage Loss: 1.1173153072946844\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.673046875\tAverage Loss: 0.9680113010951497\n",
            "\tTest: Average Accuracy: 0.6192708333333333\tAverage Loss: 1.1031057678185634\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.679296875\tAverage Loss: 0.9490577412454597\n",
            "\tTest: Average Accuracy: 0.6244791666666667\tAverage Loss: 1.0893485769305735\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.687109375\tAverage Loss: 0.9306198599407552\n",
            "\tTest: Average Accuracy: 0.628125\tAverage Loss: 1.0760312622796673\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.692578125\tAverage Loss: 0.9126782927485723\n",
            "\tTest: Average Accuracy: 0.6307291666666667\tAverage Loss: 1.0631433107409565\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.6985677083333334\tAverage Loss: 0.8952145202533491\n",
            "\tTest: Average Accuracy: 0.634375\tAverage Loss: 1.0506752005233455\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.704296875\tAverage Loss: 0.8782103375836159\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 1.0386180159829066\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.7123697916666667\tAverage Loss: 0.8616475557245522\n",
            "\tTest: Average Accuracy: 0.646875\tAverage Loss: 1.0269634921283712\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.7196614583333333\tAverage Loss: 0.8455080161346927\n",
            "\tTest: Average Accuracy: 0.6494791666666667\tAverage Loss: 1.0157042654605226\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.7251302083333333\tAverage Loss: 0.8297739238795204\n",
            "\tTest: Average Accuracy: 0.653125\tAverage Loss: 1.0048340952961283\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.73125\tAverage Loss: 0.8144284284090837\n",
            "\tTest: Average Accuracy: 0.6520833333333333\tAverage Loss: 0.9943478334249513\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.7356770833333334\tAverage Loss: 0.7994563080927034\n",
            "\tTest: Average Accuracy: 0.6572916666666667\tAverage Loss: 0.984240980646065\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.7421875\tAverage Loss: 0.7848445745528089\n",
            "\tTest: Average Accuracy: 0.6614583333333334\tAverage Loss: 0.9745088443136567\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.7463541666666667\tAverage Loss: 0.7705828355423511\n",
            "\tTest: Average Accuracy: 0.6697916666666667\tAverage Loss: 0.9651455977325987\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.7520833333333333\tAverage Loss: 0.7566632928164633\n",
            "\tTest: Average Accuracy: 0.6682291666666667\tAverage Loss: 0.9561437216513456\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.7567708333333333\tAverage Loss: 0.7430802827669432\n",
            "\tTest: Average Accuracy: 0.6703125\tAverage Loss: 0.9474940909125037\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.7622395833333333\tAverage Loss: 0.7298294512737458\n",
            "\tTest: Average Accuracy: 0.6734375\tAverage Loss: 0.939186469968029\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.7677083333333333\tAverage Loss: 0.7169069242549805\n",
            "\tTest: Average Accuracy: 0.6739583333333333\tAverage Loss: 0.931209955596393\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.774609375\tAverage Loss: 0.7043087394967334\n",
            "\tTest: Average Accuracy: 0.675\tAverage Loss: 0.9235531761024682\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.7791666666666667\tAverage Loss: 0.6920304215249466\n",
            "\tTest: Average Accuracy: 0.6755208333333333\tAverage Loss: 0.9162044092005991\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.7842447916666667\tAverage Loss: 0.6800665250152761\n",
            "\tTest: Average Accuracy: 0.678125\tAverage Loss: 0.9091518332028327\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.7889322916666667\tAverage Loss: 0.6684102681071742\n",
            "\tTest: Average Accuracy: 0.6802083333333333\tAverage Loss: 0.9023839141930217\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.7928385416666667\tAverage Loss: 0.6570534967150875\n",
            "\tTest: Average Accuracy: 0.6817708333333333\tAverage Loss: 0.8958897382245027\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.798046875\tAverage Loss: 0.6459870038106528\n",
            "\tTest: Average Accuracy: 0.6848958333333334\tAverage Loss: 0.8896591320378714\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.8020833333333334\tAverage Loss: 0.6352010044117903\n",
            "\tTest: Average Accuracy: 0.6848958333333334\tAverage Loss: 0.883682584738811\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.805078125\tAverage Loss: 0.6246855598935983\n",
            "\tTest: Average Accuracy: 0.6895833333333333\tAverage Loss: 0.8779510789819193\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.808984375\tAverage Loss: 0.6144308610024588\n",
            "\tTest: Average Accuracy: 0.6901041666666666\tAverage Loss: 0.8724559248432039\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.8127604166666667\tAverage Loss: 0.6044273750117983\n",
            "\tTest: Average Accuracy: 0.6947916666666667\tAverage Loss: 0.8671886402488688\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.81640625\tAverage Loss: 0.5946659001607271\n",
            "\tTest: Average Accuracy: 0.6942708333333333\tAverage Loss: 0.8621408873891152\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.8200520833333333\tAverage Loss: 0.5851375709564884\n",
            "\tTest: Average Accuracy: 0.6989583333333333\tAverage Loss: 0.8573044580750825\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.8243489583333333\tAverage Loss: 0.5758338450199\n",
            "\tTest: Average Accuracy: 0.7010416666666667\tAverage Loss: 0.8526712942735984\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.828125\tAverage Loss: 0.5667464883932546\n",
            "\tTest: Average Accuracy: 0.7015625\tAverage Loss: 0.8482335285522744\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.8311197916666667\tAverage Loss: 0.5578675661480967\n",
            "\tTest: Average Accuracy: 0.7020833333333333\tAverage Loss: 0.8439835311549216\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.833203125\tAverage Loss: 0.5491894394227442\n",
            "\tTest: Average Accuracy: 0.7046875\tAverage Loss: 0.8399139543502145\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.8368489583333333\tAverage Loss: 0.5407047676921135\n",
            "\tTest: Average Accuracy: 0.7078125\tAverage Loss: 0.8360177688396583\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.8404947916666666\tAverage Loss: 0.5324065146488212\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 0.8322882901907628\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.84375\tAverage Loss: 0.5242879563173939\n",
            "\tTest: Average Accuracy: 0.7130208333333333\tAverage Loss: 0.8287191951348873\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.8466145833333333\tAverage Loss: 0.5163426902007562\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 0.8253045283724912\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.8493489583333333\tAverage Loss: 0.5085646441034506\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 0.8220387006745302\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.8522135416666666\tAverage Loss: 0.5009480828533807\n",
            "\tTest: Average Accuracy: 0.71875\tAverage Loss: 0.8189164789124367\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.85546875\tAverage Loss: 0.4934876107209413\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 0.8159329684440723\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.8580729166666666\tAverage Loss: 0.4861781672521774\n",
            "\tTest: Average Accuracy: 0.721875\tAverage Loss: 0.813083588216791\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.8596354166666667\tAverage Loss: 0.47901501474527386\n",
            "\tTest: Average Accuracy: 0.721875\tAverage Loss: 0.8103640391487762\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.861328125\tAverage Loss: 0.4719937167273912\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 0.8077702668301244\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.8635416666666667\tAverage Loss: 0.4651101082897368\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 0.8052984202031824\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.866796875\tAverage Loss: 0.45836026064105856\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 0.8029448084037077\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.86953125\tAverage Loss: 0.45174044340635217\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 0.8007058582068114\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.8721354166666667\tAverage Loss: 0.44524708876174646\n",
            "\tTest: Average Accuracy: 0.7276041666666667\tAverage Loss: 0.7985780745284832\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.874609375\tAverage Loss: 0.4388767612272803\n",
            "\tTest: Average Accuracy: 0.7296875\tAverage Loss: 0.7965580062747895\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.8776041666666666\tAverage Loss: 0.432626135743614\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 0.79464221952685\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.8799479166666667\tAverage Loss: 0.4264919847954113\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 0.792827279524752\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.8833333333333333\tAverage Loss: 0.4204711734396792\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 0.7911097421250518\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.8854166666666666\tAverage Loss: 0.41456065982026946\n",
            "\tTest: Average Accuracy: 0.7333333333333333\tAverage Loss: 0.7894861544577184\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.8875\tAverage Loss: 0.40875749841819675\n",
            "\tTest: Average Accuracy: 0.7333333333333333\tAverage Loss: 0.7879530636167817\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.8901041666666667\tAverage Loss: 0.40305884375812\n",
            "\tTest: Average Accuracy: 0.734375\tAverage Loss: 0.7865070315885864\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.8920572916666667\tAverage Loss: 0.39746195315721455\n",
            "\tTest: Average Accuracy: 0.734375\tAverage Loss: 0.7851446543444861\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.893359375\tAverage Loss: 0.39196418796787175\n",
            "\tTest: Average Accuracy: 0.7338541666666667\tAverage Loss: 0.7838625830706863\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.8951822916666666\tAverage Loss: 0.38656301340192384\n",
            "\tTest: Average Accuracy: 0.7338541666666667\tAverage Loss: 0.7826575457748036\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.8979166666666667\tAverage Loss: 0.3812559973789121\n",
            "\tTest: Average Accuracy: 0.7354166666666667\tAverage Loss: 0.7815263678839911\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.9006510416666667\tAverage Loss: 0.37604080896609154\n",
            "\tTest: Average Accuracy: 0.7375\tAverage Loss: 0.7804659908473229\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.9022135416666667\tAverage Loss: 0.3709152169490714\n",
            "\tTest: Average Accuracy: 0.7385416666666667\tAverage Loss: 0.7794734881229122\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.9040364583333333\tAverage Loss: 0.3658770889381801\n",
            "\tTest: Average Accuracy: 0.7385416666666667\tAverage Loss: 0.7785460782328728\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.905859375\tAverage Loss: 0.36092439118873426\n",
            "\tTest: Average Accuracy: 0.7380208333333333\tAverage Loss: 0.7776811347719076\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.908984375\tAverage Loss: 0.35605518899078015\n",
            "\tTest: Average Accuracy: 0.7395833333333334\tAverage Loss: 0.7768761933265396\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.9110677083333333\tAverage Loss: 0.351267647085692\n",
            "\tTest: Average Accuracy: 0.7401041666666667\tAverage Loss: 0.776128955202387\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.9125\tAverage Loss: 0.3465600291687051\n",
            "\tTest: Average Accuracy: 0.7411458333333333\tAverage Loss: 0.7754372877335497\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.91484375\tAverage Loss: 0.34193069528099035\n",
            "\tTest: Average Accuracy: 0.7401041666666667\tAverage Loss: 0.7747992208966971\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.9161458333333333\tAverage Loss: 0.33737809596624885\n",
            "\tTest: Average Accuracy: 0.7411458333333333\tAverage Loss: 0.7742129401208427\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.91875\tAverage Loss: 0.33290076260630047\n",
            "\tTest: Average Accuracy: 0.7427083333333333\tAverage Loss: 0.7736767756321641\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.9201822916666667\tAverage Loss: 0.3284972943248539\n",
            "\tTest: Average Accuracy: 0.7427083333333333\tAverage Loss: 0.7731891892913237\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.921875\tAverage Loss: 0.32416634295709307\n",
            "\tTest: Average Accuracy: 0.7432291666666667\tAverage Loss: 0.7727487604005304\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=Tanh(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy decreases on train data"
      ],
      "metadata": {
        "id": "fhWR04HW_ALG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Pf9U26CTE-Dl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db51beea-ceb8-4058-a92b-31cbf76e3445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.01953125\tAverage Loss: 2.9211931768861317\n",
            "\tTest: Average Accuracy: 0.06666666666666667\tAverage Loss: 2.6457686047697253\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.12682291666666667\tAverage Loss: 2.5752739203425334\n",
            "\tTest: Average Accuracy: 0.2359375\tAverage Loss: 2.2978436638081075\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.23567708333333334\tAverage Loss: 2.253133777091367\n",
            "\tTest: Average Accuracy: 0.3182291666666667\tAverage Loss: 2.0670521913937185\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.32526041666666666\tAverage Loss: 2.0436209583701683\n",
            "\tTest: Average Accuracy: 0.37135416666666665\tAverage Loss: 1.8993783634000652\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.3848958333333333\tAverage Loss: 1.8957695666593433\n",
            "\tTest: Average Accuracy: 0.4161458333333333\tAverage Loss: 1.7874611911201523\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.418359375\tAverage Loss: 1.7904895768034517\n",
            "\tTest: Average Accuracy: 0.43645833333333334\tAverage Loss: 1.7100187324372367\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.4471354166666667\tAverage Loss: 1.7099220355912874\n",
            "\tTest: Average Accuracy: 0.45\tAverage Loss: 1.651079093860331\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.46966145833333334\tAverage Loss: 1.6425234543898803\n",
            "\tTest: Average Accuracy: 0.46510416666666665\tAverage Loss: 1.601226552221409\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.4875\tAverage Loss: 1.581778178721666\n",
            "\tTest: Average Accuracy: 0.4744791666666667\tAverage Loss: 1.5550346501647156\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.5057291666666667\tAverage Loss: 1.5252510143642548\n",
            "\tTest: Average Accuracy: 0.4822916666666667\tAverage Loss: 1.5115451653739824\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.5227864583333334\tAverage Loss: 1.4718754022932694\n",
            "\tTest: Average Accuracy: 0.4973958333333333\tAverage Loss: 1.4696696099482702\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.5369791666666667\tAverage Loss: 1.4211677940563816\n",
            "\tTest: Average Accuracy: 0.5078125\tAverage Loss: 1.4296209564423674\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.5506510416666667\tAverage Loss: 1.3728220312275843\n",
            "\tTest: Average Accuracy: 0.5177083333333333\tAverage Loss: 1.3920348709968495\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.563671875\tAverage Loss: 1.3273432950086443\n",
            "\tTest: Average Accuracy: 0.5338541666666666\tAverage Loss: 1.3564893072850912\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.5786458333333333\tAverage Loss: 1.2848286865507732\n",
            "\tTest: Average Accuracy: 0.5458333333333333\tAverage Loss: 1.3242276381168552\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.59140625\tAverage Loss: 1.2454070088858245\n",
            "\tTest: Average Accuracy: 0.553125\tAverage Loss: 1.2944642999668774\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.6013020833333333\tAverage Loss: 1.208453494896852\n",
            "\tTest: Average Accuracy: 0.5609375\tAverage Loss: 1.266420925715754\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.610546875\tAverage Loss: 1.173644137820255\n",
            "\tTest: Average Accuracy: 0.5614583333333333\tAverage Loss: 1.2406030106812451\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.61875\tAverage Loss: 1.14118059231869\n",
            "\tTest: Average Accuracy: 0.5666666666666667\tAverage Loss: 1.216592232558657\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.6270833333333333\tAverage Loss: 1.1106898141934416\n",
            "\tTest: Average Accuracy: 0.5760416666666667\tAverage Loss: 1.1944966059158402\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.6388020833333333\tAverage Loss: 1.0819448596210706\n",
            "\tTest: Average Accuracy: 0.5833333333333334\tAverage Loss: 1.1751386111873037\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.6458333333333334\tAverage Loss: 1.0549880688735191\n",
            "\tTest: Average Accuracy: 0.5864583333333333\tAverage Loss: 1.1569131044674068\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.6537760416666667\tAverage Loss: 1.0294152774087868\n",
            "\tTest: Average Accuracy: 0.5875\tAverage Loss: 1.1407072725364997\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.6587239583333333\tAverage Loss: 1.0053950535577771\n",
            "\tTest: Average Accuracy: 0.5885416666666666\tAverage Loss: 1.125447904700309\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.6661458333333333\tAverage Loss: 0.9826914860768992\n",
            "\tTest: Average Accuracy: 0.5942708333333333\tAverage Loss: 1.1124665985117297\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.6721354166666667\tAverage Loss: 0.9613295905868594\n",
            "\tTest: Average Accuracy: 0.6005208333333333\tAverage Loss: 1.1008579783761847\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.6791666666666667\tAverage Loss: 0.9410622303675453\n",
            "\tTest: Average Accuracy: 0.6026041666666667\tAverage Loss: 1.090845914292931\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.6852864583333333\tAverage Loss: 0.9219296892308273\n",
            "\tTest: Average Accuracy: 0.6036458333333333\tAverage Loss: 1.0809508587236267\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.6915364583333333\tAverage Loss: 0.903495135258192\n",
            "\tTest: Average Accuracy: 0.6072916666666667\tAverage Loss: 1.072237228362833\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.6983072916666667\tAverage Loss: 0.8859626382595829\n",
            "\tTest: Average Accuracy: 0.6088541666666667\tAverage Loss: 1.064238226705822\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.7055989583333333\tAverage Loss: 0.8692250083969\n",
            "\tTest: Average Accuracy: 0.609375\tAverage Loss: 1.0562937568143953\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.7104166666666667\tAverage Loss: 0.8528291763904985\n",
            "\tTest: Average Accuracy: 0.6125\tAverage Loss: 1.049298582192017\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.7143229166666667\tAverage Loss: 0.8369995997095001\n",
            "\tTest: Average Accuracy: 0.61875\tAverage Loss: 1.042099035754428\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.7209635416666667\tAverage Loss: 0.8216408428526815\n",
            "\tTest: Average Accuracy: 0.6229166666666667\tAverage Loss: 1.035517746598424\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.7270833333333333\tAverage Loss: 0.8065861173264016\n",
            "\tTest: Average Accuracy: 0.6270833333333333\tAverage Loss: 1.0300031479988525\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.7326822916666667\tAverage Loss: 0.7920624803595523\n",
            "\tTest: Average Accuracy: 0.63125\tAverage Loss: 1.024014553988484\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.7375\tAverage Loss: 0.7779142209127703\n",
            "\tTest: Average Accuracy: 0.6348958333333333\tAverage Loss: 1.0184958002363214\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.7428385416666666\tAverage Loss: 0.7640172381433314\n",
            "\tTest: Average Accuracy: 0.6333333333333333\tAverage Loss: 1.013461684989665\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.7471354166666667\tAverage Loss: 0.7505153818805222\n",
            "\tTest: Average Accuracy: 0.6333333333333333\tAverage Loss: 1.0090462179327766\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.7526041666666666\tAverage Loss: 0.7372108713342495\n",
            "\tTest: Average Accuracy: 0.6348958333333333\tAverage Loss: 1.0046456327651305\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.755859375\tAverage Loss: 0.7242776655100085\n",
            "\tTest: Average Accuracy: 0.634375\tAverage Loss: 1.0003420546197839\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.761328125\tAverage Loss: 0.7115732352744109\n",
            "\tTest: Average Accuracy: 0.6380208333333334\tAverage Loss: 0.9958361139141799\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.766015625\tAverage Loss: 0.6991223835900676\n",
            "\tTest: Average Accuracy: 0.6416666666666667\tAverage Loss: 0.9927043421322819\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.7700520833333333\tAverage Loss: 0.6869387477950961\n",
            "\tTest: Average Accuracy: 0.6453125\tAverage Loss: 0.9887303672883544\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.7743489583333333\tAverage Loss: 0.6750175179234691\n",
            "\tTest: Average Accuracy: 0.6484375\tAverage Loss: 0.9847599115108643\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.7779947916666666\tAverage Loss: 0.6632613297244038\n",
            "\tTest: Average Accuracy: 0.653125\tAverage Loss: 0.9811608611570981\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.78203125\tAverage Loss: 0.6518001676423705\n",
            "\tTest: Average Accuracy: 0.6520833333333333\tAverage Loss: 0.9773929263382786\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.7850260416666667\tAverage Loss: 0.6405383396213147\n",
            "\tTest: Average Accuracy: 0.65625\tAverage Loss: 0.9747304893351956\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.7888020833333333\tAverage Loss: 0.6295815037684747\n",
            "\tTest: Average Accuracy: 0.65625\tAverage Loss: 0.9720629739433668\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.79296875\tAverage Loss: 0.6187305798304177\n",
            "\tTest: Average Accuracy: 0.6583333333333333\tAverage Loss: 0.9693128108780236\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.7984375\tAverage Loss: 0.6081678150116313\n",
            "\tTest: Average Accuracy: 0.6614583333333334\tAverage Loss: 0.9666390945197206\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.8033854166666666\tAverage Loss: 0.5977529002913681\n",
            "\tTest: Average Accuracy: 0.6614583333333334\tAverage Loss: 0.9645773831668862\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.8059895833333334\tAverage Loss: 0.5876667847321259\n",
            "\tTest: Average Accuracy: 0.6625\tAverage Loss: 0.9624313237207553\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.8108072916666667\tAverage Loss: 0.577839227836742\n",
            "\tTest: Average Accuracy: 0.6635416666666667\tAverage Loss: 0.9600440444706373\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.8143229166666667\tAverage Loss: 0.5682100177769598\n",
            "\tTest: Average Accuracy: 0.6630208333333333\tAverage Loss: 0.9580339771498962\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.8180989583333333\tAverage Loss: 0.5587697905636764\n",
            "\tTest: Average Accuracy: 0.6635416666666667\tAverage Loss: 0.9555255720720506\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.821484375\tAverage Loss: 0.5494858204323634\n",
            "\tTest: Average Accuracy: 0.6666666666666666\tAverage Loss: 0.9539911123399957\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.8265625\tAverage Loss: 0.5405263931326257\n",
            "\tTest: Average Accuracy: 0.66875\tAverage Loss: 0.9521173828544202\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.8307291666666666\tAverage Loss: 0.5314918361801542\n",
            "\tTest: Average Accuracy: 0.6734375\tAverage Loss: 0.950408107867048\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.83359375\tAverage Loss: 0.522907388199973\n",
            "\tTest: Average Accuracy: 0.6744791666666666\tAverage Loss: 0.9495762897738527\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.83671875\tAverage Loss: 0.5142711565419417\n",
            "\tTest: Average Accuracy: 0.6734375\tAverage Loss: 0.9489452084700517\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.840625\tAverage Loss: 0.506045788331229\n",
            "\tTest: Average Accuracy: 0.6739583333333333\tAverage Loss: 0.9478126428633497\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.8447916666666667\tAverage Loss: 0.4980070181313396\n",
            "\tTest: Average Accuracy: 0.675\tAverage Loss: 0.9475904973354793\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.84921875\tAverage Loss: 0.4898825352678423\n",
            "\tTest: Average Accuracy: 0.6739583333333333\tAverage Loss: 0.946763399969395\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.8509114583333334\tAverage Loss: 0.48212833146115186\n",
            "\tTest: Average Accuracy: 0.6744791666666666\tAverage Loss: 0.9466094040775073\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.8528645833333334\tAverage Loss: 0.4743131875193403\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 0.9461068401724024\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.8545572916666667\tAverage Loss: 0.466793781513832\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 0.9459639498443451\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.8572916666666667\tAverage Loss: 0.4593807078497933\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 0.946132017153303\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.8604166666666667\tAverage Loss: 0.4520887810304234\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 0.945965806113567\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.8627604166666667\tAverage Loss: 0.4448076711918059\n",
            "\tTest: Average Accuracy: 0.6770833333333334\tAverage Loss: 0.9464437041337772\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.8645833333333334\tAverage Loss: 0.4377430984093736\n",
            "\tTest: Average Accuracy: 0.6786458333333333\tAverage Loss: 0.945979546694134\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.8669270833333333\tAverage Loss: 0.43076924237245995\n",
            "\tTest: Average Accuracy: 0.6765625\tAverage Loss: 0.9465371358018252\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.8686197916666667\tAverage Loss: 0.42411143923205624\n",
            "\tTest: Average Accuracy: 0.6765625\tAverage Loss: 0.9474562685922562\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.8713541666666667\tAverage Loss: 0.4172657980403353\n",
            "\tTest: Average Accuracy: 0.6760416666666667\tAverage Loss: 0.9477903417510533\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.873828125\tAverage Loss: 0.41076223840661524\n",
            "\tTest: Average Accuracy: 0.6729166666666667\tAverage Loss: 0.9484846977620093\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.8768229166666667\tAverage Loss: 0.40427981785223005\n",
            "\tTest: Average Accuracy: 0.6760416666666667\tAverage Loss: 0.949417708480198\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.8779947916666667\tAverage Loss: 0.398005990324104\n",
            "\tTest: Average Accuracy: 0.6760416666666667\tAverage Loss: 0.9502347099933797\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.8802083333333334\tAverage Loss: 0.39177774377210745\n",
            "\tTest: Average Accuracy: 0.6770833333333334\tAverage Loss: 0.9515571547566088\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.8825520833333333\tAverage Loss: 0.38571054626028584\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 0.9527554235517727\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.8848958333333333\tAverage Loss: 0.37959914656926086\n",
            "\tTest: Average Accuracy: 0.6770833333333334\tAverage Loss: 0.9543113560383681\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.8869791666666667\tAverage Loss: 0.373782539679506\n",
            "\tTest: Average Accuracy: 0.6786458333333333\tAverage Loss: 0.9556286108453401\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.88984375\tAverage Loss: 0.36791420708284583\n",
            "\tTest: Average Accuracy: 0.6791666666666667\tAverage Loss: 0.9569506948785697\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.891796875\tAverage Loss: 0.3621836402040047\n",
            "\tTest: Average Accuracy: 0.6796875\tAverage Loss: 0.9585033969298237\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.8947916666666667\tAverage Loss: 0.35648745384381414\n",
            "\tTest: Average Accuracy: 0.6802083333333333\tAverage Loss: 0.9597737240074306\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.8963541666666667\tAverage Loss: 0.3507868063689987\n",
            "\tTest: Average Accuracy: 0.6786458333333333\tAverage Loss: 0.9619791293968\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.8981770833333333\tAverage Loss: 0.345425157137622\n",
            "\tTest: Average Accuracy: 0.6802083333333333\tAverage Loss: 0.9626845709489565\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.9009114583333333\tAverage Loss: 0.34006255399487656\n",
            "\tTest: Average Accuracy: 0.6796875\tAverage Loss: 0.9651283654201882\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.9020833333333333\tAverage Loss: 0.33458405519553686\n",
            "\tTest: Average Accuracy: 0.6796875\tAverage Loss: 0.9666514552895129\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.90390625\tAverage Loss: 0.32947695736620836\n",
            "\tTest: Average Accuracy: 0.6833333333333333\tAverage Loss: 0.9685476662909979\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.905078125\tAverage Loss: 0.3243262974093865\n",
            "\tTest: Average Accuracy: 0.6822916666666666\tAverage Loss: 0.9702562709544789\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.9078125\tAverage Loss: 0.3192777404063742\n",
            "\tTest: Average Accuracy: 0.6822916666666666\tAverage Loss: 0.9722396331509997\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.9106770833333333\tAverage Loss: 0.314204516136925\n",
            "\tTest: Average Accuracy: 0.684375\tAverage Loss: 0.974157280315389\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.9122395833333333\tAverage Loss: 0.30928991960336255\n",
            "\tTest: Average Accuracy: 0.6838541666666667\tAverage Loss: 0.9760482080539054\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.9141927083333333\tAverage Loss: 0.304490030476238\n",
            "\tTest: Average Accuracy: 0.6854166666666667\tAverage Loss: 0.9783780512187238\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.9165364583333333\tAverage Loss: 0.2996806467114276\n",
            "\tTest: Average Accuracy: 0.6864583333333333\tAverage Loss: 0.9807737356817852\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.9182291666666667\tAverage Loss: 0.29498414458807637\n",
            "\tTest: Average Accuracy: 0.6864583333333333\tAverage Loss: 0.9825274671719987\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.9203125\tAverage Loss: 0.29034571931992825\n",
            "\tTest: Average Accuracy: 0.6859375\tAverage Loss: 0.9849856699099526\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.9223958333333333\tAverage Loss: 0.28588487988492883\n",
            "\tTest: Average Accuracy: 0.6864583333333333\tAverage Loss: 0.9865332702169805\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.9234375\tAverage Loss: 0.2814538007039226\n",
            "\tTest: Average Accuracy: 0.6875\tAverage Loss: 0.9894538878777467\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.9251302083333334\tAverage Loss: 0.27707618436547177\n",
            "\tTest: Average Accuracy: 0.6864583333333333\tAverage Loss: 0.9917108364219246\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIVXXUwvMuvW"
      },
      "source": [
        "#true learning rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CoYCp0rhMuNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a8d4fa-eb1d-4e03-9c5e-3faff97023f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.10325520833333333\tAverage Loss: 2.6876997378367857\n",
            "\tTest: Average Accuracy: 0.28177083333333336\tAverage Loss: 2.079665651572678\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.3561197916666667\tAverage Loss: 1.8543720102140786\n",
            "\tTest: Average Accuracy: 0.4166666666666667\tAverage Loss: 1.705073221715838\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.4578125\tAverage Loss: 1.5725923736775727\n",
            "\tTest: Average Accuracy: 0.4713541666666667\tAverage Loss: 1.552846314322685\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.5109375\tAverage Loss: 1.4019558939286552\n",
            "\tTest: Average Accuracy: 0.5020833333333333\tAverage Loss: 1.4526151274266224\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.5526041666666667\tAverage Loss: 1.2684704891113485\n",
            "\tTest: Average Accuracy: 0.5286458333333334\tAverage Loss: 1.3777548907745536\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.58984375\tAverage Loss: 1.1591953749416788\n",
            "\tTest: Average Accuracy: 0.5390625\tAverage Loss: 1.312668985510886\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.6203125\tAverage Loss: 1.0672283239868405\n",
            "\tTest: Average Accuracy: 0.5614583333333333\tAverage Loss: 1.2522563490655998\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.6470052083333333\tAverage Loss: 0.9869913079130901\n",
            "\tTest: Average Accuracy: 0.5822916666666667\tAverage Loss: 1.1957617601067083\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.6700520833333333\tAverage Loss: 0.9154270864699708\n",
            "\tTest: Average Accuracy: 0.596875\tAverage Loss: 1.1438377847702057\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.6930989583333333\tAverage Loss: 0.8511998174347775\n",
            "\tTest: Average Accuracy: 0.6083333333333333\tAverage Loss: 1.099008243400387\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.7141927083333334\tAverage Loss: 0.7936226385801829\n",
            "\tTest: Average Accuracy: 0.6255208333333333\tAverage Loss: 1.060961396184491\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.73515625\tAverage Loss: 0.741886992482223\n",
            "\tTest: Average Accuracy: 0.6401041666666667\tAverage Loss: 1.027785331354015\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.7524739583333333\tAverage Loss: 0.6950158927767919\n",
            "\tTest: Average Accuracy: 0.6473958333333333\tAverage Loss: 0.9984346494302209\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.7674479166666667\tAverage Loss: 0.6521720604681204\n",
            "\tTest: Average Accuracy: 0.6536458333333334\tAverage Loss: 0.9731268835387821\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.78515625\tAverage Loss: 0.6128134539151132\n",
            "\tTest: Average Accuracy: 0.6645833333333333\tAverage Loss: 0.9520858476475254\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.7983072916666667\tAverage Loss: 0.5765831175421814\n",
            "\tTest: Average Accuracy: 0.665625\tAverage Loss: 0.9346350950746624\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.8109375\tAverage Loss: 0.5431183547815173\n",
            "\tTest: Average Accuracy: 0.6697916666666667\tAverage Loss: 0.9202868318425307\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.8259114583333333\tAverage Loss: 0.512110627181335\n",
            "\tTest: Average Accuracy: 0.6776041666666667\tAverage Loss: 0.9089855209771166\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.841015625\tAverage Loss: 0.4833236535040764\n",
            "\tTest: Average Accuracy: 0.6838541666666667\tAverage Loss: 0.9003942153865059\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.8532552083333333\tAverage Loss: 0.4565303867476679\n",
            "\tTest: Average Accuracy: 0.6875\tAverage Loss: 0.8940567930425941\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.8614583333333333\tAverage Loss: 0.4315298293712274\n",
            "\tTest: Average Accuracy: 0.6916666666666667\tAverage Loss: 0.8895446360761828\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.8720052083333333\tAverage Loss: 0.40817850902502845\n",
            "\tTest: Average Accuracy: 0.6947916666666667\tAverage Loss: 0.8864726388478874\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.8815104166666666\tAverage Loss: 0.38636312326615235\n",
            "\tTest: Average Accuracy: 0.6984375\tAverage Loss: 0.8845081360629637\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.8920572916666667\tAverage Loss: 0.3659563417062379\n",
            "\tTest: Average Accuracy: 0.7026041666666667\tAverage Loss: 0.883381350189277\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.898046875\tAverage Loss: 0.34683933721571886\n",
            "\tTest: Average Accuracy: 0.7046875\tAverage Loss: 0.8828802259562943\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.9053385416666667\tAverage Loss: 0.32890827016851903\n",
            "\tTest: Average Accuracy: 0.7067708333333333\tAverage Loss: 0.8828704818054448\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.9123697916666667\tAverage Loss: 0.3120668879887805\n",
            "\tTest: Average Accuracy: 0.7083333333333334\tAverage Loss: 0.8832963254859328\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.9177083333333333\tAverage Loss: 0.2962276005280328\n",
            "\tTest: Average Accuracy: 0.7088541666666667\tAverage Loss: 0.8841413087272675\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.926171875\tAverage Loss: 0.28131114671219043\n",
            "\tTest: Average Accuracy: 0.7078125\tAverage Loss: 0.8853955250984894\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.9315104166666667\tAverage Loss: 0.26724959145898747\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 0.8870609267323984\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.9361979166666666\tAverage Loss: 0.2539855219874203\n",
            "\tTest: Average Accuracy: 0.7125\tAverage Loss: 0.8891513631497833\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.9404947916666667\tAverage Loss: 0.24146966137832482\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 0.8916770832375606\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.9455729166666667\tAverage Loss: 0.22965891799306334\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 0.8946361132690626\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.94921875\tAverage Loss: 0.21851554370846973\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 0.8980167928726588\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.9536458333333333\tAverage Loss: 0.208012260156332\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 0.901800704001606\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.9575520833333333\tAverage Loss: 0.1981250296491245\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 0.905971820033015\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.9606770833333333\tAverage Loss: 0.18881581617276597\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 0.9105213788249064\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.9640625\tAverage Loss: 0.1800426560175991\n",
            "\tTest: Average Accuracy: 0.7213541666666666\tAverage Loss: 0.9154299972995603\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.9665364583333333\tAverage Loss: 0.17176846253768938\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 0.9206596527445848\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.9686197916666667\tAverage Loss: 0.16396098209800403\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 0.9261596207035354\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.9705729166666667\tAverage Loss: 0.1565916507352446\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 0.9318731077868256\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.9717447916666667\tAverage Loss: 0.14963503297108746\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 0.9377440789557805\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.9747395833333333\tAverage Loss: 0.1430685319669608\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 0.9437229383430581\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.9776041666666667\tAverage Loss: 0.1368717356454832\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 0.9497684960660476\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.9791666666666666\tAverage Loss: 0.1310254295147167\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 0.9558471412572753\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.9803385416666667\tAverage Loss: 0.1255109138674736\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 0.961931542573581\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.982421875\tAverage Loss: 0.12030974707280467\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 0.9679999377774301\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.9842447916666667\tAverage Loss: 0.11540362825406536\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 0.9740358889229322\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.9848958333333333\tAverage Loss: 0.11077435540894819\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 0.9800279768395672\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.987109375\tAverage Loss: 0.10640391930748132\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 0.9859690135844533\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.9885416666666667\tAverage Loss: 0.10227473080032598\n",
            "\tTest: Average Accuracy: 0.7192708333333333\tAverage Loss: 0.9918547200071335\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.9891927083333333\tAverage Loss: 0.09836991283702817\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 0.9976822415582173\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.990234375\tAverage Loss: 0.09467356477469012\n",
            "\tTest: Average Accuracy: 0.71875\tAverage Loss: 1.0034490259089757\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.991015625\tAverage Loss: 0.09117093575986036\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.0091523317738127\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.9919270833333333\tAverage Loss: 0.0878484976690538\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.0147892689868492\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.992578125\tAverage Loss: 0.08469394024949087\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.0203570973168887\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.9930989583333333\tAverage Loss: 0.08169611452281518\n",
            "\tTest: Average Accuracy: 0.71875\tAverage Loss: 1.0258535480249973\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.994140625\tAverage Loss: 0.07884494470409412\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.031277037003552\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.9944010416666667\tAverage Loss: 0.07613132408643075\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.0366267246626493\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.994921875\tAverage Loss: 0.07354700509086834\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.0419024345100696\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.9953125\tAverage Loss: 0.07108448780489773\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.0471044789218322\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.995703125\tAverage Loss: 0.06873690897359724\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 1.052233457598978\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.9959635416666667\tAverage Loss: 0.06649793651555479\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 1.0572900869755633\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.9959635416666667\tAverage Loss: 0.06436167880571571\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.0622750906151859\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.9962239583333333\tAverage Loss: 0.06232261705779981\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.0671891479292483\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.9966145833333333\tAverage Loss: 0.060375562536883955\n",
            "\tTest: Average Accuracy: 0.7140625\tAverage Loss: 1.0720328802066215\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.9967447916666666\tAverage Loss: 0.05851563306204433\n",
            "\tTest: Average Accuracy: 0.7135416666666666\tAverage Loss: 1.0768068543005116\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.9967447916666666\tAverage Loss: 0.0567382398367102\n",
            "\tTest: Average Accuracy: 0.7109375\tAverage Loss: 1.0815115959236568\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.9971354166666667\tAverage Loss: 0.055039076438614956\n",
            "\tTest: Average Accuracy: 0.7104166666666667\tAverage Loss: 1.0861476141650415\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.997265625\tAverage Loss: 0.05341410472148897\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.0907154407911874\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.99765625\tAverage Loss: 0.05185953562745257\n",
            "\tTest: Average Accuracy: 0.7088541666666667\tAverage Loss: 1.0952156830336155\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.998046875\tAverage Loss: 0.050371805697756414\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.0996490812091557\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.9981770833333333\tAverage Loss: 0.048947552009823495\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.1040165576650318\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.9981770833333333\tAverage Loss: 0.04758358896502165\n",
            "\tTest: Average Accuracy: 0.7114583333333333\tAverage Loss: 1.1083192444671282\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.9983072916666667\tAverage Loss: 0.04627688966331368\n",
            "\tTest: Average Accuracy: 0.7119791666666667\tAverage Loss: 1.1125584836660607\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.9984375\tAverage Loss: 0.04502457298204183\n",
            "\tTest: Average Accuracy: 0.7140625\tAverage Loss: 1.1167358023189176\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.9985677083333333\tAverage Loss: 0.04382389579833756\n",
            "\tTest: Average Accuracy: 0.7119791666666667\tAverage Loss: 1.120852870565209\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.998828125\tAverage Loss: 0.04267224877290121\n",
            "\tTest: Average Accuracy: 0.7125\tAverage Loss: 1.1249114529472284\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.998828125\tAverage Loss: 0.041567153922986835\n",
            "\tTest: Average Accuracy: 0.7114583333333333\tAverage Loss: 1.1289133615071663\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.04050626258501069\n",
            "\tTest: Average Accuracy: 0.7104166666666667\tAverage Loss: 1.1328604159562805\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.0394873529204625\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.1367544130927196\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.9993489583333334\tAverage Loss: 0.03850832659523244\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 1.140597105439435\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.03756720457233398\n",
            "\tTest: Average Accuracy: 0.7104166666666667\tAverage Loss: 1.1443901878498766\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.036662122117190665\n",
            "\tTest: Average Accuracy: 0.7104166666666667\tAverage Loss: 1.148135290332712\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.03579132317530046\n",
            "\tTest: Average Accuracy: 0.7104166666666667\tAverage Loss: 1.1518339752861655\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.034953154293524386\n",
            "\tTest: Average Accuracy: 0.7109375\tAverage Loss: 1.1554877374924528\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.034146058252013715\n",
            "\tTest: Average Accuracy: 0.7109375\tAverage Loss: 1.1590980054751976\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.03336856757118505\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 1.1626661431037488\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.03261929806155365\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 1.1661934506120595\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.0318969425891558\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.1696811644791831\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.03120026522682074\n",
            "\tTest: Average Accuracy: 0.7104166666666667\tAverage Loss: 1.173130455893085\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.03052809594304349\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 1.1765424277896133\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.02987932594129267\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.1799181107238834\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.02925290370522619\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 1.1832584580922734\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.028647831736993368\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.1865643414798224\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.028063163906692914\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.1898365471521994\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.02749800327062991\n",
            "\tTest: Average Accuracy: 0.7104166666666667\tAverage Loss: 1.1930757749121832\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.026951500171777675\n",
            "\tTest: Average Accuracy: 0.7098958333333333\tAverage Loss: 1.1962826406248717\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.02642285041439208\n",
            "\tTest: Average Accuracy: 0.7088541666666667\tAverage Loss: 1.1994576835656667\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.02591129331363608\n",
            "\tTest: Average Accuracy: 0.7088541666666667\tAverage Loss: 1.2026013792306698\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=Tanh(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-5iI6Xg9Pie8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6933156-c27f-4c12-87ad-b5840bf5b031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.12109375\tAverage Loss: 2.6796883197977763\n",
            "\tTest: Average Accuracy: 0.29375\tAverage Loss: 2.1032490836914834\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.32395833333333335\tAverage Loss: 1.950976372868739\n",
            "\tTest: Average Accuracy: 0.39479166666666665\tAverage Loss: 1.7538071740422594\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.4171875\tAverage Loss: 1.641349278371665\n",
            "\tTest: Average Accuracy: 0.43385416666666665\tAverage Loss: 1.5735431162847628\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.47955729166666666\tAverage Loss: 1.437419441808514\n",
            "\tTest: Average Accuracy: 0.48020833333333335\tAverage Loss: 1.429462047961778\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.5313802083333333\tAverage Loss: 1.2872082233530913\n",
            "\tTest: Average Accuracy: 0.525\tAverage Loss: 1.3275577526284137\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.569921875\tAverage Loss: 1.168850987151093\n",
            "\tTest: Average Accuracy: 0.5411458333333333\tAverage Loss: 1.249234338119524\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.6024739583333333\tAverage Loss: 1.0715714665203193\n",
            "\tTest: Average Accuracy: 0.5645833333333333\tAverage Loss: 1.200912597620986\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.6260416666666667\tAverage Loss: 0.995072417267656\n",
            "\tTest: Average Accuracy: 0.5739583333333333\tAverage Loss: 1.1747721836087144\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.64921875\tAverage Loss: 0.9291534126669424\n",
            "\tTest: Average Accuracy: 0.5776041666666667\tAverage Loss: 1.1549539981977224\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.6721354166666667\tAverage Loss: 0.8691989539545854\n",
            "\tTest: Average Accuracy: 0.5880208333333333\tAverage Loss: 1.1412668738235732\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.6934895833333333\tAverage Loss: 0.8175694770418827\n",
            "\tTest: Average Accuracy: 0.6026041666666667\tAverage Loss: 1.122917559004947\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.7131510416666667\tAverage Loss: 0.7676092867452573\n",
            "\tTest: Average Accuracy: 0.609375\tAverage Loss: 1.101009626469828\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.727734375\tAverage Loss: 0.7189036837185117\n",
            "\tTest: Average Accuracy: 0.615625\tAverage Loss: 1.0835229287641868\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.7432291666666667\tAverage Loss: 0.6736907390101835\n",
            "\tTest: Average Accuracy: 0.6244791666666667\tAverage Loss: 1.052238416041934\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.7622395833333333\tAverage Loss: 0.632020614063608\n",
            "\tTest: Average Accuracy: 0.6348958333333333\tAverage Loss: 1.0366770916900134\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.7764322916666667\tAverage Loss: 0.5955496632753318\n",
            "\tTest: Average Accuracy: 0.640625\tAverage Loss: 1.0179608595242657\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.7901041666666667\tAverage Loss: 0.5545652682121743\n",
            "\tTest: Average Accuracy: 0.6494791666666667\tAverage Loss: 1.0032327982396785\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.8075520833333333\tAverage Loss: 0.5152522630578527\n",
            "\tTest: Average Accuracy: 0.6541666666666667\tAverage Loss: 1.0021139783676984\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.8244791666666667\tAverage Loss: 0.4798971858703665\n",
            "\tTest: Average Accuracy: 0.6614583333333334\tAverage Loss: 1.000410633206293\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.8368489583333333\tAverage Loss: 0.45033976851899576\n",
            "\tTest: Average Accuracy: 0.6697916666666667\tAverage Loss: 0.9957071664662727\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.8515625\tAverage Loss: 0.4181417044338688\n",
            "\tTest: Average Accuracy: 0.6791666666666667\tAverage Loss: 0.9937976808394534\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.8649739583333333\tAverage Loss: 0.3918735826314853\n",
            "\tTest: Average Accuracy: 0.6833333333333333\tAverage Loss: 1.0081979726184993\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.8752604166666667\tAverage Loss: 0.3669231109234172\n",
            "\tTest: Average Accuracy: 0.6921875\tAverage Loss: 0.9952623524002393\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.8872395833333333\tAverage Loss: 0.3429543938307479\n",
            "\tTest: Average Accuracy: 0.69375\tAverage Loss: 0.9978934222437543\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.8954427083333333\tAverage Loss: 0.32195986831489176\n",
            "\tTest: Average Accuracy: 0.6963541666666667\tAverage Loss: 0.9923573455757851\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.9033854166666667\tAverage Loss: 0.3018232814771204\n",
            "\tTest: Average Accuracy: 0.6958333333333333\tAverage Loss: 1.0032559620166943\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.9135416666666667\tAverage Loss: 0.2818929242891743\n",
            "\tTest: Average Accuracy: 0.6994791666666667\tAverage Loss: 1.0005118032803224\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.921484375\tAverage Loss: 0.2645315932088481\n",
            "\tTest: Average Accuracy: 0.6984375\tAverage Loss: 1.020979321691742\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.9240885416666667\tAverage Loss: 0.25179484477147496\n",
            "\tTest: Average Accuracy: 0.7\tAverage Loss: 1.0290181779313736\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.9325520833333333\tAverage Loss: 0.23621096397888738\n",
            "\tTest: Average Accuracy: 0.7010416666666667\tAverage Loss: 1.029738939215126\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.93828125\tAverage Loss: 0.21997296166048588\n",
            "\tTest: Average Accuracy: 0.7119791666666667\tAverage Loss: 1.0388339167266343\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.9459635416666666\tAverage Loss: 0.2023086852316829\n",
            "\tTest: Average Accuracy: 0.7020833333333333\tAverage Loss: 1.0603555399274947\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.9485677083333334\tAverage Loss: 0.19504736158033154\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 1.0611626088512398\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.9529947916666667\tAverage Loss: 0.18328385383471577\n",
            "\tTest: Average Accuracy: 0.7052083333333333\tAverage Loss: 1.0825605357798314\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.9342447916666666\tAverage Loss: 0.23795398639660978\n",
            "\tTest: Average Accuracy: 0.70625\tAverage Loss: 1.1288299329699383\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.9533854166666667\tAverage Loss: 0.18212567227363477\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.0983579413089735\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.9541666666666667\tAverage Loss: 0.17899455693184926\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.0882966449951823\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.9529947916666667\tAverage Loss: 0.17566379493922277\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.0897789850159834\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.9703125\tAverage Loss: 0.1379975426083776\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.1090644339101023\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.9740885416666667\tAverage Loss: 0.1263586317174344\n",
            "\tTest: Average Accuracy: 0.7145833333333333\tAverage Loss: 1.111924177002637\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.9787760416666667\tAverage Loss: 0.11617685054493841\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.1184835149808556\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.9817708333333334\tAverage Loss: 0.1087565617370356\n",
            "\tTest: Average Accuracy: 0.715625\tAverage Loss: 1.1327383641561768\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.9841145833333333\tAverage Loss: 0.10276179409102267\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 1.1475701927419486\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.986328125\tAverage Loss: 0.09706855562011688\n",
            "\tTest: Average Accuracy: 0.7192708333333333\tAverage Loss: 1.1568245212805173\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.9876302083333334\tAverage Loss: 0.09168139922840947\n",
            "\tTest: Average Accuracy: 0.7229166666666667\tAverage Loss: 1.165006469213177\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.9884114583333333\tAverage Loss: 0.08714539734851888\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 1.1768721403501237\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.9899739583333333\tAverage Loss: 0.08297290984958468\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 1.1865115749520092\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.9903645833333333\tAverage Loss: 0.07881927219353795\n",
            "\tTest: Average Accuracy: 0.7229166666666667\tAverage Loss: 1.2029733412963863\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.99140625\tAverage Loss: 0.07557725950580553\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 1.2162357698330306\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.9921875\tAverage Loss: 0.07197954782018014\n",
            "\tTest: Average Accuracy: 0.7229166666666667\tAverage Loss: 1.217662210872276\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.9927083333333333\tAverage Loss: 0.06882785485780278\n",
            "\tTest: Average Accuracy: 0.7223958333333333\tAverage Loss: 1.2235346679255592\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.993359375\tAverage Loss: 0.06586692220353307\n",
            "\tTest: Average Accuracy: 0.7223958333333333\tAverage Loss: 1.2303182958423478\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.9942708333333333\tAverage Loss: 0.06316208066160554\n",
            "\tTest: Average Accuracy: 0.7234375\tAverage Loss: 1.241425717686638\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.9950520833333333\tAverage Loss: 0.060485813364224095\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 1.2523374696141516\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.9951822916666667\tAverage Loss: 0.058114945383087785\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.256092449357122\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.9958333333333333\tAverage Loss: 0.05583618197386566\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.2584070461990653\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.9963541666666667\tAverage Loss: 0.05346013477338583\n",
            "\tTest: Average Accuracy: 0.7276041666666667\tAverage Loss: 1.2735646736643038\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.9966145833333333\tAverage Loss: 0.05140309474278384\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 1.275648926037714\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.9967447916666666\tAverage Loss: 0.04953407576210744\n",
            "\tTest: Average Accuracy: 0.725\tAverage Loss: 1.284889350965432\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.997265625\tAverage Loss: 0.04747530277127148\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.286113486036394\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.9973958333333334\tAverage Loss: 0.04586078872731738\n",
            "\tTest: Average Accuracy: 0.7223958333333333\tAverage Loss: 1.297039996010457\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.9973958333333334\tAverage Loss: 0.044129371877549096\n",
            "\tTest: Average Accuracy: 0.7239583333333334\tAverage Loss: 1.3002182561121216\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.99765625\tAverage Loss: 0.04247696681772672\n",
            "\tTest: Average Accuracy: 0.7255208333333333\tAverage Loss: 1.3057000652082562\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.9979166666666667\tAverage Loss: 0.04100053086744479\n",
            "\tTest: Average Accuracy: 0.7270833333333333\tAverage Loss: 1.314597257768978\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.9979166666666667\tAverage Loss: 0.0397223361587371\n",
            "\tTest: Average Accuracy: 0.7270833333333333\tAverage Loss: 1.3208152860719289\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.998046875\tAverage Loss: 0.0381812040142852\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.3274122119249037\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.9981770833333333\tAverage Loss: 0.03704381157534467\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.335656450490429\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.9984375\tAverage Loss: 0.03576893177641791\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.3396119707896514\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.9985677083333333\tAverage Loss: 0.03464735924768402\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.3450664344114829\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.9986979166666666\tAverage Loss: 0.03350617792254054\n",
            "\tTest: Average Accuracy: 0.7270833333333333\tAverage Loss: 1.3518196543116754\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.9986979166666666\tAverage Loss: 0.032484007511257566\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.3592637654667632\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.998828125\tAverage Loss: 0.03155442854949273\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.3644281571497496\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.030578349649998022\n",
            "\tTest: Average Accuracy: 0.7270833333333333\tAverage Loss: 1.370076054681897\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.9990885416666667\tAverage Loss: 0.029582977116657954\n",
            "\tTest: Average Accuracy: 0.7276041666666667\tAverage Loss: 1.3756827265868543\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.99921875\tAverage Loss: 0.02868900516027403\n",
            "\tTest: Average Accuracy: 0.7296875\tAverage Loss: 1.3815950308205436\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.99921875\tAverage Loss: 0.02791420749172714\n",
            "\tTest: Average Accuracy: 0.7286458333333333\tAverage Loss: 1.3881021259519548\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.99921875\tAverage Loss: 0.02715489651020801\n",
            "\tTest: Average Accuracy: 0.7286458333333333\tAverage Loss: 1.393790083132236\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.026319921307593433\n",
            "\tTest: Average Accuracy: 0.7296875\tAverage Loss: 1.3982107664002144\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.02561863992411498\n",
            "\tTest: Average Accuracy: 0.7291666666666666\tAverage Loss: 1.4051575652510777\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.024899808338360717\n",
            "\tTest: Average Accuracy: 0.7296875\tAverage Loss: 1.409934521049751\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.02423889145567774\n",
            "\tTest: Average Accuracy: 0.7286458333333333\tAverage Loss: 1.4142502847808016\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.023512108750564555\n",
            "\tTest: Average Accuracy: 0.7286458333333333\tAverage Loss: 1.4202438471174241\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.022944310804922527\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4257161314154294\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.022331081799860916\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.430663096663923\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.021758084013363883\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4359046109972284\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.02121082419106451\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.439863803206903\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.02063280880096213\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.445772923390737\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.020150984126671743\n",
            "\tTest: Average Accuracy: 0.7270833333333333\tAverage Loss: 1.4512484706639057\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.0196595839242204\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4554323709099024\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.01919103604653846\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.459186011054027\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.018762355620437175\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4643617178248092\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.018285421352516953\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.4691555189568997\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.01785144959758419\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4738842307082274\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.017456570094157842\n",
            "\tTest: Average Accuracy: 0.7276041666666667\tAverage Loss: 1.478192551501578\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.017080396870173518\n",
            "\tTest: Average Accuracy: 0.7260416666666667\tAverage Loss: 1.4824946221796236\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.0166876111339911\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.4865236002493971\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.01629261106175965\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.491143934552441\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.015951180664020077\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.4955691844874173\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.015608928436448346\n",
            "\tTest: Average Accuracy: 0.7234375\tAverage Loss: 1.4989129053671273\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.015284485638641982\n",
            "\tTest: Average Accuracy: 0.7234375\tAverage Loss: 1.503671589916407\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=32)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=32)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can say that Relu and Leaky Relu did better on our model,than Sigmoid and Tanh."
      ],
      "metadata": {
        "id": "QuvNUkya_Ozz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7erKwubF4Yr"
      },
      "source": [
        "Sigmoid and Tanh:\n",
        "\n",
        "There is a problem which is called vanishing gradient problem.This is usually happens when using Sigmoid or Tangent Hyperbolic function.The activation function squishes a large input space into a small input space between 0 and 1. Therefore, a large change in the input of the sigmoid or tangent hyperbolic  function will cause a small change in the output. Hence, the derivative becomes small.That's why sigmoid doesn't do well on this model.\n",
        "The problem becomes more significant when we use larger number of layers.\n",
        "\n",
        "\n",
        "LeakyRelu and Relu:\n",
        "\n",
        "Also there is another problem which is called dying Relu Problem.A dying ReLU always outputs the same value, i.e., 0, on any input value.In this state, it is difficult to recover because the gradient of 0 is 0. This becomes a problem when most of the input ranges are negative, or the derivative of the ReLU function is 0.The gradient fails to flow during backpropagation because the outputs are 0, and hence the weights are not updated.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXc55JedRhTu"
      },
      "source": [
        "##Batch Size:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "IijTbPLaMgMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314ea679-1634-4274-e7e6-5df5c089e78d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.07864583333333333\tAverage Loss: 2.6140366803238217\n",
            "\tTest: Average Accuracy: 0.315625\tAverage Loss: 2.0662642157489484\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.24322916666666666\tAverage Loss: 1.9347452706349808\n",
            "\tTest: Average Accuracy: 0.384375\tAverage Loss: 1.7233630022886919\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.34765625\tAverage Loss: 1.6384973210275213\n",
            "\tTest: Average Accuracy: 0.43385416666666665\tAverage Loss: 1.5505354637682527\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.42135416666666664\tAverage Loss: 1.4438856519320216\n",
            "\tTest: Average Accuracy: 0.47708333333333336\tAverage Loss: 1.4180181564908703\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.48190104166666664\tAverage Loss: 1.300764167238826\n",
            "\tTest: Average Accuracy: 0.5072916666666667\tAverage Loss: 1.3187336360894975\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.5236979166666667\tAverage Loss: 1.1886398533455063\n",
            "\tTest: Average Accuracy: 0.5458333333333333\tAverage Loss: 1.2515693310183\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.5610677083333333\tAverage Loss: 1.0958507462377263\n",
            "\tTest: Average Accuracy: 0.5578125\tAverage Loss: 1.2051258998191443\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.5981770833333333\tAverage Loss: 1.0142771709087786\n",
            "\tTest: Average Accuracy: 0.5651041666666666\tAverage Loss: 1.1767384129426788\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.6295572916666666\tAverage Loss: 0.9406476072687956\n",
            "\tTest: Average Accuracy: 0.5833333333333334\tAverage Loss: 1.1513402033732618\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.6578125\tAverage Loss: 0.8752132378601905\n",
            "\tTest: Average Accuracy: 0.5859375\tAverage Loss: 1.1317729025040397\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.6872395833333333\tAverage Loss: 0.8163154625220933\n",
            "\tTest: Average Accuracy: 0.603125\tAverage Loss: 1.111128388409257\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.712890625\tAverage Loss: 0.7645905277576444\n",
            "\tTest: Average Accuracy: 0.6140625\tAverage Loss: 1.1081024436233649\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.7322916666666667\tAverage Loss: 0.7169272940230613\n",
            "\tTest: Average Accuracy: 0.6223958333333334\tAverage Loss: 1.086455136484054\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.7515625\tAverage Loss: 0.673715251926032\n",
            "\tTest: Average Accuracy: 0.6333333333333333\tAverage Loss: 1.0860819494972715\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.7686197916666667\tAverage Loss: 0.6331314602661499\n",
            "\tTest: Average Accuracy: 0.640625\tAverage Loss: 1.083001598270342\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.7830729166666667\tAverage Loss: 0.5954855538695909\n",
            "\tTest: Average Accuracy: 0.6432291666666666\tAverage Loss: 1.0837072649253312\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.79921875\tAverage Loss: 0.5582000617732475\n",
            "\tTest: Average Accuracy: 0.6473958333333333\tAverage Loss: 1.089019798408374\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.81171875\tAverage Loss: 0.5235613561299481\n",
            "\tTest: Average Accuracy: 0.6515625\tAverage Loss: 1.0877372095919753\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.828125\tAverage Loss: 0.4910846876784357\n",
            "\tTest: Average Accuracy: 0.6588541666666666\tAverage Loss: 1.0868727372922744\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.8404947916666666\tAverage Loss: 0.46099166248822976\n",
            "\tTest: Average Accuracy: 0.6588541666666666\tAverage Loss: 1.097958563687116\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.8540364583333333\tAverage Loss: 0.4319322463351593\n",
            "\tTest: Average Accuracy: 0.6640625\tAverage Loss: 1.0981145281269444\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.8654947916666667\tAverage Loss: 0.40390366122790117\n",
            "\tTest: Average Accuracy: 0.66875\tAverage Loss: 1.1051305509076466\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.8766927083333333\tAverage Loss: 0.3775904942490855\n",
            "\tTest: Average Accuracy: 0.6677083333333333\tAverage Loss: 1.1035081387088597\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.8877604166666667\tAverage Loss: 0.3525561631600585\n",
            "\tTest: Average Accuracy: 0.6765625\tAverage Loss: 1.1044670626686066\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.8977864583333334\tAverage Loss: 0.32972286365611575\n",
            "\tTest: Average Accuracy: 0.6734375\tAverage Loss: 1.1314951499503179\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.9041666666666667\tAverage Loss: 0.3077718066686239\n",
            "\tTest: Average Accuracy: 0.6739583333333333\tAverage Loss: 1.1358633336998105\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.9141927083333333\tAverage Loss: 0.28648608852794444\n",
            "\tTest: Average Accuracy: 0.6734375\tAverage Loss: 1.139574457842795\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.923046875\tAverage Loss: 0.26722457482451056\n",
            "\tTest: Average Accuracy: 0.6713541666666667\tAverage Loss: 1.1528854167616196\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.93046875\tAverage Loss: 0.24844184350736817\n",
            "\tTest: Average Accuracy: 0.6723958333333333\tAverage Loss: 1.1503341735894996\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.937109375\tAverage Loss: 0.23228967955565244\n",
            "\tTest: Average Accuracy: 0.6744791666666666\tAverage Loss: 1.1672436056454585\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.9421875\tAverage Loss: 0.21766575316014614\n",
            "\tTest: Average Accuracy: 0.6859375\tAverage Loss: 1.1465660779063573\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.9485677083333334\tAverage Loss: 0.20379715028965736\n",
            "\tTest: Average Accuracy: 0.6895833333333333\tAverage Loss: 1.1466207231817103\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.9540364583333333\tAverage Loss: 0.1898462067954689\n",
            "\tTest: Average Accuracy: 0.6921875\tAverage Loss: 1.152995460809515\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.9576822916666666\tAverage Loss: 0.17799077925542223\n",
            "\tTest: Average Accuracy: 0.6984375\tAverage Loss: 1.141390207295653\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.962890625\tAverage Loss: 0.16655400559559375\n",
            "\tTest: Average Accuracy: 0.6979166666666666\tAverage Loss: 1.1482497433496475\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.9647135416666667\tAverage Loss: 0.15579627211483327\n",
            "\tTest: Average Accuracy: 0.7020833333333333\tAverage Loss: 1.151447983437108\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.96796875\tAverage Loss: 0.14623671127316146\n",
            "\tTest: Average Accuracy: 0.7088541666666667\tAverage Loss: 1.1435825332510765\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.9721354166666667\tAverage Loss: 0.13649695677390447\n",
            "\tTest: Average Accuracy: 0.7072916666666667\tAverage Loss: 1.1532355974154929\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.976171875\tAverage Loss: 0.12806007055105423\n",
            "\tTest: Average Accuracy: 0.7067708333333333\tAverage Loss: 1.1580563250230722\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.9790364583333333\tAverage Loss: 0.12018770795044786\n",
            "\tTest: Average Accuracy: 0.7083333333333334\tAverage Loss: 1.1663453264166952\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.9821614583333333\tAverage Loss: 0.11280044005077948\n",
            "\tTest: Average Accuracy: 0.7083333333333334\tAverage Loss: 1.1741747805864624\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.9842447916666667\tAverage Loss: 0.10635091730142135\n",
            "\tTest: Average Accuracy: 0.7135416666666666\tAverage Loss: 1.1803667277532213\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.9859375\tAverage Loss: 0.10043400020697507\n",
            "\tTest: Average Accuracy: 0.709375\tAverage Loss: 1.191372286135453\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.9877604166666667\tAverage Loss: 0.09487961496258063\n",
            "\tTest: Average Accuracy: 0.7119791666666667\tAverage Loss: 1.1989403033461847\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.9888020833333333\tAverage Loss: 0.08935058598181615\n",
            "\tTest: Average Accuracy: 0.7135416666666666\tAverage Loss: 1.2093338464799246\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.9908854166666666\tAverage Loss: 0.08461816332977533\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.2175769597278001\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.9912760416666667\tAverage Loss: 0.08036709802759755\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 1.2280397691345892\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.992578125\tAverage Loss: 0.07638772895715272\n",
            "\tTest: Average Accuracy: 0.7192708333333333\tAverage Loss: 1.2355806619041245\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.99375\tAverage Loss: 0.07201346217307504\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.2459168906275484\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.994140625\tAverage Loss: 0.06894482678438925\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 1.2531179754294923\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.9947916666666666\tAverage Loss: 0.06545940096906433\n",
            "\tTest: Average Accuracy: 0.71875\tAverage Loss: 1.2632310344125266\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.9953125\tAverage Loss: 0.06236489009027354\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.2704922777893386\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.9955729166666667\tAverage Loss: 0.059617200855025754\n",
            "\tTest: Average Accuracy: 0.7192708333333333\tAverage Loss: 1.2819649007143992\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.9958333333333333\tAverage Loss: 0.05681534582411218\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.2886786740990046\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.99609375\tAverage Loss: 0.05436795836483126\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.2974187446637506\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.9966145833333333\tAverage Loss: 0.051890132472613\n",
            "\tTest: Average Accuracy: 0.7192708333333333\tAverage Loss: 1.3054343938878863\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.996875\tAverage Loss: 0.04970182271014476\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.3150834854880114\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.9973958333333334\tAverage Loss: 0.04753069745493294\n",
            "\tTest: Average Accuracy: 0.7213541666666666\tAverage Loss: 1.3221169200181164\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.9977864583333333\tAverage Loss: 0.04572728064132446\n",
            "\tTest: Average Accuracy: 0.7208333333333333\tAverage Loss: 1.3306791032392378\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.9983072916666667\tAverage Loss: 0.043640117300776056\n",
            "\tTest: Average Accuracy: 0.721875\tAverage Loss: 1.3382100208881742\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.9985677083333333\tAverage Loss: 0.042098746263900345\n",
            "\tTest: Average Accuracy: 0.721875\tAverage Loss: 1.3457400199532699\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.9989583333333333\tAverage Loss: 0.040418237456958286\n",
            "\tTest: Average Accuracy: 0.7234375\tAverage Loss: 1.3533283780186414\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.9990885416666667\tAverage Loss: 0.038936184912056644\n",
            "\tTest: Average Accuracy: 0.7244791666666667\tAverage Loss: 1.3592796872916362\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.9990885416666667\tAverage Loss: 0.037557123180240605\n",
            "\tTest: Average Accuracy: 0.721875\tAverage Loss: 1.3672393287600506\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.9994791666666667\tAverage Loss: 0.03618326265128224\n",
            "\tTest: Average Accuracy: 0.721875\tAverage Loss: 1.3750028329264243\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.03479623475109963\n",
            "\tTest: Average Accuracy: 0.7223958333333333\tAverage Loss: 1.3810947379472218\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.03370134095295791\n",
            "\tTest: Average Accuracy: 0.7192708333333333\tAverage Loss: 1.3873486604199348\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.03245464333558518\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 1.3951245019022267\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.03150474079378412\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 1.401899889791413\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.03033757310660172\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 1.407064642895069\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.999609375\tAverage Loss: 0.029409067028057945\n",
            "\tTest: Average Accuracy: 0.721875\tAverage Loss: 1.4155959781896787\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.028443187353746655\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 1.4210157639785999\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.9997395833333333\tAverage Loss: 0.027565494684889356\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 1.4281132786270538\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.026685707596561605\n",
            "\tTest: Average Accuracy: 0.7192708333333333\tAverage Loss: 1.4335186153006174\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02598145709548462\n",
            "\tTest: Average Accuracy: 0.7203125\tAverage Loss: 1.4402661266488355\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.025163053825640252\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.4468465389767953\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.024467899307757744\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 1.4520312826956787\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.023749319326459836\n",
            "\tTest: Average Accuracy: 0.71875\tAverage Loss: 1.4584564811831207\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02312649500447892\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.464945324519012\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02244338885674715\n",
            "\tTest: Average Accuracy: 0.7197916666666667\tAverage Loss: 1.470848501019296\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02185516995901275\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.4771361768429103\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02128814258662557\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.4824612849895449\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.020714170023958943\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.4878177019561236\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.02018400641121284\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.4935188449966934\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.019674671428983694\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.4986279391106916\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.019174779142404317\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.5039645071479026\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.01870647931491606\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.5099451758248412\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.018232104002700766\n",
            "\tTest: Average Accuracy: 0.7166666666666667\tAverage Loss: 1.515326623438159\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.017794280352585293\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.5202517267410802\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.017396441748854737\n",
            "\tTest: Average Accuracy: 0.7161458333333334\tAverage Loss: 1.5259172828750958\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.016960173448571356\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.5299094374599027\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.016594519098941263\n",
            "\tTest: Average Accuracy: 0.7171875\tAverage Loss: 1.5347192568105095\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.016205757797350846\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.5400558710819103\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.01586688052194395\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.5448513986746106\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.015485166092006501\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.5489265533779861\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.015168485418793055\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.553674649003164\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.014842167690548117\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.5580989252735984\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.014515157918384718\n",
            "\tTest: Average Accuracy: 0.7182291666666667\tAverage Loss: 1.5626330441309606\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.014229734769303108\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.5671304619900623\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.013918162073624726\n",
            "\tTest: Average Accuracy: 0.7177083333333333\tAverage Loss: 1.5714605116969937\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=16)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=16)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0oJBUdXyYtFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365f3b6b-27e0-495a-9c5f-f2ba25109372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.0734375\tAverage Loss: 3.027482277951574\n",
            "\tTest: Average Accuracy: 0.07958984375\tAverage Loss: 2.76727575608379\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.069140625\tAverage Loss: 2.7696040575575096\n",
            "\tTest: Average Accuracy: 0.0712890625\tAverage Loss: 2.7657564477929357\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.07083333333333333\tAverage Loss: 2.7669350804590374\n",
            "\tTest: Average Accuracy: 0.07177734375\tAverage Loss: 2.764520065798583\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.07369791666666667\tAverage Loss: 2.765340489148531\n",
            "\tTest: Average Accuracy: 0.0732421875\tAverage Loss: 2.763101009287358\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.0765625\tAverage Loss: 2.7636431206314396\n",
            "\tTest: Average Accuracy: 0.076171875\tAverage Loss: 2.7607696686783356\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.11588541666666667\tAverage Loss: 2.648190302700521\n",
            "\tTest: Average Accuracy: 0.14501953125\tAverage Loss: 2.5067238682904813\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.15690104166666666\tAverage Loss: 2.4750713882038156\n",
            "\tTest: Average Accuracy: 0.17041015625\tAverage Loss: 2.4191746434218384\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.17708333333333334\tAverage Loss: 2.4321755695952345\n",
            "\tTest: Average Accuracy: 0.17626953125\tAverage Loss: 2.3763946672238196\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.18463541666666666\tAverage Loss: 2.4047687712445955\n",
            "\tTest: Average Accuracy: 0.18896484375\tAverage Loss: 2.3573687549043107\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.18580729166666668\tAverage Loss: 2.3857115375246156\n",
            "\tTest: Average Accuracy: 0.21240234375\tAverage Loss: 2.3470597098439967\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.18463541666666666\tAverage Loss: 2.382459855187884\n",
            "\tTest: Average Accuracy: 0.21044921875\tAverage Loss: 2.3181469128544063\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.18268229166666666\tAverage Loss: 2.3657176713916894\n",
            "\tTest: Average Accuracy: 0.21875\tAverage Loss: 2.306122686856739\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.17591145833333333\tAverage Loss: 2.3549616442292813\n",
            "\tTest: Average Accuracy: 0.2001953125\tAverage Loss: 2.283029015299986\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.16953125\tAverage Loss: 2.3606899619745074\n",
            "\tTest: Average Accuracy: 0.1943359375\tAverage Loss: 2.266450724584013\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.166015625\tAverage Loss: 2.3683494285697346\n",
            "\tTest: Average Accuracy: 0.1982421875\tAverage Loss: 2.266613498895941\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.16341145833333334\tAverage Loss: 2.37190680445039\n",
            "\tTest: Average Accuracy: 0.21923828125\tAverage Loss: 2.2542438918747005\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.17330729166666667\tAverage Loss: 2.353836857744921\n",
            "\tTest: Average Accuracy: 0.19873046875\tAverage Loss: 2.2454802748704257\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.1734375\tAverage Loss: 2.354798037381147\n",
            "\tTest: Average Accuracy: 0.19775390625\tAverage Loss: 2.2392603062619436\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.17486979166666666\tAverage Loss: 2.3544620311292643\n",
            "\tTest: Average Accuracy: 0.20458984375\tAverage Loss: 2.243030611533133\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.18776041666666668\tAverage Loss: 2.3427497495217313\n",
            "\tTest: Average Accuracy: 0.19970703125\tAverage Loss: 2.2352805031575067\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.178515625\tAverage Loss: 2.3590453221053753\n",
            "\tTest: Average Accuracy: 0.2119140625\tAverage Loss: 2.248648414988044\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.18802083333333333\tAverage Loss: 2.3501070654076766\n",
            "\tTest: Average Accuracy: 0.220703125\tAverage Loss: 2.2313067447117763\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.19153645833333333\tAverage Loss: 2.340463120224911\n",
            "\tTest: Average Accuracy: 0.22119140625\tAverage Loss: 2.2296720592479655\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.19348958333333333\tAverage Loss: 2.343899001332901\n",
            "\tTest: Average Accuracy: 0.22900390625\tAverage Loss: 2.224185592351241\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.19583333333333333\tAverage Loss: 2.3326676893018496\n",
            "\tTest: Average Accuracy: 0.2294921875\tAverage Loss: 2.2201237326732377\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.19986979166666666\tAverage Loss: 2.312538613419424\n",
            "\tTest: Average Accuracy: 0.23193359375\tAverage Loss: 2.2104909910936206\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.19895833333333332\tAverage Loss: 2.3033468629171967\n",
            "\tTest: Average Accuracy: 0.2265625\tAverage Loss: 2.2067680706614796\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.200390625\tAverage Loss: 2.3075712840795117\n",
            "\tTest: Average Accuracy: 0.2236328125\tAverage Loss: 2.2112591941301125\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.202734375\tAverage Loss: 2.29879055212492\n",
            "\tTest: Average Accuracy: 0.23046875\tAverage Loss: 2.2179494893866627\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.20611979166666666\tAverage Loss: 2.2911394324329755\n",
            "\tTest: Average Accuracy: 0.24072265625\tAverage Loss: 2.1751053725561564\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.23372395833333334\tAverage Loss: 2.193514327896693\n",
            "\tTest: Average Accuracy: 0.2646484375\tAverage Loss: 2.0807161038132906\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.26341145833333335\tAverage Loss: 2.074480156971126\n",
            "\tTest: Average Accuracy: 0.2587890625\tAverage Loss: 2.067604279707781\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.26705729166666664\tAverage Loss: 2.078515359434296\n",
            "\tTest: Average Accuracy: 0.2578125\tAverage Loss: 2.041230666697837\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.27174479166666665\tAverage Loss: 2.0612579542456695\n",
            "\tTest: Average Accuracy: 0.255859375\tAverage Loss: 2.0597630512343024\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.27252604166666666\tAverage Loss: 2.03936207762509\n",
            "\tTest: Average Accuracy: 0.2626953125\tAverage Loss: 2.0382894631390327\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.27122395833333335\tAverage Loss: 2.002581149977381\n",
            "\tTest: Average Accuracy: 0.25048828125\tAverage Loss: 2.064942715460376\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.2713541666666667\tAverage Loss: 1.9700946566711175\n",
            "\tTest: Average Accuracy: 0.2548828125\tAverage Loss: 2.040243608844892\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.27434895833333334\tAverage Loss: 1.9539610638272873\n",
            "\tTest: Average Accuracy: 0.26708984375\tAverage Loss: 2.0165243041853373\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.276953125\tAverage Loss: 1.9422910734556216\n",
            "\tTest: Average Accuracy: 0.271484375\tAverage Loss: 2.0213844006287607\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.2727864583333333\tAverage Loss: 1.9387538975786904\n",
            "\tTest: Average Accuracy: 0.2666015625\tAverage Loss: 2.0320794844532273\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.2765625\tAverage Loss: 1.9211074044811995\n",
            "\tTest: Average Accuracy: 0.26611328125\tAverage Loss: 2.026848342058761\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.27890625\tAverage Loss: 1.9052243675766847\n",
            "\tTest: Average Accuracy: 0.26611328125\tAverage Loss: 2.017291415862483\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.2794270833333333\tAverage Loss: 1.906759943690068\n",
            "\tTest: Average Accuracy: 0.265625\tAverage Loss: 2.028822391045388\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.2825520833333333\tAverage Loss: 1.8936195417257633\n",
            "\tTest: Average Accuracy: 0.2666015625\tAverage Loss: 2.0321966207357365\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.291015625\tAverage Loss: 1.8658681368217052\n",
            "\tTest: Average Accuracy: 0.2724609375\tAverage Loss: 2.0171612207727696\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.2950520833333333\tAverage Loss: 1.8557462056762088\n",
            "\tTest: Average Accuracy: 0.2802734375\tAverage Loss: 2.014619222274168\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.29765625\tAverage Loss: 1.8500214292983392\n",
            "\tTest: Average Accuracy: 0.27880859375\tAverage Loss: 2.013375197643837\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.295703125\tAverage Loss: 1.8447632846026611\n",
            "\tTest: Average Accuracy: 0.28076171875\tAverage Loss: 2.008948337122635\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.29765625\tAverage Loss: 1.8370130968632066\n",
            "\tTest: Average Accuracy: 0.2861328125\tAverage Loss: 2.0016534895717895\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.2986979166666667\tAverage Loss: 1.8286153253218103\n",
            "\tTest: Average Accuracy: 0.28515625\tAverage Loss: 1.9927078098774604\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.29791666666666666\tAverage Loss: 1.8236465395966854\n",
            "\tTest: Average Accuracy: 0.287109375\tAverage Loss: 1.9993976610319777\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.30078125\tAverage Loss: 1.8172212771601304\n",
            "\tTest: Average Accuracy: 0.2861328125\tAverage Loss: 1.9836718253401284\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.30026041666666664\tAverage Loss: 1.8131173798842135\n",
            "\tTest: Average Accuracy: 0.2841796875\tAverage Loss: 1.9837185022924702\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.303125\tAverage Loss: 1.8071286750305697\n",
            "\tTest: Average Accuracy: 0.2880859375\tAverage Loss: 1.9846733922050808\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.304296875\tAverage Loss: 1.803356316956793\n",
            "\tTest: Average Accuracy: 0.28662109375\tAverage Loss: 1.975416187036203\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.305078125\tAverage Loss: 1.7986785994503147\n",
            "\tTest: Average Accuracy: 0.28857421875\tAverage Loss: 1.978219766650811\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.3059895833333333\tAverage Loss: 1.79435299391251\n",
            "\tTest: Average Accuracy: 0.28857421875\tAverage Loss: 1.9852759864007876\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.3072916666666667\tAverage Loss: 1.7892356698938596\n",
            "\tTest: Average Accuracy: 0.28662109375\tAverage Loss: 1.9833947240109127\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.3079427083333333\tAverage Loss: 1.7874329350346803\n",
            "\tTest: Average Accuracy: 0.2880859375\tAverage Loss: 1.9727220038225781\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.3111979166666667\tAverage Loss: 1.7841935724776106\n",
            "\tTest: Average Accuracy: 0.29150390625\tAverage Loss: 1.9793910938450046\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.30911458333333336\tAverage Loss: 1.7827921104224598\n",
            "\tTest: Average Accuracy: 0.29248046875\tAverage Loss: 1.972920535703675\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.312109375\tAverage Loss: 1.778077771978449\n",
            "\tTest: Average Accuracy: 0.2919921875\tAverage Loss: 1.9780958862045184\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.3111979166666667\tAverage Loss: 1.776054010452416\n",
            "\tTest: Average Accuracy: 0.29443359375\tAverage Loss: 1.978266130581996\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.3131510416666667\tAverage Loss: 1.7748313503623696\n",
            "\tTest: Average Accuracy: 0.29248046875\tAverage Loss: 1.966630866497072\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.3138020833333333\tAverage Loss: 1.770120169551532\n",
            "\tTest: Average Accuracy: 0.2958984375\tAverage Loss: 1.9729638278487625\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.31549479166666666\tAverage Loss: 1.7688227562842387\n",
            "\tTest: Average Accuracy: 0.2978515625\tAverage Loss: 1.9710693869070752\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.31588541666666664\tAverage Loss: 1.7679871076432987\n",
            "\tTest: Average Accuracy: 0.296875\tAverage Loss: 1.9717980522551293\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.31536458333333334\tAverage Loss: 1.7621649043312824\n",
            "\tTest: Average Accuracy: 0.29443359375\tAverage Loss: 1.9657425535959163\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.31731770833333334\tAverage Loss: 1.7628209080000503\n",
            "\tTest: Average Accuracy: 0.29736328125\tAverage Loss: 1.9547613896314493\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.31536458333333334\tAverage Loss: 1.7578413968153606\n",
            "\tTest: Average Accuracy: 0.298828125\tAverage Loss: 1.9663812633036482\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.3170572916666667\tAverage Loss: 1.7580379170688423\n",
            "\tTest: Average Accuracy: 0.29833984375\tAverage Loss: 1.963884716531296\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.3171875\tAverage Loss: 1.7587678913707507\n",
            "\tTest: Average Accuracy: 0.30029296875\tAverage Loss: 1.9499524984362608\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.31861979166666665\tAverage Loss: 1.7537088938488152\n",
            "\tTest: Average Accuracy: 0.29833984375\tAverage Loss: 1.9486608747018457\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.3151041666666667\tAverage Loss: 1.752255271636942\n",
            "\tTest: Average Accuracy: 0.302734375\tAverage Loss: 1.9434857547953341\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.316015625\tAverage Loss: 1.7532106387711819\n",
            "\tTest: Average Accuracy: 0.302734375\tAverage Loss: 1.946059818244413\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.31796875\tAverage Loss: 1.7506667412435142\n",
            "\tTest: Average Accuracy: 0.30322265625\tAverage Loss: 1.944451788561433\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.3182291666666667\tAverage Loss: 1.7486713008602546\n",
            "\tTest: Average Accuracy: 0.3037109375\tAverage Loss: 1.9474932944267307\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.32083333333333336\tAverage Loss: 1.7460453950356722\n",
            "\tTest: Average Accuracy: 0.2998046875\tAverage Loss: 1.9592638470180384\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.3165364583333333\tAverage Loss: 1.7494964172603396\n",
            "\tTest: Average Accuracy: 0.29736328125\tAverage Loss: 1.96561752218939\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.31692708333333336\tAverage Loss: 1.7502988137505011\n",
            "\tTest: Average Accuracy: 0.30126953125\tAverage Loss: 1.9530647632212896\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.3182291666666667\tAverage Loss: 1.7464794124591234\n",
            "\tTest: Average Accuracy: 0.30224609375\tAverage Loss: 1.9510712642979327\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.32057291666666665\tAverage Loss: 1.7431237862892348\n",
            "\tTest: Average Accuracy: 0.302734375\tAverage Loss: 1.9503840103750794\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.3221354166666667\tAverage Loss: 1.740779095545642\n",
            "\tTest: Average Accuracy: 0.30322265625\tAverage Loss: 1.9458653561338157\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.32252604166666665\tAverage Loss: 1.7395591073300656\n",
            "\tTest: Average Accuracy: 0.302734375\tAverage Loss: 1.9463587462130296\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.32317708333333334\tAverage Loss: 1.738062616416901\n",
            "\tTest: Average Accuracy: 0.3037109375\tAverage Loss: 1.9444467482661751\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.32526041666666666\tAverage Loss: 1.7354828857279534\n",
            "\tTest: Average Accuracy: 0.3037109375\tAverage Loss: 1.9434435977784\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 0.325\tAverage Loss: 1.7322629787758705\n",
            "\tTest: Average Accuracy: 0.3046875\tAverage Loss: 1.9492047831692725\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 0.32838541666666665\tAverage Loss: 1.7294168748340892\n",
            "\tTest: Average Accuracy: 0.30908203125\tAverage Loss: 1.9445226312238262\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 0.32838541666666665\tAverage Loss: 1.7274895067452178\n",
            "\tTest: Average Accuracy: 0.310546875\tAverage Loss: 1.9381912480706698\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 0.330859375\tAverage Loss: 1.7243091625029214\n",
            "\tTest: Average Accuracy: 0.3125\tAverage Loss: 1.934622176155719\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 0.3328125\tAverage Loss: 1.7202246184289625\n",
            "\tTest: Average Accuracy: 0.31396484375\tAverage Loss: 1.9330330669529578\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 0.33255208333333336\tAverage Loss: 1.7163041262824341\n",
            "\tTest: Average Accuracy: 0.3173828125\tAverage Loss: 1.9252932944917676\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 0.3365885416666667\tAverage Loss: 1.713072607155626\n",
            "\tTest: Average Accuracy: 0.31494140625\tAverage Loss: 1.9343674514798574\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 0.3365885416666667\tAverage Loss: 1.7085664323083394\n",
            "\tTest: Average Accuracy: 0.3193359375\tAverage Loss: 1.9256341657944276\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 0.33541666666666664\tAverage Loss: 1.7059100193592618\n",
            "\tTest: Average Accuracy: 0.3193359375\tAverage Loss: 1.9211032991866184\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 0.33736979166666664\tAverage Loss: 1.7018302821617448\n",
            "\tTest: Average Accuracy: 0.3193359375\tAverage Loss: 1.9210149340686344\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 0.33880208333333334\tAverage Loss: 1.6982617836991556\n",
            "\tTest: Average Accuracy: 0.3193359375\tAverage Loss: 1.919576929237616\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 0.34036458333333336\tAverage Loss: 1.6941203886626455\n",
            "\tTest: Average Accuracy: 0.3203125\tAverage Loss: 1.9215747152822362\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 0.33893229166666666\tAverage Loss: 1.6933377338543367\n",
            "\tTest: Average Accuracy: 0.3203125\tAverage Loss: 1.9202450216708846\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 0.34153645833333335\tAverage Loss: 1.6882549684132655\n",
            "\tTest: Average Accuracy: 0.32177734375\tAverage Loss: 1.916909916386021\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=256)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=256)\n",
        "\n",
        "\n",
        "network2 = FeedForwardNN(INPUT_SHAPE)\n",
        "network2.add_layer(48, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
        "#network.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "#network.add_layer(16, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network2.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network2.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log = network2.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EnINKAabdVH"
      },
      "source": [
        "Here we see that larger batch size did worse.This was because with the larger batch size our model has poor generalization and over-fits and doesn't converge.Therefor we can say that smaller batch sizes bring us more accuracy ( more accurate way of saying the fact is that there is a high correlation between the learning rate and the batch size, when the learning rates are high, the large batch size performs better than with small learning rates.)\n",
        "\n",
        "Totally about batch size we can say that trade off is very important .Beacuse small batch sizes have some problems, too.Updating the weights based on a small batch will be more noisy. The noise can be good, helping by jerking out of local optima. However, the same noise and jerkiness will prevent the descent from fully converging to an optima at all.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jTPApnGH-C1"
      },
      "outputs": [],
      "source": [
        "train_image_df= train_image_df/255\n",
        "test_image_df=test_image_df/255"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Another network \n",
        "\n",
        "Here , I have trained another network in order to see changes of diffrent parameters ,better."
      ],
      "metadata": {
        "id": "yV5FN8UBB0iV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Ad_RF1BtH8Ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e877fb1-0063-4d0a-b9f3-0fff5be8b5a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "()\n",
            "(1920, 1024)\n",
            "(1920, 1)\n",
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004111405697909573\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.210045449938006\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004106904803561305\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.2103454622384384\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004102151257897983\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2105850160886416\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040973960457910873\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2108403121198523\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040929967764486623\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.211107823781371\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040879934140935126\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2113253002150075\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004083732966305179\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2115856019519\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040793710843785904\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.211791612737111\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000407453268346742\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2120741161601623\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004070356024935758\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2123040506727714\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004065468242050073\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2125559842077154\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040612740070464746\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2127702066995605\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040564442378104236\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2130110397993876\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004052204481319055\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.21330332343933\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040476398061362523\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2135361703355727\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040429708686528625\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2137483290785633\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040389293314699933\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2140014182768355\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040342285856460566\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.214239959998734\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004029807331597647\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.214528644392549\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040252769525758134\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2147081421664674\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004021121262147509\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.214951615884632\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004016507512182473\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.215274786137233\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040119681926044875\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2154548058306442\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00040083198286222285\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.215704735094583\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0004002943944066286\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2159374843029127\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003999025033220462\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.216148683935336\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003994915510556779\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2164476844454786\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000398991560301878\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.216681755236953\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003986192056717472\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.216902569332175\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039814893879291935\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.217126465868954\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039773683062355777\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2174176736537476\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003973000547775595\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2176232371398257\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039682086626094176\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2178676932087455\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039644941980232083\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.218134313993146\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003959857329033719\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2183489207019695\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039560288732660634\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2185741085110795\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003951558784957783\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2188197222107555\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039470574975262687\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.219061725793487\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003943109394225684\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2193112461777402\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039383788789799077\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2195587332605275\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039345721637424567\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2197898415735926\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003929985745154506\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2200458097359026\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003926328370696137\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2202790127227585\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003921692621434482\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2205079840472335\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039177996441892154\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.220762478362164\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039130506812532195\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2209608209482012\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039089987370555316\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.221235140331762\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00039052343654284635\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2214478436592784\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003900955572335628\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2216804471308587\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038966899989625073\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2219295734203928\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003892496075438441\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2221882928708125\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038884465075692773\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2224048457393724\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003884174703643803\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2226960475016155\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038798047262610195\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2228985326311896\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038763859444372595\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.223134897289616\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038717973726356853\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2233517916889656\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038678142227464493\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2235818449215943\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003863502172494152\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.223883141869827\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003859706189677871\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2240542120942264\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038554951298327864\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.22426796859438\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003851598020715757\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2245244055127547\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038472586909237607\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.224755800403167\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000384316480168032\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.225041051246312\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038395432151368074\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2252354549781375\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003835296989691322\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.22546404388662\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038312093016259867\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2257214746030765\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038269070882842053\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2259225247815926\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038233645353124185\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2261990098167694\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038186482701079366\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2264542108308385\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003814868460725013\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2266322996460266\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003810840782543498\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2268667563310176\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003807164467360989\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.227145071679397\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00038028202951579705\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.227331321932807\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003798782229300999\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.227555340274735\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003794905746286268\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2278069335073227\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037906672144835587\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.228012565490007\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037870738702688915\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2282709392931177\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000378285713879543\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.228510980147768\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037791578179280003\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2287729582137166\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037750041302005594\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.22896867305779\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003770750849493417\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2291995939861757\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037673544892008183\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2294586071078797\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003763101356245852\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2296665597783147\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037591079848772947\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2298926213285766\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037553260237434033\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.23015364458564\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037514998973856386\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2303657352906043\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000374747517103117\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2305934463834705\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037437196583056225\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.230813231505978\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003739782058001701\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.231060869330433\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037359731301828114\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2313076646787082\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037319409564438437\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.231500688495877\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037280668318919326\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.231727948185198\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003724618177965205\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2319379688876664\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003720639908100701\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.232204262763015\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003716464914816908\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.232431808716584\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003712776048495204\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2326581457777106\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037089947246442056\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.23292258517222\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00037053067063529306\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.233106146312574\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003701468875065497\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2333793732238685\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036976231202160884\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2335553755150013\n"
          ]
        }
      ],
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "#X_train=train_image_df\n",
        "#Y_train=train_label_df\n",
        "#X_test=test_image_df\n",
        "#Y_test=test_label_df\n",
        "\n",
        "#print(np.shape(X_train))\n",
        "#print(np.shape(Y_train))\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=28, batch_size=32)\n",
        "print(np.shape(TRAINLOADER))\n",
        "#print(\"hefdah\")\n",
        "#for tr in TRAINLOADER:\n",
        "#  print(tr)\n",
        "\n",
        "print(np.shape(X_test))\n",
        "print(np.shape(Y_test))\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=28, batch_size=32)\n",
        "\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "\n",
        "network3.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Learning Rate "
      ],
      "metadata": {
        "id": "I_-3wnKTqcH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.05\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtFaNBm6oSvi",
        "outputId": "5c51b78d-ad98-4997-9066-d0a70729091b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.005093835536051768\n",
            "\tTest: Average Accuracy: 0.734375\tAverage Loss: 1.7160298111681263\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.005041958026356835\n",
            "\tTest: Average Accuracy: 0.73388671875\tAverage Loss: 1.7184440393302203\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004990730769939775\n",
            "\tTest: Average Accuracy: 0.734375\tAverage Loss: 1.7205238821783708\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004939035059741051\n",
            "\tTest: Average Accuracy: 0.7333984375\tAverage Loss: 1.7222686537856935\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004895718838212551\n",
            "\tTest: Average Accuracy: 0.7333984375\tAverage Loss: 1.724340689973448\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004846721239102331\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7266797646760996\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004798917588250429\n",
            "\tTest: Average Accuracy: 0.7333984375\tAverage Loss: 1.728630276844086\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0047538101836721\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7304242607482427\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004710044889192696\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7326872840311287\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004664407826360282\n",
            "\tTest: Average Accuracy: 0.7333984375\tAverage Loss: 1.7346683613143974\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004620050319782201\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7364434687947745\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0045825318039647385\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7379591429902135\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0045371853719146414\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7401381057313174\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0044963330464061445\n",
            "\tTest: Average Accuracy: 0.73388671875\tAverage Loss: 1.742156953436043\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004456122243988098\n",
            "\tTest: Average Accuracy: 0.73388671875\tAverage Loss: 1.743879512707058\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.00441344179669627\n",
            "\tTest: Average Accuracy: 0.7333984375\tAverage Loss: 1.7458023160092073\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004380396765438331\n",
            "\tTest: Average Accuracy: 0.7333984375\tAverage Loss: 1.7475610876481045\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004338498981841892\n",
            "\tTest: Average Accuracy: 0.73388671875\tAverage Loss: 1.7494845130803862\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0043028701624195686\n",
            "\tTest: Average Accuracy: 0.73388671875\tAverage Loss: 1.751434764768277\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004263634080617821\n",
            "\tTest: Average Accuracy: 0.73388671875\tAverage Loss: 1.7527723393700394\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004228796865841098\n",
            "\tTest: Average Accuracy: 0.73388671875\tAverage Loss: 1.7547552713251466\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004192672601650094\n",
            "\tTest: Average Accuracy: 0.734375\tAverage Loss: 1.7565961502420764\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004157410785970817\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.758401797975979\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0041222439607429325\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7601063853572114\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004089856152551596\n",
            "\tTest: Average Accuracy: 0.7314453125\tAverage Loss: 1.7620772351398353\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004053416067974983\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7633741235854297\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.004022646038250722\n",
            "\tTest: Average Accuracy: 0.73291015625\tAverage Loss: 1.7651683208882523\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003989354492957393\n",
            "\tTest: Average Accuracy: 0.73193359375\tAverage Loss: 1.7669133501994403\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003956017703518674\n",
            "\tTest: Average Accuracy: 0.732421875\tAverage Loss: 1.768417182810146\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003926642967756017\n",
            "\tTest: Average Accuracy: 0.732421875\tAverage Loss: 1.7704307756877156\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.00389437226289606\n",
            "\tTest: Average Accuracy: 0.73193359375\tAverage Loss: 1.77200265291475\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0038624494996954977\n",
            "\tTest: Average Accuracy: 0.73193359375\tAverage Loss: 1.7735050878888952\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0038338507054458382\n",
            "\tTest: Average Accuracy: 0.732421875\tAverage Loss: 1.7755106393757933\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0038042648984803807\n",
            "\tTest: Average Accuracy: 0.73193359375\tAverage Loss: 1.7771824944037948\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0037747264879950527\n",
            "\tTest: Average Accuracy: 0.73193359375\tAverage Loss: 1.7787148313965577\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0037446250718181054\n",
            "\tTest: Average Accuracy: 0.732421875\tAverage Loss: 1.7802566679532712\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003715139390089747\n",
            "\tTest: Average Accuracy: 0.73193359375\tAverage Loss: 1.781809928158064\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0036875192309607356\n",
            "\tTest: Average Accuracy: 0.73046875\tAverage Loss: 1.7835432090141246\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0036609105391597644\n",
            "\tTest: Average Accuracy: 0.73046875\tAverage Loss: 1.7850031637477297\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0036340159499833086\n",
            "\tTest: Average Accuracy: 0.7314453125\tAverage Loss: 1.7864826358503891\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0036060581154840235\n",
            "\tTest: Average Accuracy: 0.72998046875\tAverage Loss: 1.7880795191717649\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003577302464152491\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.7898749988393816\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0035546191421283947\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.791337884538442\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003526099691259796\n",
            "\tTest: Average Accuracy: 0.72998046875\tAverage Loss: 1.7928163267492363\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0035010225398475966\n",
            "\tTest: Average Accuracy: 0.72900390625\tAverage Loss: 1.7942630172298855\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003476974372172992\n",
            "\tTest: Average Accuracy: 0.73046875\tAverage Loss: 1.7958129249976127\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0034515503707228455\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.7973260844227237\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0034274149802075104\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.7985542995731194\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0034031475758829885\n",
            "\tTest: Average Accuracy: 0.72998046875\tAverage Loss: 1.8003831117658886\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0033792710146260843\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.8018357011193777\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0033557717964422403\n",
            "\tTest: Average Accuracy: 0.72900390625\tAverage Loss: 1.8033006491220358\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0033310790233508766\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8047089633529498\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003309619076493055\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8063463843120995\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0032864692134393493\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.807569802347337\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0032646566403987877\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8091550489808113\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003241499120576913\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8103003168864802\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0032195822150574934\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8120748119277117\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0031980204515199965\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.813394889917681\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0031764922297932235\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.8146572109440557\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003156858562687622\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.8163197566254914\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0031349827228563856\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.81734386765932\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003113099102570163\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8188168239983242\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003094431816343854\n",
            "\tTest: Average Accuracy: 0.7294921875\tAverage Loss: 1.8202887201700813\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003073004063279326\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8215535389877906\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.003054424901940861\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8231285926173355\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0030346106856612457\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.824360904995849\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0030144006562006953\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8257178048274911\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0029965224946312615\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 1.8271390121016022\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0029766634513967364\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8282781830350623\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0029581788487150723\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8296482805359813\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0029404370940486996\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8311160821179988\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0029209990079025285\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8325678062522641\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0029036322450220657\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.8336609447329728\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.00288490919679831\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8350710218051463\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0028677801600181046\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.8363532639000744\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002851307958443862\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8377235867543096\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002833004607565049\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.8389732569234276\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0028157520458932227\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8402196173826533\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0027975379039416304\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8414662501329189\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.0027828411420131455\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8428824913419355\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002765199765021825\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8442195537202892\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002749975112980712\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.845158761154939\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002732636333349504\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.846560464710245\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002717005704473269\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8476936898477643\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002701423980869593\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.848983108793029\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 0.9998697916666667\tAverage Loss: 0.002685948048891732\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8501400933644614\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002670858700459367\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.8512943046794064\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002653619407007839\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.852633088806844\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002639963717030719\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.8536765109774067\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0026246358805428302\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.8547996253754517\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002610750631738721\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.8560527462702985\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0025951513237359868\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.8573079532542853\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0025807907447343522\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.8583264160774453\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002566165191271049\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.859644599965999\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002552841505382597\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.8608031851876183\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0025379399096051502\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.8619023415209985\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0025239158835569904\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.8630431262691431\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002510884761166149\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8640797488801497\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0024970054147154873\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8654269183223458\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002482926800122084\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.866188297213335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVXD166Fpnay",
        "outputId": "3756a2b0-b910-45c8-99be-91ec21545a45"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002470292088135755\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8675331338846153\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0024570522539018704\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8686011072197937\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002443118193227159\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8696860373405988\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00243103722558581\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8708107640294795\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0024172207144840304\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8719191644310804\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002404947854424101\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8728624334771533\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0023922804520224304\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8740442336642498\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002379427015590486\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8752905781565423\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0023678492556599828\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.876201875979037\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0023548946663625916\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8773244317450528\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002343123690058545\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8785084651007358\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002330413907179925\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.879620018442646\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0023187672527942133\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8807041631227506\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0023075020360436805\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8818380365463034\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022948670128455774\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8827516249853664\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022834613951099292\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8839031310398648\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022724733635781217\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8849011357844652\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022607555143504083\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8859569499051498\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022496702370586787\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8869531943687452\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022378091089222366\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8880989395481544\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022274750343105262\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.888938456044209\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022160560277062966\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8900098109856793\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0022052664418254543\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8911079355476044\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002194490599125054\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8921943982904024\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0021835883692073147\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8931531354568625\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0021736118576622093\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8940851201746716\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002162761380188024\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.895264926177619\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0021521790649798134\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8961647040575218\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002142475141022052\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.8971051617743009\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002131380715485394\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8981541382400602\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0021209867667539425\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.8992468440149677\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0021118473647220672\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9000768566950477\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002101753280999736\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9010148902385975\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002091641525200464\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9022341556728282\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002081549666626007\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9032115829105463\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002072092539194045\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9041777281638361\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002062049137485045\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9051772036532062\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002052895429854943\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9061145138368247\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0020432768627642256\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9071030337316388\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0020340936973583185\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9081126095132022\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0020248746079515934\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9090451384280325\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002015037166530265\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9100897321015684\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.002006259427510932\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9109997542116388\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001996905335175435\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.912013294919138\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019882017648123066\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9130248026929322\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019791866357486447\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9138429020625796\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019697227317617212\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9148578171068182\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019612170757831266\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9158706824528853\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019528647092172493\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9166942202735506\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019438833226741248\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9178549497276522\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019355248084224135\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9186433385980122\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019268354652413277\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9195590473766861\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019185058824084022\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9205627829842946\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019103511290411092\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9215374465302855\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0019024355748616846\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9224943084058452\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018931907718699862\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9233115241630692\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018854804437113022\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9241718887855073\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00187745323024936\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9250639677164902\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018694571291820463\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.926106794703804\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018612647726018842\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9268758056333368\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018532254278404387\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9278444838374886\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001845349050461527\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9286123571198206\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018374489257002972\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9296187284204582\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018298002744229131\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9305407247619777\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018229863528230216\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9315736323134964\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00181467244918052\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.932230746983347\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0018070795847190445\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.933097957391833\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001799734790926551\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.933987343953484\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017927154302171846\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9349021968184679\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017846099262076366\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9358743413235189\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017774110125861639\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9366695749566643\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017704173276055792\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.937521239325285\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017632581924417916\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9384988591956969\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017561843590315394\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9393824733066523\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017485767124849185\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9402186273484658\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017416114044223189\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9409883396652792\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017349577390331464\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9418265730708186\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017281928801077687\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9428634749034033\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017213387571873948\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9436278686529374\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017140701603893696\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9443873489750512\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0017074770213075983\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9454732104827341\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001700417132920993\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.946200291984851\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016943420821154598\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9472098234571225\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016876008714019643\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9479636444808035\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016811002869608885\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9487292586490506\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016737717286506688\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9498102832544175\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016676665450689793\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.950497191472027\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016615327883768745\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9512810506781255\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016551759907734586\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9522997932509565\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016480679527861306\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9530180040340221\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016426381556459463\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9537415217450795\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001636079184369824\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9547307954833082\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016297284633357012\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.955583789424927\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016234618961908911\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9564359372675755\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016175200430481227\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9572826808349684\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001610980768840962\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9579667580540232\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0016060198661156351\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9586402951987099\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015992589077899813\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.959796622343473\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001593483381205612\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.960392440415356\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015869068570750595\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.961366757544798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STMxp03VrVPL",
        "outputId": "4407f633-38e7-401a-b40f-98a0eed7d076"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015814369434064555\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.962020982593471\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015757612546487\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9626883095867438\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015699498402412968\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.963695503277113\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015639008385831866\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9644931422849856\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015583719606622679\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.965187332095728\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015525654838048533\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9660919694246182\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015470902220928165\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9667010522386725\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001541433757535164\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.967579852369365\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015356179945743992\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9683778139813097\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015304562558478075\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9691200195884042\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015248001456747218\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9698644899802833\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015193758860853202\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.970708295154331\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001514005640392763\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9714959031596087\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0015086838921889868\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9722248362998418\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001503413001684692\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9728713428655344\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014980889920023807\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9737097337503564\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014927076640451399\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9744095558294135\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014877267558103357\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9752638360602357\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014820195661068675\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.976066775301918\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014772603841904071\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9766912766897167\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001471753557887366\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.977515028156764\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014671725862236832\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9782922705693045\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014620283568425238\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9790618387088181\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014570076489438387\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9797359491989583\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014519313084539838\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.980410962257475\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014470042620150542\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9812199497805394\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001441904902406099\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.981911365957909\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014373550396753246\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9826971327522385\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014321460342455992\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.983416014044333\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014271755878928474\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9841818789618433\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014225495251109044\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9849054289757961\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014180144296684191\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.985734988218814\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014129300780764934\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9863868384826455\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014081864687400367\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9871239615277227\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0014037689344661328\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9877178002895841\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013987717299841168\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9885872061414276\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001394458309814843\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9892707022285245\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013895554865044808\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9898864847851105\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013849876096805526\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9907198077095143\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013804811751748746\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9913937216753255\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013760328879682446\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9921455600855649\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001371425965004602\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9928480396381691\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00136698095235281\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9935451376726725\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013626206086026057\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9942104098503939\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001358241277269859\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 1.9949334647518762\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013538005427646876\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 1.9957802342819955\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001349683845721136\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.996386633459703\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001344997432294536\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 1.9971018849671194\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013408699991017269\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9976989421598659\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013366051706306958\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9983908970332316\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001332321748980523\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 1.9990886994973818\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013282864608717782\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 1.9996776143860542\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013237403749778753\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 2.0005578890143285\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013199781280257674\n",
            "\tTest: Average Accuracy: 0.72607421875\tAverage Loss: 2.001158020190029\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013156077755435563\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.0019718485472913\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001311907670120422\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.0024993204233197\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001307153916185465\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.0033054233805117\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0013033331111565296\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.0039374933845053\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012993080564911465\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.004631361522601\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012952962621243383\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.0053236774669454\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00129141388071986\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.0059378345740946\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012872267203686458\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.006766527700499\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001283200782592666\n",
            "\tTest: Average Accuracy: 0.7265625\tAverage Loss: 2.007339483636773\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001279604930835809\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 2.0079515949675715\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012755666641645874\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 2.0086189664314755\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001271601201898514\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 2.009367148081659\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012679460072239337\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 2.0100290448952123\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012640045337888141\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 2.0106090113217103\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012600055579047142\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 2.011342795066507\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012563765211350696\n",
            "\tTest: Average Accuracy: 0.72705078125\tAverage Loss: 2.011885212584194\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001252428059424206\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0125976495117834\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001248994654184559\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0132647745568653\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012453182610567004\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0139176380686363\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012412320210858396\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0145685380747613\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001237784398316113\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0151581802169556\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012340951257512147\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0158613333267317\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012303358886056953\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0165801077526204\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001226543567659321\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.017123883730943\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012230924036062084\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.017719353229297\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012194728646643346\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.018457318203308\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012159115415097796\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.019016320369805\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012123992077294828\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 2.0197073424479868\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012089767223302016\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.0204084394970145\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012053321768657097\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 2.020913297618206\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0012018218585523337\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0214663272491125\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011982865988197226\n",
            "\tTest: Average Accuracy: 0.728515625\tAverage Loss: 2.0222146144381448\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011949084757351062\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0228508947097863\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011915831259347858\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.023496335472222\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.001188112899486704\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.0240670825451854\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00118471002279215\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.024694932322822\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011813156239155276\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.0253708780136694\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011780647381981284\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.0259253070403442\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00117445588987073\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.026586193703797\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011711283001505138\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.0271832009013298\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011679145031807303\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.0278161513976922\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011647528200196323\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.028469288744491\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011616442653867554\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.029012240122694\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011579770202193357\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.029653096602739\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011549651140408499\n",
            "\tTest: Average Accuracy: 0.72802734375\tAverage Loss: 2.030357936800667\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0011516244325944734\n",
            "\tTest: Average Accuracy: 0.7275390625\tAverage Loss: 2.0308152068946157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that on this network smaller learning rates result in better results on train set."
      ],
      "metadata": {
        "id": "o3voWwpTrF7r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Activation Function"
      ],
      "metadata": {
        "id": "UKG4BufjrAEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Sigmoid(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Sigmoid(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltMvCR8PqZyL",
        "outputId": "bd939cd8-90df-4db9-ac2b-23ca633d9758"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036939364310846094\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2338274887579113\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003689896438214658\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.234039088029083\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036864107215742723\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2342601506865702\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036824359816763454\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.234524170630292\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036789991537452204\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2347236030167252\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036751406075727507\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2349581353236805\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036711974530714245\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2351340429307927\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036675165893210887\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2353856758945105\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003663844873630694\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.235608362211568\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003660114527335728\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.235864689664301\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003656558557627783\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2360990815489354\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000365261477319759\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.236320006201148\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003649030223576005\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.236514205459732\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003645487471791544\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2367626194490557\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036416174838624767\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2369729028757837\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036379066923160965\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.237194603509791\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003634481217260554\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.237434798538679\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036308641335119576\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2376472514467536\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003626813715603595\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2379049344465476\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000362340740062618\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2381128475557683\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036200732630033936\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2383348236979534\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036162007736728825\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2385130369344997\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00036125083185641293\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.238735762614276\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003608954509438531\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2390236133379804\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003605205695765672\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.239226168114118\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003601648566146579\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2394401602801235\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003598266810173132\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.23969080600257\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003594703038365894\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.239896445378475\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000359089594280747\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.240079306744515\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035876049546542445\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2403372918005187\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035838791337271003\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.240562761004644\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035803193079264015\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2407782309140667\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003576726080064809\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2410186439029345\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035729518554233154\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.241238409516906\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003569892091996371\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.241473410516112\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035661672506450624\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2416828704028604\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003562459568974212\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2418997104724316\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003559197850264646\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.242134212477811\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003555556265556621\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.242308569568274\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035519084955565143\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.242565168806695\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035488322227145787\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2427998188713496\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003544952584734647\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.24301762619599\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035415705137615985\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2432371274837277\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035379831437717566\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2434566197292134\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003534680088584475\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.243646277055886\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003531239372507832\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2438816196728193\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003527711674167553\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2441243719962483\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003524343103853512\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2443002511069587\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000352077863433337\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.244539247879302\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003517351583605039\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2447732704679617\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003513812798953478\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2449946042713784\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035105978344872416\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2451939263040708\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00035072086767783394\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2454516098990567\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003503770140057122\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2456438021811325\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003500366150531252\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2458814472643858\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003496835192265442\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.246091615563508\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003493450626879412\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.246316528862587\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003490240961783816\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.246524292769543\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034864784031605025\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2467286147640246\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034836696018250384\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.246963642413216\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034797479228657345\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2471801657849846\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034767647692887047\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2474157866407714\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003473297114968216\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2475995778493614\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003469886965980178\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.247817035561574\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034666569020175563\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.248036806932235\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034632361191712146\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.248276413175608\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034597523917755227\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2484841066045766\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003456791611641531\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.248688730101618\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003453378572364011\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.2489143210303912\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003450033802182785\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2491488510131696\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034465223281891034\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2493066327449514\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003443472841577127\n",
            "\tTest: Average Accuracy: 0.7328125\tAverage Loss: 2.249542467471237\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034402153828419745\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.24976583954795\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003436634694780786\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2500204820423098\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034335496643182246\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.250225898522143\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003430198288814961\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.250409265809845\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034270561570526467\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2506222222064083\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003423703056356689\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.250869346091174\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000342044968912035\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.25105858358575\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034171718746226105\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.251326452480588\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034139154125166\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2514778560725985\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034109827102343386\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.251709430183716\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034074986281720565\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.251888420553115\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003404331565182749\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2521181784105155\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00034008589674781577\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2523749732915146\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000339782392682022\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2525635481798294\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003394648316408382\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.252760786010933\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033914722887851974\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2529800904623953\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003388061643504251\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2531974425920422\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003385198944577223\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2534241317471477\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000338164399384564\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.253599954990995\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003378593549092404\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2538417982863215\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033755856678423685\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.254030590764654\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033723837977787165\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2542498176985344\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003369019515340308\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.254468371490231\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033659990030351407\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2546488599419505\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033628798016391303\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.254922843024221\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033597196229298045\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2550837153619656\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033565228909065406\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2553167784357115\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003353284546991953\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.255529179073895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Sigmoid(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Sigmoid(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Sigmoid(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnaVd_kDswKs",
        "outputId": "ec54dbf9-83a2-4a51-d411-1784064c9af5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033501313741336075\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2557391436403225\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000334717548967251\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.255954044094677\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033441456855217734\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.25612893416216\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033408794745134335\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.256372715093763\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003337843029479952\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2565600732043003\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033345504089233295\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2567740831615555\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033317445992560465\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2569687693225715\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003328498395043821\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.257198573868811\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003325520130594567\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.257389806593381\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00033221114312884044\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.257628475657264\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003319276363965206\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.257790318806255\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003316284840923042\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2580627894453906\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003312943351814065\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2582248572688415\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003309849840237205\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.258441249467716\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003307185488698213\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.258671453524206\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003303973414002608\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2588118732856217\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003300792563832189\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.25907452886846\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000329798037932401\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2592397726994897\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032947468697344613\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.259476361703426\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003291849477794908\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2596852356553154\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032886437089388863\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2598971391840994\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003285718155844108\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2601115324608614\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003282760186477428\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.260260425976654\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003279771909429386\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2605147081133183\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032768033723518304\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.260735356804841\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032737974151568076\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2609133928601546\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003270535685177708\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2611431833625963\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032679076347686705\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2613190277759236\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032647896843591355\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.261521064751729\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003261761658096428\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.261715099286208\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003259032805402774\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2619214573528206\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032557771967894937\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.262154226291116\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032529403719940063\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2623854386174225\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032500711789904365\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2625219214956402\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032470860959500083\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2627666813557514\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003243976557079997\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.262962045792878\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032412078664106875\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.263200183273374\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003238173301537299\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.263331007456868\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003235264931056404\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2635483444566393\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032324197237769875\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2637688321334797\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032292937024167403\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.263955862217129\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032265766857912567\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.264191955960118\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003223721146206289\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2643695041176928\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003220604595498396\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2645976485298687\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003217970789328902\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2647912729297133\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003214744670605541\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2649859350284545\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003212093959509145\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.265147565360695\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032092979260319067\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2653801078454903\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003206234051173123\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.26555760439889\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003203401974536806\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2657827870251888\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00032006260724663484\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2659833083104064\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031976311738609865\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.26618112337277\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031948323854268183\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2664059819031803\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031918975276259786\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.266587707769953\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003189305607002026\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2667912492405264\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031861229327871145\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.266988120387293\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003183442976956585\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2672128189481326\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031805146232177713\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2673601022528933\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031777342319570145\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.267597018442444\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031751115868378874\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2677797281976853\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031720478145470115\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.267993134548865\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031692779228376474\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2681718483429503\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003166737989540202\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.268388599169733\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031634116418486377\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.268586321198506\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003161106998941769\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.268804990933355\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031578600041609026\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.268987060242623\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031554111344844873\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2691473677392753\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003152732694135074\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.269383798378222\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003149620565141426\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.269605365832878\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003146948332902096\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2697746707131925\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003144223592276756\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2699353444817416\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031415337286309675\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2701496529078744\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031386710315715703\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.27036363881136\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003135884691049848\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.270562728680111\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003133111902341342\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2707799704110747\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003130655707161249\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2709489793738853\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031276680783166747\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2711601004098014\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003124967383207686\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.271333361476462\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031221924336106765\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2715270690408347\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003119492938740385\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2717555703928127\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031166963311424965\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.271905388789998\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003114029588540184\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2721269737555345\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003111412933240067\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2723359836289756\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031083991414494527\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2725591492491493\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003106247672182163\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.2727455270591523\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00031030611331798774\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.272887097303332\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003100558308360418\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2731234580432\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003097693883670102\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2733327437247\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00030951933694707676\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2735074371086545\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003092507195061656\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.273749126757193\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003089711971235926\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.273879616029874\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003087044973988417\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2741235656293575\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00030845167539559314\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2742716822198856\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003081750460866659\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.274503971262981\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003079114137375739\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.274708470166062\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00030764145474510506\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2748523681522\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00030737793539976986\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.275081031680016\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003071224903484404\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2752369440553135\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003068499045383438\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2754766004441196\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0003065820172932212\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2756430622367043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Tanh(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Tanh(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQ-q6smJtypE",
        "outputId": "f38f776a-f1f4-4f3a-ef0d-008804eae0ec"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002819256081120716\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.294673383630855\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00028165405132103764\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2948509300675264\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002814502551576561\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.295040463847654\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002812411660619696\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.295239211652246\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00028102478992063113\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.295457337120668\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002807942456788669\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.295589469847577\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00028057160916485877\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.295775610710344\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00028034641056190967\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2959797475538393\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00028014978675066054\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.296153052856746\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002798937899302174\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2963189003452267\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027968877913684835\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.296511081649283\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027946547188916995\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2967005007364474\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027924018696302903\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.296860958640116\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027902586402999145\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.29706687783397\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002788049092494485\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2972487217771342\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002785880821744682\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.297411673119829\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002783762400537161\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2976103678232125\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002781416370531313\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2977998750295114\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002779373443737999\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.297955762677221\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002776965206480141\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.298186464449252\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000277498516062693\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.29831281047593\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002772717427746789\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2985217335056305\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027705866661664074\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2987078796414524\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002768413242809381\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2988643082529734\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027662332172529206\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.299050064246096\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027640725633891185\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.299230536980737\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027620784497746635\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2994311268235412\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002759626990659734\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2995902508013484\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002757544056371843\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.2997721010507592\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002755473486090365\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.2999384241384906\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027533265333742684\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.300162684582541\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002751070438340734\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3003472191179033\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002748930163570901\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3004855064121696\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002746985838495611\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.300675020614086\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027446566927178274\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3008655124246347\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002742607834282172\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3010229603569647\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027404095229505\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3012512939660175\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002738356830390188\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.301377089481163\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027362630057960825\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3015667810381633\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027339765581368844\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.301753567470613\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027319730327539273\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3019222041834526\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002729881272737714\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.302063591796048\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027276929756118757\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3022800747563172\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027257493291092075\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3024577949532103\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002723419252095705\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3026171526752184\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027215822197821586\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3028333863901387\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027192769499356177\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.30297664405605\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002717249957123215\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3031719898257363\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002715286011370596\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.303352903824247\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027130439730184663\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3035324366427616\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000271088813137242\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3036879760348166\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027088912648885077\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.303858586720819\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002706741789378965\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3040645582644874\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002704852000298925\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.304213649488291\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00027027189595777194\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.304388844585691\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002700553546262448\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3046029119928315\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026984868220950487\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3047202375061033\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002696555206135544\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3049220189981794\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002694428335542067\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.305093055472674\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002692336348105793\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.305257433715267\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002690271326433173\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.305467113901008\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026882631995979895\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3056474853325204\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002686097782181783\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3058059709863414\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002684172470621465\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.30599851823412\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002682126768339849\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.306140748478786\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026800848155055017\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3063517089879197\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026780226451934494\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.306457999216487\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026761838537357584\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3066888621607737\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002673860629907007\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3068556087714227\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026719880376030203\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3070064039908003\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002669883103417978\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.307231414006628\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002667822092511134\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.307390740827823\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002665856603140839\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.307561921425561\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026638509527347266\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.307716860882972\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002661844011360871\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3079020567201476\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026599179227625603\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3080616400105414\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002657682296940087\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.308240395772589\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026559298237980135\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.308435851977195\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002653750003687639\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.308594701173319\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002651714956725362\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3087692569800704\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002649753336182783\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3089488359371684\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026479177476445746\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3091315640910395\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026459001709343733\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3092909721489465\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000264382734573085\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3094720458717504\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002641772251243471\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.309617639374819\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000263989975219721\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.309818291038122\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002637887684890129\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.309984931050364\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002635937973715157\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3101472943756582\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002633978986031947\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.31030053422535\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002631925202558953\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.310532166997055\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002629871632845353\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.310667502832264\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002628089936721412\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3108172545078127\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002626017714183238\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.311029962287585\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026241325452764166\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3111864391422414\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002622145373696856\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.311378988149846\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002620161581306926\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.311528351078152\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002618282533167225\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.311715619215418\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002616205687327459\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3118629495420526\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026142552288229657\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.312083197460532\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026124450121889516\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3122020806593793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Tanh(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Tanh(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Tanh(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJDnwapIvX2t",
        "outputId": "66456e85-3abe-4e60-d4a3-f8f27a287317"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026104058766552977\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3124005766256213\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026086054041456484\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3125810689162463\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026065479114983773\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3127221245032894\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026047126883210124\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3129104356655557\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026026201227316684\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3131012523179972\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00026007885334615574\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3132587764299704\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025988370249887426\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3134414425594665\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002596977425649739\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.313562526449155\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002595052371799704\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3137787443764157\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025929362498786947\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3139445294581664\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025912503960914265\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3140978186294685\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002589187500629793\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3142901321783618\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002587450385730047\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3144263209595097\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025854369536283217\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.314616683888135\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025835326459882046\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3147790524393748\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002581701661382537\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3149135258813405\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025797002748471296\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3151391533886736\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002577921185999346\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3152728466072756\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002576158542242819\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.31546174980864\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025739258036748617\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.315642374451369\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025721717899357665\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.315792868076636\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025702729660437274\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.315971022713086\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002568617782835006\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.316155513225541\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025664378873671193\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3163279248875215\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002564743819066017\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3164695582756876\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002562912752544846\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.316620339977901\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025609573340987625\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3167986376122442\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025590160379366925\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3169826763038737\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002557267347722578\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3171673745292813\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002555346047218798\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3173187493986895\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025534644796445236\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.317463136077332\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025516905633220406\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.317665093911246\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025496741016283104\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3177928073802985\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025479608568985116\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.317983155271173\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025461507479324145\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3181550989969417\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002544228600929297\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.318314593915077\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025423594218222846\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.318480058631103\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002540611010864442\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3186476446173945\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002538624325782465\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3188196993645107\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025370003330670157\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.318989915622741\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025350796393466737\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.319125432224239\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025331945121172413\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.319301472249875\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025315072105983397\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.319503707677813\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002529652541422411\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.319656497764926\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002527479987152071\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.319825647122117\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002526104762018251\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3199683492093035\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002524074696005396\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3201636232072875\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002522266606350349\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3203115031712707\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025204260368202707\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3204878612373867\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002518840110308168\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.320673663331062\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000251673779444392\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.320810892325892\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002515090559032144\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3209948968281773\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002513250809631855\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3211485534302074\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025113143750560496\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3213027208984096\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025098512001194386\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.321488845143797\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025078206765260266\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3216728380247798\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025061274173886883\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3218166236178654\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002504264760518781\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3219759314846207\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025025865868867695\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3221391438284757\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00025005363621317315\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.322322982755725\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002499022230158929\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3224683979660354\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024971528941077124\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3226334492565184\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002495288924940435\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3228177334635833\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024935746631595614\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3229699642947392\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002491780911194626\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.323135195832796\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024899663351032295\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3232671461765735\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024884345137720146\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.323463792295018\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002486422561885072\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.323650212215898\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024847948860791174\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.323788476434302\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002482964400169122\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.323959035027457\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024811576371054877\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.32410978238531\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002479495524503387\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3242749373395566\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000247764587689621\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3244347762005217\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024758811225033595\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3245876829706678\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002474209262658463\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3247912819085674\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024723798415208505\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3249320526746535\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024708043399919064\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3250917973341734\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000246884274440224\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.325275227796168\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002467260183900373\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3254189504569336\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024654771936705465\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3256057113609443\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002463742069391713\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3257690902305783\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024619061474894123\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3259132213841496\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002460377931355252\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3260747849188816\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002458511031092844\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3262487449764486\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024568126503962705\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.326441926632635\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024549902714285447\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.326536586892272\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002453460364699464\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3267348908483427\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024516310408437\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3268762846239466\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002449880546976824\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3270525598696556\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002448250017458764\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.327227443712437\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024465121398336475\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3273546409949923\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002444788973471574\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.327552195397168\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024430233933257143\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.327727029488074\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002441279664046412\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3278693953902745\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024396460394118013\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3280335674990194\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024380144252889957\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.328177756129794\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024362382295390264\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3283171242026937\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024346885086630983\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.328512162942164\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002432928866466834\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3286726122177273\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00024309798841943252\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3288188751133516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "TRAINLOADER = Dataloader(X_train,Y_train,n_classes=16, batch_size=16)\n",
        "\n",
        "TESTLOADER =  Dataloader(X_test,Y_test,n_classes=16, batch_size=16)\n",
        "\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=Relu(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=Identical(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57yxOCUtwlNV",
        "outputId": "796ea341-10e4-4bd5-b7ee-29c7bd192593"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021268099845021994\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.359764333565924\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021259372882471557\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3599016120061806\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002124589531710053\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3600548933292487\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021232650240234261\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.360197902588176\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021219995026260446\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.360334652156399\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021206578636589563\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.360455912956638\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021194149225382594\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3606336874712683\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021179701982003475\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.360752068543214\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021167545341648563\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.360911296229425\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021153277719560982\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3610501427377755\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021141034232671017\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3612032276607295\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021127989526517857\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.361341642122189\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000211153901849757\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3614751619761765\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021101818562119983\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.361618828580748\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021089119963754\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.361745738412696\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021076548223751684\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3618892979641286\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021062031458470332\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.362056395459347\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021050230015903296\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3621668518566623\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021037676558852792\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.362308956144252\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021024042815157514\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3624402514801734\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021011371363293077\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.362611251685547\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020998442434460064\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3627419715256703\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000209854109401262\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3628741878777957\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002097264514767708\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.363041201215269\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020959905073982045\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.363164575115421\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020946908659525085\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.363297478394705\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020934141080298152\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.363442061352186\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020921301712815507\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.363589947623689\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002090742127679321\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3637274186044395\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020895901024167626\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3638939516297226\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000208832892318379\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3639845427308592\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020870559234292187\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3641506423973646\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020857529519701244\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.364265802431939\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002084414833390908\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3644392204391163\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002083181444328841\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3645905920331813\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020819426014329369\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3647005115593767\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020807158719994591\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.364848582704882\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002079347006989264\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.364998223096142\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020781493540136554\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3651335474356316\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020768969219535455\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3652702423191396\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020756217044404693\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3653838636130837\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020743823551006572\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.365552384523069\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020730775483874416\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.365681245122934\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020718281929845705\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.365835139685609\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002070586488852718\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.365947712507571\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020694262158651723\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.366109965376955\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020680173981150218\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3662339148915636\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020668726808029166\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3663680709254105\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020655172426357882\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3665316361204125\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002064382772398659\n",
            "\tTest: Average Accuracy: 0.73125\tAverage Loss: 2.3666434296295353\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020631240033584054\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.366770331803375\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020617822507860853\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3669413779422173\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020606640298141072\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.367060230043768\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020593151854569528\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3672327381491316\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002058041236462354\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3673466929518714\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020568861959746376\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.367502278199875\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020556570195045254\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.367628525814719\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020544245272575087\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.367758144039674\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002053093161366211\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3679099406532047\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002051991238417186\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3680479310463216\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020507468618244728\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.368154166089963\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020494663834959436\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.368309082023174\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020482793489755427\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3684507115410516\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020469741495136263\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.368562308754765\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020458308528406674\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3687282545990502\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002044506744015979\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.368872157941404\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002043372739700804\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3689991349483934\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020421466849247902\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.36915224002451\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002040886725056978\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.369287365144309\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020396645692926787\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3694046054668094\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002038438287356011\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.369564688779635\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020372804921555898\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3696786430666736\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020359500621116715\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.369826774361763\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020348641359866208\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.369956304149697\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020335572322922603\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.370117233705286\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020324303973032922\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3702392108971946\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002031191594088115\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.370382529544878\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020299857288694478\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3704980488323173\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020287689467337166\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.370672744930593\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002027486646837759\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.370780033919968\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002026430833684686\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.370929909390864\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020251798607660555\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3710483372037445\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020238998426206495\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3711777876618014\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020227810826246195\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3713203541537182\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002021585197680296\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3714620207363595\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002020369283079259\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.371598954160985\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020191929149735103\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3717262194429853\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020179387262178044\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.371880415176305\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020167635503178666\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3719947438983353\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020155596750181666\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3721402205607727\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020144416869829183\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3722742414543845\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020132075005198247\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.37240812950461\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020119938671679256\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3725614691132564\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020108993831175753\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.37268748475129\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002009582980466802\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.372832437088356\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020084764135453037\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.372956401501305\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020072869423328558\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.3730792729520886\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002006138524551759\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.373212866528357\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002004859011205096\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.373367532954113\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00020037127946865972\n",
            "\tTest: Average Accuracy: 0.7307291666666667\tAverage Loss: 2.373497010606483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = 32*32\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 100\n",
        "\n",
        "\n",
        "network3 = FeedForwardNN(INPUT_SHAPE)\n",
        "network3.add_layer(48, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
        "network3.add_layer(32, input_shape=INPUT_SHAPE, activation=LeakyRelu(), weight_initializer='uniform')\n",
        "network3.add_layer(16, activation=LeakyRelu(), weight_initializer='uniform')\n",
        "network3.set_training_param(loss=CrossEntropy(), lr=LEARNING_RATE)\n",
        "\n",
        "log3 = network.fit(EPOCHS, TRAINLOADER, TESTLOADER)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvrWfohLyTSA",
        "outputId": "39e312db-71b3-4790-8787-99f504bc120d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022696926048750685\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.344766152761279\n",
            "Epoch 2:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022681981416510508\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.344902012281084\n",
            "Epoch 3:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022667485774581183\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3450888762829805\n",
            "Epoch 4:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022651335496531763\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.345222509272259\n",
            "Epoch 5:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022638036656257826\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3453822542217924\n",
            "Epoch 6:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022622848800347826\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3455008832101654\n",
            "Epoch 7:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022607492505038473\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.3456682126439947\n",
            "Epoch 8:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022592602026170282\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3458112334544157\n",
            "Epoch 9:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002257864828606807\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.345978963612142\n",
            "Epoch 10:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002256324770642082\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3461218709580494\n",
            "Epoch 11:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022547924497304738\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.346260778690093\n",
            "Epoch 12:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022534559141383357\n",
            "\tTest: Average Accuracy: 0.7322916666666667\tAverage Loss: 2.346413080184476\n",
            "Epoch 13:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022517941077891869\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.346594672277179\n",
            "Epoch 14:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022504706996386543\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3467125368083384\n",
            "Epoch 15:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002248873734028095\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3468787598438827\n",
            "Epoch 16:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002247629814276358\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3470430171518477\n",
            "Epoch 17:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002245930711967593\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3471682699540333\n",
            "Epoch 18:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022446551836272606\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.347325899032565\n",
            "Epoch 19:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022431257589795078\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.347482121955888\n",
            "Epoch 20:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022416377714426925\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3476339867613323\n",
            "Epoch 21:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022402233556047195\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3477573775845415\n",
            "Epoch 22:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022387920066694773\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3479251043658738\n",
            "Epoch 23:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002237228359997538\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.34808380791445\n",
            "Epoch 24:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022357884319886855\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.348253604882714\n",
            "Epoch 25:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022343964460490713\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3483395812754058\n",
            "Epoch 26:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022328885444225882\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3485275597483377\n",
            "Epoch 27:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022314937714398497\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3486851371131388\n",
            "Epoch 28:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002230066870394226\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3487939379327174\n",
            "Epoch 29:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022286638177123518\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.34897216278902\n",
            "Epoch 30:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002227126832268274\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3491226889268955\n",
            "Epoch 31:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022258063439659962\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.349254161652195\n",
            "Epoch 32:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022242209176405548\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3494232024891875\n",
            "Epoch 33:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022228385396037644\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3495486775987975\n",
            "Epoch 34:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022214923920105218\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.349689782225052\n",
            "Epoch 35:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002220021378161861\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3498477832496807\n",
            "Epoch 36:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022185468906708272\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3499741697037937\n",
            "Epoch 37:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022170928408349973\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3501508545125023\n",
            "Epoch 38:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022157788919014825\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.350283658640775\n",
            "Epoch 39:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022142775957015128\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3504266348932092\n",
            "Epoch 40:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002212848910365715\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3505897698942917\n",
            "Epoch 41:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022115113528280435\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3507277890104095\n",
            "Epoch 42:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022099895021069537\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3508824861408337\n",
            "Epoch 43:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022086009422652973\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3510422501677013\n",
            "Epoch 44:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022072228711845926\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3511677854158486\n",
            "Epoch 45:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022057357352647138\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.351332400142961\n",
            "Epoch 46:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022043130406613711\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3514925692932795\n",
            "Epoch 47:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022030197738565413\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.35159375226605\n",
            "Epoch 48:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022015446712160346\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.351763214110249\n",
            "Epoch 49:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00022001140221771556\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3519342375047985\n",
            "Epoch 50:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002198774104073124\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3520596042932227\n",
            "Epoch 51:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021971633891410528\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3522301716537273\n",
            "Epoch 52:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021960249093726098\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3523478761763794\n",
            "Epoch 53:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021944815483814403\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.352523060553021\n",
            "Epoch 54:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021931611086056774\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3526395834202303\n",
            "Epoch 55:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002191723582812123\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3527890944445633\n",
            "Epoch 56:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002190339810833683\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3529523491174364\n",
            "Epoch 57:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021888947201488166\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3531167316994126\n",
            "Epoch 58:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021874551875637228\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.353250493636888\n",
            "Epoch 59:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021862556487670006\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.353369398145661\n",
            "Epoch 60:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000218475532779448\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.35355085474208\n",
            "Epoch 61:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021832933025462865\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.353692233983203\n",
            "Epoch 62:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002181970026554284\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.353832246964332\n",
            "Epoch 63:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021805009961441493\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.354003747269367\n",
            "Epoch 64:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021793800638327416\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3541374356805536\n",
            "Epoch 65:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002177833578751588\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3542631090930914\n",
            "Epoch 66:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021764393103621964\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3544104274921334\n",
            "Epoch 67:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021750061930706467\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.35455541362032\n",
            "Epoch 68:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021736149748823502\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.354710549705263\n",
            "Epoch 69:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000217239265573347\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.35487128530056\n",
            "Epoch 70:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021709745680269544\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3550048958364496\n",
            "Epoch 71:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021695038340592259\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3551520522745624\n",
            "Epoch 72:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002168174012473793\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.355303784874638\n",
            "Epoch 73:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021667299696191586\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3554370917576377\n",
            "Epoch 74:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021654897134215517\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.35557812173587\n",
            "Epoch 75:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021641974855096956\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.355726862680858\n",
            "Epoch 76:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021627162210116223\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3558881146873243\n",
            "Epoch 77:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021613436120879477\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.356007728833302\n",
            "Epoch 78:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021600293711394983\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3561799320550803\n",
            "Epoch 79:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021586310110174246\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.356304789343377\n",
            "Epoch 80:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021573065105379117\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3564366647128367\n",
            "Epoch 81:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002155942221690439\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.356600787385114\n",
            "Epoch 82:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.000215454752442992\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.356734838300165\n",
            "Epoch 83:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021532712356724728\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.356901477873696\n",
            "Epoch 84:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021518934859506502\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.357041322058517\n",
            "Epoch 85:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021504647717860142\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3571658915130778\n",
            "Epoch 86:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021491073869872896\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3573314939266186\n",
            "Epoch 87:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021477780648230908\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3574547145268596\n",
            "Epoch 88:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021465411861711065\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.357604757742005\n",
            "Epoch 89:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021451535346955707\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.357735355373083\n",
            "Epoch 90:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021436726693570615\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3579107722062314\n",
            "Epoch 91:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021425247162008484\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.358012634136767\n",
            "Epoch 92:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021410598929525655\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3581944330452123\n",
            "Epoch 93:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021398189837912952\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.358286610768576\n",
            "Epoch 94:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002138456944192484\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3584523445449372\n",
            "Epoch 95:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002137038116507353\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3586021747129475\n",
            "Epoch 96:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021358083556437894\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.358735320367636\n",
            "Epoch 97:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021344589219579463\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3588981593473424\n",
            "Epoch 98:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021330427679207628\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.359037400772699\n",
            "Epoch 99:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.0002131773202236221\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.3591811029841874\n",
            "Epoch 100:\n",
            "\tTrain: Average Accuracy: 1.0\tAverage Loss: 0.00021305160623516755\n",
            "\tTest: Average Accuracy: 0.7317708333333334\tAverage Loss: 2.359309467430073\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}